from aiogram import Router, F
from aiogram.types import (
    Message,
    CallbackQuery,
    InlineKeyboardMarkup,
    InlineKeyboardButton,
    InputMediaPhoto,
    ReplyKeyboardRemove

)
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import State, StatesGroup
from aiogram.filters import Command
from langchain.schema import SystemMessage, HumanMessage, Document
import asyncio
import html
from typing import Optional, Dict, List, Tuple
from fuzzywuzzy import fuzz
from typing import Dict, Set, Tuple, List
from datetime import datetime
import re

from bot.handlers.ultimate_classifier import ultimate_classifier
from bot.handlers.query_preprocessing import expand_query_with_abbreviations

from src.database.db_init import db
from src.data_vectorization import DataProcessor
from models.models_init import Google_Gemini_2_5_Flash_Lite as llm
from bot.handlers.utils import (
    fix_bold,
    safe_delete_message,
    create_test_link,
    is_test_code_pattern,
    normalize_test_code,
    check_profile_request,
    filter_results_by_type,
    is_profile_test
    )
from bot.handlers.sending_style import (
    animate_loading,
    format_test_data,
    format_test_info,
    get_user_first_name,
    get_time_based_farewell,
    format_similar_tests_with_links
)
from bot.handlers.score_test import (
    select_best_match,
    fuzzy_test_search,
    smart_test_search
)
from bot.keyboards import (
    get_menu_by_role,
    get_dialog_kb,
    get_back_to_menu_kb,
    get_search_type_kb,
    get_search_type_clarification_kb,
    get_confirmation_kb
)


# LOADING_GIF_ID = (
#     "CgACAgIAAxkBAAMIaGr_qy1Wxaw2VrBrm3dwOAkYji4AAu54AAKmqHlJAtZWBziZvaA2BA"
# )
LOADING_GIF_ID = "CgACAgIAAxkBAAIBFGiBcXtGY7OZvr3-L1dZIBRNqSztAALueAACpqh5Scn4VmIRb4UjNgQ"
# LOADING_GIF_ID = "CgACAgIAAxkBAAMMaHSq3vqxq2RuMMj-DIMvldgDjfkAAu54AAKmqHlJCNcCjeoHRJI2BA"
# –ù–∞–∑–∏–º
# LOADING_GIF_ID = "CgACAgIAAxkBAANPaMvCZEN3F6cNDG58zpcLZnhqiDsAAu54AAKmqHlJU1E65w2DvLo2BA"

questions_router = Router()


class TestCallback:
    @staticmethod
    def pack(action: str, test_code: str) -> str:
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–±–ª–µ–º–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞
        if "AN520" in test_code and "," in test_code:
            test_code = "AN520–ì–ò–≠"
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
        if len(test_code) > 40:
            test_code = test_code[:40]
            
        return f"{action}:{test_code}"

    @staticmethod
    def unpack(callback_data: str) -> Tuple[str, str]:
        parts = callback_data.split(":", 1)
        return parts[0] if len(parts) > 0 else "", parts[1] if len(parts) > 1 else ""

class QuestionStates(StatesGroup):
    waiting_for_search_type = State()
    waiting_for_code = State()
    waiting_for_name = State()
    in_dialog = State()
    processing = State()
    clarifying_search = State()
    confirming_search_type = State()


# –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–æ–∏—Å–∫–∞
class SearchContext:
    def __init__(self):
        self.original_query = ""
        self.search_attempts = []
        self.candidate_tests = []
        self.clarification_step = 0
        self.filters = {}
        
class PaginationCallback:
    """–ö–ª–∞—Å—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å callback –¥–∞–Ω–Ω—ã–º–∏ –ø–∞–≥–∏–Ω–∞—Ü–∏–∏"""
    @staticmethod
    def pack(action: str, page: int, search_id: str) -> str:
        return f"page:{action}:{page}:{search_id}"
    
    @staticmethod
    def unpack(callback_data: str) -> Tuple[str, int, str]:
        parts = callback_data.split(":", 3)
        action = parts[1] if len(parts) > 1 else ""
        page = int(parts[2]) if len(parts) > 2 else 0
        search_id = parts[3] if len(parts) > 3 else ""
        return action, page, search_id


def _rerank_hits_by_query(hits: List[Tuple[Document, float]], query: str) -> List[Tuple[Document, float]]:

    if not hits:
        return hits
    # –í—ã–¥–µ–ª—è–µ–º —Ç–æ–ª—å–∫–æ –±—É–∫–≤—ã –≤ –≤–µ—Ä—Ö–Ω–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ
    query_alpha = "".join(ch for ch in (query or "") if ch.isalpha()).upper()
    if len(query_alpha) < 2 or len(query_alpha) > 6:
        return hits

    rescored: List[Tuple[Document, float]] = []
    for doc, base_score in hits:
        code_upper = str(doc.metadata.get("test_code", "")).upper()
        bonus = 0.0

        if code_upper.startswith(query_alpha):
            bonus += 0.5
        elif query_alpha in code_upper:
            bonus += 0.25
        else:
            if base_score < 0.6:
                bonus -= 0.15

        new_score = max(0.0, min(1.0, base_score + bonus))
        rescored.append((doc, new_score))

    rescored.sort(key=lambda x: x[1], reverse=True)
    return rescored

def create_paginated_keyboard(
    tests: List[Document],
    current_page: int = 0,
    items_per_page: int = 6,
    search_id: str = None
) -> Tuple[InlineKeyboardMarkup, int, int]:
    """
    –°–æ–∑–¥–∞–µ—Ç –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É —Å –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π –¥–ª—è —Å–ø–∏—Å–∫–∞ —Ç–µ—Å—Ç–æ–≤
    
    Returns:
        Tuple[keyboard, total_pages, items_shown]
    """
    total_items = len(tests)
    total_pages = (total_items + items_per_page - 1) // items_per_page
    
    # –í—ã—á–∏—Å–ª—è–µ–º –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è —Ç–µ–∫—É—â–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    start_idx = current_page * items_per_page
    end_idx = min(start_idx + items_per_page, total_items)
    
    keyboard = []
    row = []
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∫–Ω–æ–ø–∫–∏ —Ç–µ—Å—Ç–æ–≤ –¥–ª—è —Ç–µ–∫—É—â–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    for doc in tests[start_idx:end_idx]:
        test_code = doc.metadata.get("test_code", "")
        
        # –°–∞–Ω–∏—Ç–∏–∑–∏—Ä—É–µ–º –∫–æ–¥ –¥–ª—è –∫–Ω–æ–ø–∫–∏
        button_text = sanitize_test_code_for_display(test_code)
        
        row.append(
            InlineKeyboardButton(
                text=button_text,
                callback_data=TestCallback.pack("show_test", test_code)  # pack —Å–∞–º –æ–±—Ä–∞–±–æ—Ç–∞–µ—Ç
            )
        )
        
        if len(row) >= 3:  # –ü–æ 3 –∫–Ω–æ–ø–∫–∏ –≤ —Ä—è–¥
            keyboard.append(row)
            row = []
    
    if row:
        keyboard.append(row)
    
    # –î–æ–±–∞–≤–ª—è–µ–º –Ω–∞–≤–∏–≥–∞—Ü–∏–æ–Ω–Ω—ã–µ –∫–Ω–æ–ø–∫–∏
    nav_row = []
    
    # –ö–Ω–æ–ø–∫–∞ "–ù–∞–∑–∞–¥"
    if current_page > 0:
        nav_row.append(
            InlineKeyboardButton(
                text="‚óÄÔ∏è –ù–∞–∑–∞–¥",
                callback_data=PaginationCallback.pack("prev", current_page - 1, search_id)
            )
        )
    
    # –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü
    nav_row.append(
        InlineKeyboardButton(
            text=f"üìÑ {current_page + 1}/{total_pages}",
            callback_data="ignore"
        )
    )
    
    # –ö–Ω–æ–ø–∫–∞ "–í–ø–µ—Ä–µ–¥"
    if current_page < total_pages - 1:
        nav_row.append(
            InlineKeyboardButton(
                text="–í–ø–µ—Ä–µ–¥ ‚ñ∂Ô∏è",
                callback_data=PaginationCallback.pack("next", current_page + 1, search_id)
            )
        )
    
    if nav_row and total_pages > 1:
        keyboard.append(nav_row)
    
    # –ö–Ω–æ–ø–∫–∞ –∑–∞–∫—Ä—ã—Ç–∏—è
    keyboard.append([
        InlineKeyboardButton(
            text="‚ùå –ó–∞–∫—Ä—ã—Ç—å",
            callback_data="close_keyboard"
        )
    ])
    
    return InlineKeyboardMarkup(inline_keyboard=keyboard), total_pages, end_idx - start_idx

@questions_router.message(F.text == "üîÑ –ù–æ–≤—ã–π –≤–æ–ø—Ä–æ—Å")
async def handle_new_question_in_dialog(message: Message, state: FSMContext):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è –Ω–æ–≤—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ –≤ —Ä–µ–∂–∏–º–µ –¥–∏–∞–ª–æ–≥–∞."""
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Ç–µ—Å—Ç–æ–≤
    data = await state.get_data()
    last_viewed = data.get("last_viewed_test")

    await message.answer(
        "üí° –í–≤–µ–¥–∏—Ç–µ –∫–æ–¥ —Ç–µ—Å—Ç–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä: AN5) –∏–ª–∏ –æ–ø–∏—à–∏—Ç–µ, —á—Ç–æ –≤—ã –∏—â–µ—Ç–µ:",
        reply_markup=get_back_to_menu_kb(),
    )

    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ–¥—Å–∫–∞–∑–∫–∏
    await show_personalized_suggestions(message, state)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ç–æ—Ä–∏—é –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤ –ø—Ä–∏ –ø–µ—Ä–µ—Ö–æ–¥–µ –∫ –Ω–æ–≤–æ–º—É –ø–æ–∏—Å–∫—É
    await state.set_state(QuestionStates.waiting_for_search_type)
    if last_viewed:
        await state.update_data(last_viewed_test=last_viewed)


@questions_router.callback_query(F.data == "new_search")
async def handle_new_search(callback: CallbackQuery, state: FSMContext):
    await callback.answer()

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
    data = await state.get_data()
    last_viewed = data.get("last_viewed_test")

    await callback.message.answer(
        "üí° –í–≤–µ–¥–∏—Ç–µ –∫–æ–¥ —Ç–µ—Å—Ç–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä: AN5) –∏–ª–∏ –æ–ø–∏—à–∏—Ç–µ, —á—Ç–æ –≤—ã –∏—â–µ—Ç–µ:",
        reply_markup=get_back_to_menu_kb(),
    )

    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ–¥—Å–∫–∞–∑–∫–∏
    message = callback.message
    message.from_user = callback.from_user
    await show_personalized_suggestions(message, state)

    await state.set_state(QuestionStates.waiting_for_search_type)
    if last_viewed:
        await state.update_data(last_viewed_test=last_viewed)

@questions_router.callback_query(F.data.startswith("page:"))
async def handle_pagination(callback: CallbackQuery, state: FSMContext):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü"""
    await callback.answer()
    
    action, page, search_id = PaginationCallback.unpack(callback.data)
    
    # –ü–æ–ª—É—á–∞–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞
    data = await state.get_data()
    search_results = data.get(f"search_results_{search_id}", [])
    
    if not search_results:
        await callback.answer("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ —É—Å—Ç–∞—Ä–µ–ª–∏. –í—ã–ø–æ–ª–Ω–∏—Ç–µ –Ω–æ–≤—ã–π –ø–æ–∏—Å–∫.", show_alert=True)
        return
    
    # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    keyboard, total_pages, items_shown = create_paginated_keyboard(
        search_results,
        current_page=page,
        items_per_page=6,
        search_id=search_id
    )
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –¥–ª—è —Ç–µ–∫—É—â–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    start_idx = page * 6
    end_idx = start_idx + items_shown
    
    response = f"üîç <b>–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ (—Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page + 1} –∏–∑ {total_pages}):</b>\n\n"
    
    for i, doc in enumerate(search_results[start_idx:end_idx], start=start_idx + 1):
        test_data = format_test_data(doc.metadata)
        test_code = sanitize_test_code_for_display(test_data["test_code"])
        test_name = html.escape(test_data["test_name"])
        department = html.escape(test_data.get("department", "–ù–µ —É–∫–∞–∑–∞–Ω–æ"))
        
        # –ú–µ—Ç–∫–∞ –¥–ª—è –ø—Ä–æ—Ñ–∏–ª–µ–π
        type_label = "üî¨ –ü—Ä–æ—Ñ–∏–ª—å" if is_profile_test(test_code) else "üß™ –¢–µ—Å—Ç"
        
        link = create_test_link(test_code)
        
        response += (
            f"<b>{i}.</b> {type_label}: <a href='{link}'>{test_code}</a>\n"
            f"üìù {test_name}\n"
            f"üìã {department}\n\n"
        )
    
    response += "\nüí° <i>–ù–∞–∂–º–∏—Ç–µ –Ω–∞ –∫–æ–¥ —Ç–µ—Å—Ç–∞ –∏–ª–∏ –≤—ã–±–µ—Ä–∏—Ç–µ –∏–∑ –∫–Ω–æ–ø–æ–∫ –Ω–∏–∂–µ</i>"
    
    # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
    try:
        await callback.message.edit_text(
            response,
            parse_mode="HTML",
            disable_web_page_preview=True,
            reply_markup=keyboard
        )
    except Exception as e:
        print(f"[ERROR] Failed to update message: {e}")
        await callback.answer("–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏—è", show_alert=True)

@questions_router.callback_query(F.data.startswith("show_container_photos:"))
async def handle_show_container_photos_callback(callback: CallbackQuery):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è –ø–æ–∫–∞–∑–∞ —Ñ–æ—Ç–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤"""
    await callback.answer()
    
    test_code = callback.data.split(":", 1)[1]
    
    try:
        processor = DataProcessor()
        processor.load_vector_store()
        
        results = processor.search_test(filter_dict={"test_code": test_code})
        
        if not results:
            await callback.message.answer("‚ùå –¢–µ—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return
        
        doc = results[0][0] if isinstance(results[0], tuple) else results[0]
        test_data = format_test_data(doc.metadata)
        
        # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü—Ä–æ–≤–µ—Ä—è–µ–º –û–ë–ê –ø–æ–ª—è
        container_types_to_check = []
        
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º primary_container_type (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)
        primary_container = str(test_data.get("primary_container_type", "")).strip()
        if primary_container and primary_container.lower() not in ["–Ω–µ —É–∫–∞–∑–∞–Ω", "–Ω–µ—Ç", "-", ""]:
            primary_container = primary_container.replace('"', "").replace("\n", " ")
            primary_container = " ".join(primary_container.split())
            if "*I*" in primary_container:
                container_types_to_check.extend([ct.strip() for ct in primary_container.split("*I*")])
            else:
                container_types_to_check.append(primary_container)
        
        # –ó–∞—Ç–µ–º –ø—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—ã—á–Ω—ã–π container_type
        container_type_raw = str(test_data.get("container_type", "")).strip()
        if container_type_raw and container_type_raw.lower() not in ["–Ω–µ —É–∫–∞–∑–∞–Ω", "–Ω–µ—Ç", "-", ""]:
            container_type_raw = container_type_raw.replace('"', "").replace("\n", " ")
            container_type_raw = " ".join(container_type_raw.split())
            if "*I*" in container_type_raw:
                container_types_to_check.extend([ct.strip() for ct in container_type_raw.split("*I*")])
            else:
                container_types_to_check.append(container_type_raw)
        
        # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
        container_types_to_check = list(dict.fromkeys(container_types_to_check))
        
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —Ñ–æ—Ç–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤
        found_photos = []
        
        for ct in container_types_to_check:
            ct_normalized = " ".join(word.capitalize() for word in ct.split())
            photo_data = await db.get_container_photo(ct_normalized)
            if photo_data:
                found_photos.append(photo_data["file_id"])

        # –ï—Å–ª–∏ –µ—Å—Ç—å —Ñ–æ—Ç–æ - –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º
        if found_photos:
            message_ids = []

            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤—Å–µ —Ñ–æ—Ç–æ –ø–æ –æ—Ç–¥–µ–ª—å–Ω–æ—Å—Ç–∏
            for i, file_id in enumerate(found_photos):
                is_last = i == len(found_photos) - 1

                if is_last:
                    # –ü–æ—Å–ª–µ–¥–Ω–µ–µ —Ñ–æ—Ç–æ —Å –∫–Ω–æ–ø–∫–æ–π
                    hide_keyboard = InlineKeyboardMarkup(
                        inline_keyboard=[
                            [
                                InlineKeyboardButton(
                                    text="üôà –°–∫—Ä—ã—Ç—å —Ñ–æ—Ç–æ",
                                    callback_data=f"hide_photos:{test_code}:placeholder",
                                )
                            ]
                        ]
                    )

                    sent_msg = await callback.message.answer_photo(
                        photo=file_id, reply_markup=hide_keyboard
                    )
                else:
                    # –û—Å—Ç–∞–ª—å–Ω—ã–µ —Ñ–æ—Ç–æ –±–µ–∑ –∫–Ω–æ–ø–∫–∏
                    sent_msg = await callback.message.answer_photo(photo=file_id)

                message_ids.append(sent_msg.message_id)

            # –û–±–Ω–æ–≤–ª—è–µ–º callback_data –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è —Å–æ –≤—Å–µ–º–∏ ID
            if message_ids:
                hide_keyboard = InlineKeyboardMarkup(
                    inline_keyboard=[
                        [
                            InlineKeyboardButton(
                                text="üôà –°–∫—Ä—ã—Ç—å —Ñ–æ—Ç–æ",
                                callback_data=f"hide_photos:{test_code}:{','.join(map(str, message_ids))}",
                            )
                        ]
                    ]
                )

                # –†–µ–¥–∞–∫—Ç–∏—Ä—É–µ–º –∫–Ω–æ–ø–∫—É –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
                await callback.bot.edit_message_reply_markup(
                    chat_id=callback.message.chat.id,
                    message_id=message_ids[-1],
                    reply_markup=hide_keyboard,
                )

        else:
            await callback.message.answer("‚ùå –§–æ—Ç–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –±–∞–∑–µ")

    except Exception as e:
        print(f"[ERROR] Failed to show container photos: {e}")
        await callback.message.answer("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–æ—Ç–æ")


@questions_router.callback_query(F.data.startswith("hide_photos:"))
async def handle_hide_photos_callback(callback: CallbackQuery):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è —Å–∫—Ä—ã—Ç–∏—è —Ñ–æ—Ç–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤"""
    await callback.answer("–§–æ—Ç–æ —Å–∫—Ä—ã—Ç—ã")

    try:
        # –ü–∞—Ä—Å–∏–º –¥–∞–Ω–Ω—ã–µ: hide_photos:test_code:photo_msg_ids
        parts = callback.data.split(":", 2)
        photo_msg_ids = [int(msg_id) for msg_id in parts[2].split(",")]

        # –£–¥–∞–ª—è–µ–º –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è —Å —Ñ–æ—Ç–æ (–≤–∫–ª—é—á–∞—è –ø–æ—Å–ª–µ–¥–Ω–µ–µ —Å –∫–Ω–æ–ø–∫–æ–π)
        for msg_id in photo_msg_ids:
            try:
                await callback.bot.delete_message(
                    chat_id=callback.message.chat.id, message_id=msg_id
                )
            except:
                pass

    except Exception as e:
        print(f"[ERROR] Failed to hide photos: {e}")
        await callback.answer("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫—Ä—ã—Ç–∏–∏ —Ñ–æ—Ç–æ", show_alert=True)


# –î–æ–±–∞–≤–ª—è–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è –æ–¥–∏–Ω–æ—á–Ω–æ–≥–æ —Ñ–æ—Ç–æ
@questions_router.callback_query(F.data.startswith("hide_single:"))
async def handle_hide_single_photo(callback: CallbackQuery):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è —Å–∫—Ä—ã—Ç–∏—è –æ–¥–∏–Ω–æ—á–Ω–æ–≥–æ —Ñ–æ—Ç–æ —Å –∫–Ω–æ–ø–∫–æ–π"""
    await callback.answer("–§–æ—Ç–æ —Å–∫—Ä—ã—Ç–æ")

    try:
        # –£–¥–∞–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ —Å —Ñ–æ—Ç–æ –∏ –∫–Ω–æ–ø–∫–æ–π
        await callback.message.delete()
    except Exception as e:
        print(f"[ERROR] Failed to hide single photo: {e}")


@questions_router.callback_query(F.data.startswith("hide_photos:"))
async def handle_hide_photos_callback(callback: CallbackQuery):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è —Å–∫—Ä—ã—Ç–∏—è —Ñ–æ—Ç–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤"""
    await callback.answer("–§–æ—Ç–æ —Å–∫—Ä—ã—Ç—ã")  # –¢–æ–ª—å–∫–æ –≤—Å–ø–ª—ã–≤–∞—é—â–µ–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ

    try:
        # –ü–∞—Ä—Å–∏–º –¥–∞–Ω–Ω—ã–µ: hide_photos:test_code:photo_msg_ids
        parts = callback.data.split(":", 2)
        photo_msg_ids = [int(msg_id) for msg_id in parts[2].split(",")]

        for msg_id in photo_msg_ids:
            try:
                await callback.bot.delete_message(
                    chat_id=callback.message.chat.id, message_id=msg_id
                )
            except:
                pass

        try:
            await callback.message.delete()
        except:
            pass

    except Exception as e:
        print(f"[ERROR] Failed to hide photos: {e}")
        # –û—à–∏–±–∫—É –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –≤–æ –≤—Å–ø–ª—ã–≤–∞—é—â–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–∏
        await callback.answer("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫—Ä—ã—Ç–∏–∏ —Ñ–æ—Ç–æ", show_alert=True)


@questions_router.callback_query(F.data == "close_keyboard")
async def handle_close_keyboard(callback: CallbackQuery):
    await callback.answer()
    await callback.message.edit_reply_markup(reply_markup=None)


# –¢–∞–∫–∂–µ –¥–æ–±–∞–≤–∏–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –¥–ª—è callback –∫–Ω–æ–ø–æ–∫, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –±—ã—Ç—å –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã:
@questions_router.callback_query(F.data == "search_by_code")
async def handle_search_by_code_callback(callback: CallbackQuery, state: FSMContext):
    await callback.answer()
    await callback.message.answer(
        "–í–≤–µ–¥–∏—Ç–µ –∫–æ–¥ —Ç–µ—Å—Ç–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, AN5):", reply_markup=get_back_to_menu_kb()
    )
    await state.set_state(QuestionStates.waiting_for_code)


@questions_router.callback_query(F.data == "search_by_name")
async def handle_search_by_name_callback(callback: CallbackQuery, state: FSMContext):
    await callback.answer()
    await callback.message.answer(
        "–í–≤–µ–¥–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –∏–ª–∏ –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–µ—Å—Ç–∞:", reply_markup=get_back_to_menu_kb()
    )
    await state.set_state(QuestionStates.waiting_for_name)


# –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏
@questions_router.callback_query(F.data.startswith("show_test:"))
async def handle_show_test_callback(callback: CallbackQuery, state: FSMContext):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è –ø–æ–∫–∞–∑–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ç–µ—Å—Ç–µ –∏–∑ inline –∫–Ω–æ–ø–∫–∏."""
    action, test_code = TestCallback.unpack(callback.data)

    # –û—Ç–≤–µ—á–∞–µ–º –Ω–∞ callback —á—Ç–æ–±—ã —É–±—Ä–∞—Ç—å "—á–∞—Å–∏–∫–∏"
    await callback.answer()

    try:
        processor = DataProcessor()
        processor.load_vector_store()

        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º —Ç–æ—á–Ω—ã–π –ø–æ–∏—Å–∫
        results = processor.search_test(filter_dict={"test_code": test_code})

        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ - –ø—Ä–æ–±—É–µ–º —Å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π
        if not results:
            normalized_code = normalize_test_code(test_code)
            results = processor.search_test(filter_dict={"test_code": normalized_code})

        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ - –∏—Å–ø–æ–ª—å–∑—É–µ–º fuzzy –ø–æ–∏—Å–∫ —Å –≤—ã—Å–æ–∫–∏–º –ø–æ—Ä–æ–≥–æ–º
        if not results:
            print(
                f"[DEBUG] Test {test_code} not found with exact search. Trying fuzzy..."
            )
            fuzzy_results = await fuzzy_test_search(processor, test_code, threshold=85)

            if fuzzy_results:
                # –ò—â–µ–º —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å—Ä–µ–¥–∏ fuzzy —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                for doc, score in fuzzy_results:
                    if doc.metadata.get("test_code", "").upper() == test_code.upper():
                        results = [(doc, score)]
                        print(
                            f"[DEBUG] Found exact match in fuzzy results: {doc.metadata.get('test_code')}"
                        )
                        break

                # –ï—Å–ª–∏ —Ç–æ—á–Ω–æ–≥–æ –Ω–µ –Ω–∞—à–ª–∏ - –±–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π —Å –≤—ã—Å–æ–∫–∏–º score
                if not results and fuzzy_results[0][1] >= 90:
                    results = [fuzzy_results[0]]
                    print(
                        f"[DEBUG] Using best fuzzy match: {fuzzy_results[0][0].metadata.get('test_code')} (score: {fuzzy_results[0][1]})"
                    )

        # –ü–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞ - —Ç–µ–∫—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫
        if not results:
            print(f"[DEBUG] Trying text search for {test_code}")
            text_results = processor.search_test(query=test_code, top_k=50)

            # –ò—â–µ–º —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∫–æ–¥–∞
            for doc, score in text_results:
                doc_code = doc.metadata.get("test_code", "")
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å —É—á–µ—Ç–æ–º —Ä–µ–≥–∏—Å—Ç—Ä–∞ –∏ –ø—Ä–æ–±–µ–ª–æ–≤
                if doc_code.strip().upper() == test_code.strip().upper():
                    results = [(doc, score)]
                    print(f"[DEBUG] Found via text search: {doc_code}")
                    break

        # –ï—Å–ª–∏ –≤—Å–µ –µ—â–µ –Ω–µ –Ω–∞—à–ª–∏ - –∏—Å–ø–æ–ª—å–∑—É–µ–º smart_test_search
        if not results:
            result, found_variant, match_type = await smart_test_search(
                processor, test_code
            )
            if result:
                results = [result]
                print(
                    f"[DEBUG] Found via smart search: {found_variant} (type: {match_type})"
                )

        if not results:
            print(f"[ERROR] Test {test_code} not found after all attempts")
            await callback.message.answer(f"‚ùå –¢–µ—Å—Ç {test_code} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö")
            return

        doc = results[0][0] if isinstance(results[0], tuple) else results[0]
        test_data = format_test_data(doc.metadata)

        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç
        response = f"<b>–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≤—ã–±—Ä–∞–Ω–Ω–æ–º —Ç–µ—Å—Ç–µ:</b>\n\n"
        response += format_test_info(test_data)

        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        user_id = callback.from_user.id
        await db.add_search_history(
            user_id=user_id,
            search_query=f"–í—ã–±–æ—Ä –∏–∑ —Å–ø–∏—Å–∫–∞: {test_code}",
            found_test_code=test_data["test_code"],
            search_type="code",
            success=True,
        )
        await db.update_user_frequent_test(
            user_id=user_id,
            test_code=test_data["test_code"],
            test_name=test_data["test_name"],
        )

        # –û–±–Ω–æ–≤–ª—è–µ–º —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã
        data = await state.get_data()
        if (
            "last_viewed_test" in data
            and data["last_viewed_test"] != test_data["test_code"]
        ):
            await db.update_related_tests(
                user_id=user_id,
                test_code_1=data["last_viewed_test"],
                test_code_2=test_data["test_code"],
            )

        # --- –ë–ª–æ–∫ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –∑–∞–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω –ø–æ –∑–∞–ø—Ä–æ—Å—É ---
        # # –ü–æ–ª—É—á–∞–µ–º —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        # related_tests = await db.get_user_related_tests(user_id, test_data["test_code"])
        #
        # # –ò—â–µ–º –ø–æ—Ö–æ–∂–∏–µ —Ç–µ—Å—Ç—ã –¥–ª—è —ç—Ç–æ–≥–æ —Ç–µ—Å—Ç–∞
        # similar_tests = await fuzzy_test_search(
        #     processor, test_data["test_code"], threshold=40
        # )
        #
        # # –§–∏–ª—å—Ç—Ä—É–µ–º, —á—Ç–æ–±—ã –Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å —Å–∞–º —Ç–µ—Å—Ç
        # similar_tests = [
        #     (d, s)
        #     for d, s in similar_tests
        #     if d.metadata.get("test_code") != test_data["test_code"]
        # ]
        #
        # # –°–æ–∑–¥–∞–µ–º –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É –µ—Å–ª–∏ –µ—Å—Ç—å –ø–æ—Ö–æ–∂–∏–µ –∏–ª–∏ —Å–≤—è–∑–∞–Ω–Ω—ã–µ
        # reply_markup = None
        # if related_tests or similar_tests:
        #     keyboard = []
        #     row = []
        #
        #     # –°–Ω–∞—á–∞–ª–∞ —Å–≤—è–∑–∞–Ω–Ω—ã–µ –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏ (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)
        #     for related in related_tests[:4]:
        #         row.append(
        #             InlineKeyboardButton(
        #                 text=f"‚≠ê {related['test_code']}",
        #                 callback_data=TestCallback.pack(
        #                     "show_test", related["test_code"]
        #                 ),
        #             )
        #         )
        #         if len(row) >= 2:
        #             keyboard.append(row)
        #             row = []
        #
        #     # –ó–∞—Ç–µ–º –ø–æ—Ö–æ–∂–∏–µ
        #     for doc, _ in similar_tests[:4]:
        #         if len(keyboard) * 2 + len(row) >= 8:  # –ú–∞–∫—Å–∏–º—É–º 8 –∫–Ω–æ–ø–æ–∫
        #             break
        #         code = doc.metadata.get("test_code")
        #         if not any(r["test_code"] == code for r in related_tests):
        #             row.append(
        #                 InlineKeyboardButton(
        #                     text=code,
        #                     callback_data=TestCallback.pack("show_test", code),
        #                 )
        #             )
        #             if len(row) >= 2:
        #                 keyboard.append(row)
        #                 row = []
        #
        #     if row:
        #         keyboard.append(row)
        #
        #     reply_markup = InlineKeyboardMarkup(inline_keyboard=keyboard)
        # --- –ö–æ–Ω–µ—Ü –∑–∞–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –±–ª–æ–∫–∞ ---

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é —Å —Ñ–æ—Ç–æ –¢–û–õ–¨–ö–û –û–î–ò–ù –†–ê–ó
        await send_test_info_with_photo(callback.message, test_data, response)

        # # –ï—Å–ª–∏ –µ—Å—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ - –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –∏—Ö –æ—Ç–¥–µ–ª—å–Ω—ã–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º
        # if reply_markup:
        #     await callback.message.answer(
        #         "üéØ –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º —Ç–∞–∫–∂–µ:", reply_markup=reply_markup
        #     )

        # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å —Ç–µ–∫—É—â–∏–º —Ç–µ—Å—Ç–æ–º
        await state.set_state(QuestionStates.in_dialog)
        await state.update_data(
            current_test=test_data, last_viewed_test=test_data["test_code"]
        )

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è –¥–∏–∞–ª–æ–≥–∞
        await callback.message.answer(
            "–ú–æ–∂–µ—Ç–µ –∑–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å –æ–± —ç—Ç–æ–º —Ç–µ—Å—Ç–µ –∏–ª–∏ –≤—ã–±—Ä–∞—Ç—å –¥–µ–π—Å—Ç–≤–∏–µ:",
            reply_markup=get_dialog_kb()
        )

    except Exception as e:
        print(f"[ERROR] Callback handling failed: {e}")
        import traceback

        traceback.print_exc()
        await callback.message.answer("‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ç–µ—Å—Ç–µ")


@questions_router.callback_query(F.data.startswith("quick_test:"))
async def handle_quick_test_selection(callback: CallbackQuery, state: FSMContext):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –±—ã—Å—Ç—Ä–æ–≥–æ –≤—ã–±–æ—Ä–∞ —Ç–µ—Å—Ç–∞ –∏–∑ –ø–æ–¥—Å–∫–∞–∑–æ–∫"""
    test_code = callback.data.split(":")[1]

    try:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º DataProcessor –Ω–∞–ø—Ä—è–º—É—é –¥–ª—è –ø–æ–∏—Å–∫–∞
        processor = DataProcessor()
        processor.load_vector_store()

        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫–æ–¥ —Ç–µ—Å—Ç–∞
        normalized_code = normalize_test_code(test_code)

        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º —Ç–æ—á–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–º—É –∫–æ–¥—É
        results = processor.search_test(filter_dict={"test_code": normalized_code})

        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ - –ø—Ä–æ–±—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∫–æ–¥
        if not results:
            results = processor.search_test(filter_dict={"test_code": test_code})

        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ - –ø—Ä–æ–±—É–µ–º fuzzy –ø–æ–∏—Å–∫
        if not results:
            print(
                f"[DEBUG] Test {test_code} not found with filter. Trying fuzzy search..."
            )
            fuzzy_results = await fuzzy_test_search(processor, test_code, threshold=90)

            if fuzzy_results:
                # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å –≤—ã—Å–æ–∫–∏–º score
                results = [fuzzy_results[0]]
                print(
                    f"[DEBUG] Found via fuzzy search: {results[0][0].metadata.get('test_code')}"
                )
            else:
                # –ü—Ä–æ–±—É–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫
                print(f"[DEBUG] Trying text search for {test_code}")
                text_results = processor.search_test(query=test_code, top_k=10)

                # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ —Ç–æ—á–Ω–æ–º—É —Å–æ–≤–ø–∞–¥–µ–Ω–∏—é –∫–æ–¥–∞
                for doc, score in text_results:
                    doc_code = doc.metadata.get("test_code", "")
                    if (
                        doc_code.upper() == test_code.upper()
                        or doc_code.upper() == normalized_code.upper()
                    ):
                        results = [(doc, score)]
                        print(f"[DEBUG] Found via text search: {doc_code}")
                        break

        if not results:
            # –ü–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞ - –∏—Å–ø–æ–ª—å–∑—É–µ–º smart_test_search
            result, found_variant, match_type = await smart_test_search(
                processor, test_code
            )
            if result:
                results = [result]
                print(
                    f"[DEBUG] Found via smart search: {found_variant} (type: {match_type})"
                )

        if not results:
            print(f"[ERROR] Test {test_code} not found after all attempts")
            await callback.message.answer(f"‚ùå –¢–µ—Å—Ç {test_code} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö")
            await callback.answer()
            return

        doc = results[0][0] if isinstance(results[0], tuple) else results[0]
        test_data = format_test_data(doc.metadata)

        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        response = f"<b>–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≤—ã–±—Ä–∞–Ω–Ω–æ–º —Ç–µ—Å—Ç–µ:</b>\n\n"
        response += format_test_info(test_data)

        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        user_id = callback.from_user.id
        await db.add_search_history(
            user_id=user_id,
            search_query=f"–ë—ã—Å—Ç—Ä—ã–π –≤—ã–±–æ—Ä: {test_code}",
            found_test_code=test_data["test_code"],
            search_type="code",
            success=True,
        )
        await db.update_user_frequent_test(
            user_id=user_id,
            test_code=test_data["test_code"],
            test_name=test_data["test_name"],
        )

        # –û–±–Ω–æ–≤–ª—è–µ–º —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã
        data = await state.get_data()
        if (
            "last_viewed_test" in data
            and data["last_viewed_test"] != test_data["test_code"]
        ):
            await db.update_related_tests(
                user_id=user_id,
                test_code_1=data["last_viewed_test"],
                test_code_2=test_data["test_code"],
            )

        # --- –ë–ª–æ–∫ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –∑–∞–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω –ø–æ –∑–∞–ø—Ä–æ—Å—É ---
        # # –ü–æ–ª—É—á–∞–µ–º —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        # related_tests = await db.get_user_related_tests(user_id, test_data["test_code"])
        #
        # # –ò—â–µ–º –ø–æ—Ö–æ–∂–∏–µ —Ç–µ—Å—Ç—ã –¥–ª—è —ç—Ç–æ–≥–æ —Ç–µ—Å—Ç–∞
        # similar_tests = await fuzzy_test_search(
        #     processor, test_data["test_code"], threshold=40
        # )
        #
        # # –§–∏–ª—å—Ç—Ä—É–µ–º, —á—Ç–æ–±—ã –Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å —Å–∞–º —Ç–µ—Å—Ç
        # similar_tests = [
        #     (d, s)
        #     for d, s in similar_tests
        #     if d.metadata.get("test_code") != test_data["test_code"]
        # ]
        #
        # # –°–æ–∑–¥–∞–µ–º –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É –µ—Å–ª–∏ –µ—Å—Ç—å –ø–æ—Ö–æ–∂–∏–µ –∏–ª–∏ —Å–≤—è–∑–∞–Ω–Ω—ã–µ
        # reply_markup = None
        # if related_tests or similar_tests:
        #     keyboard = []
        #     row = []
        #
        #     # –°–Ω–∞—á–∞–ª–∞ —Å–≤—è–∑–∞–Ω–Ω—ã–µ –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏ (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)
        #     for related in related_tests[:4]:
        #         row.append(
        #             InlineKeyboardButton(
        #                 text=f"‚≠ê {related['test_code']}",
        #                 callback_data=TestCallback.pack(
        #                     "show_test", related["test_code"]
        #                 ),
        #             )
        #         )
        #         if len(row) >= 2:
        #             keyboard.append(row)
        #             row = []
        #
        #     # –ó–∞—Ç–µ–º –ø–æ—Ö–æ–∂–∏–µ
        #     for doc, _ in similar_tests[:4]:
        #         if len(keyboard) * 2 + len(row) >= 8:  # –ú–∞–∫—Å–∏–º—É–º 8 –∫–Ω–æ–ø–æ–∫
        #             break
        #         code = doc.metadata.get("test_code")
        #         if not any(r["test_code"] == code for r in related_tests):
        #             row.append(
        #                 InlineKeyboardButton(
        #                     text=code,
        #                     callback_data=TestCallback.pack("show_test", code),
        #                 )
        #             )
        #             if len(row) >= 2:
        #                 keyboard.append(row)
        #                 row = []
        #
        #     if row:
        #         keyboard.append(row)
        #
        #     reply_markup = InlineKeyboardMarkup(inline_keyboard=keyboard)
        # --- –ö–æ–Ω–µ—Ü –∑–∞–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –±–ª–æ–∫–∞ ---

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é —Å —Ñ–æ—Ç–æ –¢–û–õ–¨–ö–û –û–î–ò–ù –†–ê–ó
        await send_test_info_with_photo(callback.message, test_data, response)

        # # –ï—Å–ª–∏ –µ—Å—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ - –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –∏—Ö –æ—Ç–¥–µ–ª—å–Ω—ã–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º
        # if reply_markup:
        #     await callback.message.answer(
        #         "üéØ –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º —Ç–∞–∫–∂–µ:", reply_markup=reply_markup
        #     )

        # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å —Ç–µ–∫—É—â–∏–º —Ç–µ—Å—Ç–æ–º
        await state.set_state(QuestionStates.in_dialog)
        await state.update_data(
            current_test=test_data, last_viewed_test=test_data["test_code"]
        )

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è –¥–∏–∞–ª–æ–≥–∞
        await callback.message.answer(
            "–ú–æ–∂–µ—Ç–µ –∑–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å –æ–± —ç—Ç–æ–º —Ç–µ—Å—Ç–µ –∏–ª–∏ –≤—ã–±—Ä–∞—Ç—å –¥–µ–π—Å—Ç–≤–∏–µ:",
            reply_markup=get_dialog_kb()
        )

    except Exception as e:
        print(f"[ERROR] Quick test selection failed: {e}")
        import traceback

        traceback.print_exc()
        await callback.message.answer("‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ç–µ—Å—Ç–µ")

    await callback.answer()  # –ó–∞–∫—Ä—ã–≤–∞–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –Ω–∞–∂–∞—Ç–∏–∏


@questions_router.callback_query(F.data == "ignore")
async def handle_ignore_callback(callback: CallbackQuery):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã—Ö –∫–Ω–æ–ø–æ–∫"""
    await callback.answer()


@questions_router.message(F.text == "üî¨ –ó–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç—É")
async def start_question(message: Message, state: FSMContext):
    """–ù–∞—á–∞–ª–æ –¥–∏–∞–ª–æ–≥–∞ —Å –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–º –±–µ–∑ –≤—ã–±–æ—Ä–∞ —Ç–∏–ø–∞ –ø–æ–∏—Å–∫–∞."""
    user_id = message.from_user.id
    user = await db.get_user(user_id)

    if not user:
        await message.answer(
            "–î–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —ç—Ç–æ–π —Ñ—É–Ω–∫—Ü–∏–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –ø—Ä–æ–π—Ç–∏ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—é.\n–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–æ–º–∞–Ω–¥—É /start"
        )
        return

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é
    user_name = get_user_first_name(user)

    prompt = f"""–ü—Ä–∏–≤–µ—Ç, {user_name} üëã

üî¨ –Ø –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –≤–µ—Ç–µ—Ä–∏–Ω–∞—Ä–Ω–æ–π –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–∏–∏ VetUnion –∏ –ø–æ–º–æ–≥—É –≤–∞–º –Ω–∞–π—Ç–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ:

üìã <b>–õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω—ã—Ö —Ç–µ—Å—Ç–∞—Ö –∏ –∞–Ω–∞–ª–∏–∑–∞—Ö:</b>
‚Ä¢ –ü–æ –∫–æ–¥—É —Ç–µ—Å—Ç–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä: AN116, –∞–Ω116, –ê–ù116 –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ 116)
‚Ä¢ –ü–æ –Ω–∞–∑–≤–∞–Ω–∏—é –∏–ª–∏ –æ–ø–∏—Å–∞–Ω–∏—é (–Ω–∞–ø—Ä–∏–º–µ—Ä: "–æ–±—â–∏–π –∞–Ω–∞–ª–∏–∑ –∫—Ä–æ–≤–∏", "–±–∏–æ—Ö–∏–º–∏—è")
‚Ä¢ –ü–æ –ø—Ä–æ—Ñ–∏–ª—è–º —Ç–µ—Å—Ç–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä: "–ø—Ä–æ—Ñ–∏–ª–∏ –±–∏–æ—Ö–∏–º–∏—è")

üß™ <b>–ü—Ä–µ–∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏—Ö —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è—Ö:</b>
‚Ä¢ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø–∞—Ü–∏–µ–Ω—Ç–∞
‚Ä¢ –ü—Ä–∞–≤–∏–ª–∞ –≤–∑—è—Ç–∏—è –±–∏–æ–º–∞—Ç–µ—Ä–∏–∞–ª–∞
‚Ä¢ –£—Å–ª–æ–≤–∏—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∏ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏
‚Ä¢ –¢–∏–ø—ã –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤ –¥–ª—è –ø—Ä–æ–±

üí° <b>–ö–∞–∫ –º–Ω–µ –∑–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å:</b>
‚Ä¢ –í–≤–µ–¥–∏—Ç–µ –∫–æ–¥ —Ç–µ—Å—Ç–∞: <code>AN116</code> –∏–ª–∏ <code>116</code>
‚Ä¢ –û–ø–∏—à–∏—Ç–µ, —á—Ç–æ –∏—â–µ—Ç–µ: "–∞–Ω–∞–ª–∏–∑ –Ω–∞ –≥–ª—é–∫–æ–∑—É"
‚Ä¢ –î–ª—è –ø–æ–∏—Å–∫–∞ –ø—Ä–æ—Ñ–∏–ª–µ–π –¥–æ–±–∞–≤—å—Ç–µ —Å–ª–æ–≤–æ "–ø—Ä–æ—Ñ–∏–ª–∏"

–Ø –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—é —Ç–∏–ø –≤–∞—à–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ –∏ –Ω–∞–π–¥—É –Ω—É–∂–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é.

‚úèÔ∏è –ü—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏—Ç–µ –≤–∞—à –≤–æ–ø—Ä–æ—Å –∏–ª–∏ –∫–æ–¥ —Ç–µ—Å—Ç–∞:"""

    await db.clear_buffer(user_id)
    await message.answer(prompt, reply_markup=get_back_to_menu_kb())

    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ–¥—Å–∫–∞–∑–∫–∏
    await show_personalized_suggestions(message, state)

    await state.set_state(QuestionStates.waiting_for_search_type)


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —Ö–µ–Ω–¥–ª–µ—Ä –¥–ª—è –∫–Ω–æ–ø–∫–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –¥–∏–∞–ª–æ–≥–∞ (—Ä–∞–±–æ—Ç–∞–µ—Ç –≤ –ª—é–±–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏)
@questions_router.message(F.text == "‚ùå –ó–∞–≤–µ—Ä—à–∏—Ç—å –¥–∏–∞–ª–æ–≥")
async def handle_end_dialog(message: Message, state: FSMContext):
    current_state = await state.get_state()
    user = await db.get_user(message.from_user.id)

    # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ role
    if user:
        try:
            role = user["role"] if user["role"] else "user"
        except (KeyError, TypeError):
            role = "user"
    else:
        role = "user"

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é
    user_name = get_user_first_name(user)

    # –ò—Å–∫–ª—é—á–µ–Ω–∏–µ: –µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–∞–∂–∞–ª "–∑–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç—É" –∏ –Ω–µ –≤–≤–µ–ª –≤–æ–ø—Ä–æ—Å
    if current_state == QuestionStates.waiting_for_search_type:
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –≤ –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é
        await state.clear()
        farewell = get_time_based_farewell(user_name)
        await message.answer(farewell, reply_markup=get_menu_by_role(role))
        return

    # –í–æ –≤—Å–µ—Ö –æ—Å—Ç–∞–ª—å–Ω—ã—Ö —Å–ª—É—á–∞—è—Ö –∑–∞–≤–µ—Ä—à–∞–µ–º –¥–∏–∞–ª–æ–≥
    await state.clear()
    farewell = get_time_based_farewell(user_name)
    await message.answer(farewell, reply_markup=get_menu_by_role(role))
    return


# –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è —Å—Ç–∞—Ä–æ–π –∫–Ω–æ–ø–∫–∏ (–¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
@questions_router.message(F.text == "üîô –í–µ—Ä–Ω—É—Ç—å—Å—è –≤ –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é")
async def handle_back_to_menu_legacy(message: Message, state: FSMContext):
    await state.clear()
    user = await db.get_user(message.from_user.id)
    role = user["role"] if "role" in user.keys() else "staff"
    await message.answer("–û–ø–µ—Ä–∞—Ü–∏—è –æ—Ç–º–µ–Ω–µ–Ω–∞.", reply_markup=get_menu_by_role(role))
    return


@questions_router.message(QuestionStates.waiting_for_search_type)
async def handle_universal_search(message: Message, state: FSMContext):
    """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –∑–∞–ø—Ä–æ—Å–æ–≤ - –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø –ø–æ–∏—Å–∫–∞."""
    text = message.text.strip()
    user_id = message.from_user.id

    if text == "üîÑ –ù–æ–≤—ã–π –≤–æ–ø—Ä–æ—Å":
        await handle_new_question_in_dialog(message, state)
        return

    expanded_query = expand_query_with_abbreviations(text)
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –∫–Ω–æ–ø–∫–∞ –ª–∏ —ç—Ç–æ –≤–æ–∑–≤—Ä–∞—Ç–∞
    if text == "üîô –í–µ—Ä–Ω—É—Ç—å—Å—è –≤ –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é" or text == "‚ùå –ó–∞–≤–µ—Ä—à–∏—Ç—å –¥–∏–∞–ª–æ–≥":
        return

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–∞ –∑–∞–ø—Ä–æ—Å–∞
    query_type, confidence, metadata = await ultimate_classifier.classify_with_certainty(expanded_query)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
    await state.update_data(
        query_classification={
            "type": query_type,
            "confidence": confidence,
            "metadata": metadata,
            "original_query": text
        }
    )

    # –ï—Å–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤—ã—Å–æ–∫–∞—è (>0.85) - —Å—Ä–∞–∑—É –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º
    if confidence > 0.85:
        await _process_confident_query(message, state, query_type, text, metadata)
    else:
        # –ï—Å–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å —Å—Ä–µ–¥–Ω—è—è (0.7-0.85) - –ø—Ä–æ—Å–∏–º –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ
        await _ask_confirmation(message, state, query_type, expanded_query, confidence)

    # –ï—Å–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –Ω–∏–∑–∫–∞—è (<0.7) - –∏—Å–ø–æ–ª—å–∑—É–µ–º LLM –¥–ª—è —É—Ç–æ—á–Ω–µ–Ω–∏—è
    if confidence < 0.7:
        await _clarify_with_llm(message, state, expanded_query, query_type, confidence)

async def _process_confident_query(message: Message, state: FSMContext, query_type: str, text: str, metadata: Dict):
    user_id = message.from_user.id
    expanded_query = expand_query_with_abbreviations(text)
    
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª—è –ø—Ä–æ—Ñ–∏–ª–µ–π
    profile_keywords = ['–æ–±—Å', '–ø—Ä–æ—Ñ–∏–ª–∏', '–ø—Ä–æ—Ñ–∏–ª—å', '–∫–æ–º–ø–ª–µ–∫—Å—ã', '–∫–æ–º–ø–ª–µ–∫—Å', '–ø–∞–Ω–µ–ª–∏', '–ø–∞–Ω–µ–ª—å']
    should_show_profiles = any(keyword in text.lower() for keyword in profile_keywords)
    
    if should_show_profiles:
        print(f"[PROFILES] Detected profile keywords, setting show_profiles=True")
        await state.update_data(show_profiles=True)
    
    if any(keyword in text.lower() for keyword in profile_keywords):
        query_type = "profile"
        print(f"[PROFILE DETECTED] Changed query_type to 'profile' for text: {text}")  # –î–û–ë–ê–í–¨–¢–ï –≠–¢–û

    if query_type == "code":
        await state.set_state(QuestionStates.waiting_for_code)
        await handle_code_search_with_text(message, state, expanded_query)
    elif query_type == "name":
        await state.set_state(QuestionStates.waiting_for_name)
        await handle_name_search_with_text(message, state, expanded_query)
    elif query_type == "profile":
        # –î–û–ë–ê–í–¨–¢–ï –î–ò–ê–ì–ù–û–°–¢–ò–ö–£
        print(f"[PROFILE BRANCH] Setting show_profiles=True for query: {text}")
        await state.update_data(show_profiles=True)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–∏–ª–æ—Å—å
        check_data = await state.get_data()
        print(f"[PROFILE BRANCH] State after update: show_profiles={check_data.get('show_profiles')}")
        
        await state.set_state(QuestionStates.waiting_for_name)
        await handle_name_search_with_text(message, state, expanded_query)
    else:  # general
        await db.add_request_stat(
            user_id=user_id, request_type="question", request_text=text
        )
        await handle_general_question(message, state, expanded_query)

async def _ask_confirmation(message: Message, state: FSMContext, query_type: str, text: str, confidence: float):
    """–ó–∞–ø—Ä–æ—Å –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è —Ç–∏–ø–∞ –ø–æ–∏—Å–∫–∞"""
    type_descriptions = {
        "code": "–ø–æ–∏—Å–∫ –ø–æ –∫–æ–¥—É —Ç–µ—Å—Ç–∞",
        "name": "–ø–æ–∏—Å–∫ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é —Ç–µ—Å—Ç–∞",
        "profile": "–ø–æ–∏—Å–∫ –ø—Ä–æ—Ñ–∏–ª—è —Ç–µ—Å—Ç–æ–≤",
        "general": "–æ–±—â–∏–π –≤–æ–ø—Ä–æ—Å"
    }

    confirmation_text = (
        f"ü§î –Ø –ø–æ–Ω—è–ª –≤–∞—à –∑–∞–ø—Ä–æ—Å –∫–∞–∫ <b>{type_descriptions[query_type]}</b> "
        f"(—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.0%}).\n\n"
        f"–≠—Ç–æ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ç–∏–ø –ø–æ–∏—Å–∫–∞?"
    )

    await message.answer(
        confirmation_text,
        parse_mode="HTML",
        reply_markup=get_confirmation_kb()
    )
    await state.set_state(QuestionStates.confirming_search_type)

async def _clarify_with_llm(message: Message, state: FSMContext, text: str, initial_type: str, confidence: float):
    clarification_text = (
        f"üîç –Ø –Ω–µ —Å–æ–≤—Å–µ–º —É–≤–µ—Ä–µ–Ω, —á—Ç–æ –≤—ã –∏—â–µ—Ç–µ.\n\n"
        f"–í–∞—à –∑–∞–ø—Ä–æ—Å: <b>{html.escape(text)}</b>\n\n"
        f"–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ —Ç–∏–ø –ø–æ–∏—Å–∫–∞:"
    )

    await message.answer(
        clarification_text,
        parse_mode="HTML",
        reply_markup=get_search_type_clarification_kb()
    )
    await state.set_state(QuestionStates.clarifying_search)


@questions_router.message(QuestionStates.confirming_search_type)
async def handle_search_confirmation(message: Message, state: FSMContext):
    user_id = message.from_user.id

    text = message.text.strip()
    data = await state.get_data()
    classification = data.get("query_classification", {})

    if text == "‚úÖ –î–∞":
        # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø–æ–¥—Ç–≤–µ—Ä–¥–∏–ª - –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∑–∞–ø—Ä–æ—Å
        query_type = classification.get("type", "general")
        original_query = classification.get("original_query", "")
        expanded_query = expand_query_with_abbreviations(original_query)

        # –£–±–∏—Ä–∞–µ–º –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è
        await message.answer("‚úÖ –ü—Ä–∏–Ω—è—Ç–æ! –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å...", reply_markup=get_dialog_kb())

        if query_type == "code":
            await state.set_state(QuestionStates.waiting_for_code)
            await handle_code_search_with_text(message, state, original_query)
        elif query_type == "name":
            await state.set_state(QuestionStates.waiting_for_name)
            await handle_name_search_with_text(message, state, expanded_query)
        elif query_type == "profile":
            await state.update_data(show_profiles=True)
            await state.set_state(QuestionStates.waiting_for_name)
            await handle_name_search_with_text(message, state, expanded_query)
        else:
            await db.add_request_stat(
                user_id=user_id, request_type="question", request_text=text
            )
            await handle_general_question(message, state, expanded_query)

    elif text == "‚ùå –ù–µ—Ç":
        # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –ø–æ–¥—Ç–≤–µ—Ä–¥–∏–ª - –ø—Ä–µ–¥–ª–∞–≥–∞–µ–º –≤—ã–±—Ä–∞—Ç—å —Ç–∏–ø
        await message.answer("‚ùå –ü–æ–Ω—è—Ç–Ω–æ! –£—Ç–æ—á–Ω–∏—Ç–µ —Ç–∏–ø –ø–æ–∏—Å–∫–∞:", reply_markup=get_dialog_kb())

        await state.set_state(QuestionStates.clarifying_search)

        await _clarify_with_llm(
            message, state,
            classification.get("original_query", ""),
            classification.get("type", "general"),
            classification.get("confidence", 0.5)
        )

    elif text == "‚ùå –ó–∞–≤–µ—Ä—à–∏—Ç—å –¥–∏–∞–ª–æ–≥":
        await handle_end_dialog(message, state)
    else:
        await message.answer("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–Ω–æ–ø–∫–∏ –¥–ª—è –æ—Ç–≤–µ—Ç–∞.")



@questions_router.message(QuestionStates.clarifying_search, F.text)
async def handle_text_input_during_clarification(message: Message, state: FSMContext):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –≤–≤–æ–¥–∞ –≤–æ –≤—Ä–µ–º—è —É—Ç–æ—á–Ω–µ–Ω–∏—è —Ç–∏–ø–∞ –ø–æ–∏—Å–∫–∞"""
    text = message.text.strip()

    # –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤–≤–µ–ª —Ç–µ–∫—Å—Ç –≤–º–µ—Å—Ç–æ –≤—ã–±–æ—Ä–∞ –∫–Ω–æ–ø–∫–∏, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∫ –Ω–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
    if text and text not in ["üî¢ –ü–æ–∏—Å–∫ –ø–æ –∫–æ–¥—É —Ç–µ—Å—Ç–∞", "üìù –ü–æ–∏—Å–∫ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é",
                           "üî¨ –ü–æ–∏—Å–∫ –ø—Ä–æ—Ñ–∏–ª—è —Ç–µ—Å—Ç–æ–≤", "‚ùì –û–±—â–∏–π –≤–æ–ø—Ä–æ—Å", "‚ùå –ó–∞–≤–µ—Ä—à–∏—Ç—å –¥–∏–∞–ª–æ–≥"]:

        # –û—á–∏—â–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ —É—Ç–æ—á–Ω–µ–Ω–∏—è
        await state.set_state(QuestionStates.waiting_for_search_type)

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∫ –Ω–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
        await handle_universal_search(message, state)
    else:
        # –ï—Å–ª–∏ —ç—Ç–æ –æ–¥–Ω–∞ –∏–∑ –∫–Ω–æ–ø–æ–∫, –ø–µ—Ä–µ–¥–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –æ—Å–Ω–æ–≤–Ω–æ–º—É –æ–±—Ä–∞–±–æ—Ç—á–∏–∫—É
        await handle_search_clarification(message, state)

@questions_router.message(QuestionStates.clarifying_search)
async def handle_search_clarification(message: Message, state: FSMContext):
    user_id = message.from_user.id

    text = message.text.strip()
    data = await state.get_data()
    original_query = data.get("query_classification", {}).get("original_query", "")
    expanded_query = expand_query_with_abbreviations(original_query)


    if text == "üî¢ –ü–æ–∏—Å–∫ –ø–æ –∫–æ–¥—É —Ç–µ—Å—Ç–∞":
        await message.answer("‚úÖ –ò—â—É –ø–æ –∫–æ–¥—É...", reply_markup=get_dialog_kb())
        await state.set_state(QuestionStates.waiting_for_code)
        await handle_code_search_with_text(message, state, original_query)
    elif text == "üìù –ü–æ–∏—Å–∫ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é":
        await message.answer("‚úÖ –ò—â—É –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é...", reply_markup=get_dialog_kb())
        await state.set_state(QuestionStates.waiting_for_name)
        await handle_name_search_with_text(message, state, expanded_query)
    elif text == "üî¨ –ü–æ–∏—Å–∫ –ø—Ä–æ—Ñ–∏–ª—è —Ç–µ—Å—Ç–æ–≤":
        await message.answer("‚úÖ –ò—â—É –ø—Ä–æ—Ñ–∏–ª–∏ —Ç–µ—Å—Ç–æ–≤...", reply_markup=get_dialog_kb())

        await state.update_data(show_profiles=True)
        await state.set_state(QuestionStates.waiting_for_name)
        await handle_name_search_with_text(message, state, expanded_query)
    elif text == "‚ùì –û–±—â–∏–π –≤–æ–ø—Ä–æ—Å":
        await db.add_request_stat(
            user_id=user_id, request_type="question", request_text=text
        )
        await message.answer("‚úÖ –û—Ç–≤–µ—á–∞—é –Ω–∞ –≤–æ–ø—Ä–æ—Å...", reply_markup=get_dialog_kb())
        await handle_general_question(message, state, expanded_query)
    elif text == "‚ùå –ó–∞–≤–µ—Ä—à–∏—Ç—å –¥–∏–∞–ª–æ–≥":
        await handle_end_dialog(message, state)
    else:
        await message.answer("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ —Ç–∏–ø –ø–æ–∏—Å–∫–∞ –∏–∑ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω—ã—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤.")


@questions_router.message(QuestionStates.in_dialog, F.text == "üì∑ –ü–æ–∫–∞–∑–∞—Ç—å –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä")
async def handle_show_container_photo(message: Message, state: FSMContext):
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ñ–æ—Ç–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ —Ç–µ—Å—Ç–∞."""
    data = await state.get_data()
    test_data = data.get("current_test")

    if not test_data:
        await message.answer("‚ùå –°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ —Ç–µ—Å—Ç")
        return


@questions_router.message(QuestionStates.waiting_for_name)
async def handle_name_search(message: Message, state: FSMContext):
    """Handle test name search using RAG."""
    await _handle_name_search_internal(message, state)


@questions_router.message(QuestionStates.in_dialog)
async def handle_dialog(message: Message, state: FSMContext):
    text = message.text.strip()
    user_id = message.from_user.id

    if text == "üîÑ –ù–æ–≤—ã–π –≤–æ–ø—Ä–æ—Å":
        await handle_new_question_in_dialog(message, state)
        return

    data = await state.get_data()
    test_data = data.get("current_test")

    expanded_query = expand_query_with_abbreviations(text)
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–∞ –Ω–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
    query_type, confidence, metadata = await ultimate_classifier.classify_with_certainty(expanded_query)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–µ–Ω –ª–∏ –Ω–æ–≤—ã–π –ø–æ–∏—Å–∫ (–Ω–µ –æ–±—â–∏–π –≤–æ–ø—Ä–æ—Å –æ —Ç–µ–∫—É—â–µ–º —Ç–µ—Å—Ç–µ)
    needs_new_search = await _should_initiate_new_search(expanded_query, test_data, query_type, confidence)

    if needs_new_search:
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–∏—Ö —à–∞–≥–æ–≤
        await state.update_data(
            query_classification={
                "type": query_type,
                "confidence": confidence,
                "metadata": metadata,
                "original_query": text
            }
        )

        # –í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å ‚Äî —Å—Ä–∞–∑—É –º–∞—Ä—à—Ä—É—Ç–∏–∑–∏—Ä—É–µ–º
        if confidence > 0.85:
            await _process_confident_query(message, state, query_type, expanded_query, metadata)
        else:
            # –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å ‚Äî —Å–ø—Ä–æ—Å–∏—Ç—å –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ
            await _ask_confirmation(message, state, query_type, expanded_query, confidence)
            # –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å ‚Äî –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ —É—Ç–æ—á–Ω–µ–Ω–∏–µ —á–µ—Ä–µ–∑ LLM
            if confidence < 0.7:
                await _clarify_with_llm(message, state, expanded_query, query_type, confidence)
        return

    # –í–æ–ø—Ä–æ—Å –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ —Ç–µ–∫—É—â–µ–º—É —Ç–µ—Å—Ç—É ‚Äî –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ, –æ—Å—Ç–∞—ë–º—Å—è –≤ in_dialog
    await _handle_contextual_question(message, state, expanded_query, test_data)


async def _should_initiate_new_search(text: str, current_test_data: Dict, query_type: str, confidence: float) -> bool:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –Ω—É–∂–Ω–æ –ª–∏ –Ω–∞—á–∏–Ω–∞—Ç—å –Ω–æ–≤—ã–π –ø–æ–∏—Å–∫"""
    if not current_test_data:
        return True

    # –ï—Å–ª–∏ –∑–∞–ø—Ä–æ—Å —è–≤–Ω–æ —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ –Ω–æ–≤—ã–π –ø–æ–∏—Å–∫
    if query_type != "general" and confidence > 0.7:
        return True

    # –≠–≤—Ä–∏—Å—Ç–∏–∫–∏ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –Ω–æ–≤–æ–≥–æ –ø–æ–∏—Å–∫–∞
    text_lower = text.lower()

    # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞, —É–∫–∞–∑—ã–≤–∞—é—â–∏–µ –Ω–∞ –Ω–æ–≤—ã–π –ø–æ–∏—Å–∫
    new_search_keywords = [
        '–Ω–∞–π–¥–∏', '–∏—â–∏', '–ø–æ–∫–∞–∂–∏', '–ø–æ–∏—Å–∫', '–Ω–∞–π—Ç–∏',
        '–¥—Ä—É–≥–æ–π', '–µ—â–µ', '—Å–ª–µ–¥—É—é—â–∏–π', '–∏–Ω–æ–π',
        '–∫–æ–¥', '—Ç–µ—Å—Ç', '–∞–Ω–∞–ª–∏–∑', '–ø—Ä–æ—Ñ–∏–ª—å'
    ]

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ –∑–∞–ø—Ä–æ—Å —É–∫–∞–∑–∞–Ω–∏–µ –Ω–∞ –Ω–æ–≤—ã–π –ø–æ–∏—Å–∫
    has_search_intent = any(keyword in text_lower for keyword in new_search_keywords)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è –ª–∏ –∫–æ–¥ –¥—Ä—É–≥–æ–≥–æ —Ç–µ—Å—Ç–∞
    has_other_code = await _contains_other_test_code(text, current_test_data.get("test_code", ""))

    return has_search_intent or has_other_code

async def _contains_other_test_code(text: str, current_test_code: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ —Ç–µ–∫—Å—Ç –∫–æ–¥ –¥—Ä—É–≥–æ–≥–æ —Ç–µ—Å—Ç–∞"""
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤—Å–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ –∫–æ–¥—ã —Ç–µ—Å—Ç–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–∞
    code_patterns = [
        r'[A–ê][N–ù]\d+[A-Z–ê-–Ø\-]*',
        r'\b\d+[A-Z–ê-–Ø\-]*',
        r'[A-Z–ê-–Ø]+\d+[A-Z–ê-–Ø\-]*',
    ]

    found_codes = set()
    for pattern in code_patterns:
        matches = re.findall(pattern, text, re.IGNORECASE)
        for match in matches:
            normalized = normalize_test_code(match)
            if normalized and normalized != current_test_code:
                found_codes.add(normalized)

    return len(found_codes) > 0

async def _ask_dialog_clarification(message: Message, state: FSMContext, text: str, query_type: str, confidence: float):
    """–ó–∞–ø—Ä–æ—Å —É—Ç–æ—á–Ω–µ–Ω–∏—è –≤ —Ä–µ–∂–∏–º–µ –¥–∏–∞–ª–æ–≥–∞"""
    clarification_text = (
        f"üîç –í—ã —Ö–æ—Ç–∏—Ç–µ –∑–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å –æ —Ç–µ–∫—É—â–µ–º —Ç–µ—Å—Ç–µ –∏–ª–∏ –Ω–∞—á–∞—Ç—å –Ω–æ–≤—ã–π –ø–æ–∏—Å–∫?\n\n"
        f"–ó–∞–ø—Ä–æ—Å: <b>{html.escape(text)}</b>"
    )

    keyboard = InlineKeyboardMarkup(
        keyboard=[
            [InlineKeyboardButton(text="‚ùì –í–æ–ø—Ä–æ—Å –æ —Ç–µ–∫—É—â–µ–º —Ç–µ—Å—Ç–µ")],
            [InlineKeyboardButton(text="üîç –ù–æ–≤—ã–π –ø–æ–∏—Å–∫")],
            [InlineKeyboardButton(text="‚ùå –ó–∞–≤–µ—Ä—à–∏—Ç—å –¥–∏–∞–ª–æ–≥")]
        ],
        resize_keyboard=True
    )

    await message.answer(clarification_text, parse_mode="HTML", reply_markup=keyboard)
    await state.set_state(QuestionStates.clarifying_search)

async def _handle_contextual_question(message: Message, state: FSMContext, question: str, test_data: Dict):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–æ–ø—Ä–æ—Å–∞ –æ —Ç–µ–∫—É—â–µ–º —Ç–µ—Å—Ç–µ"""
    if not test_data:
        await message.answer("–ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ—Ç–µ—Ä—è–Ω. –ó–∞–¥–∞–π—Ç–µ –Ω–æ–≤—ã–π –≤–æ–ø—Ä–æ—Å.")
        await state.set_state(QuestionStates.waiting_for_search_type)
        return

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ —á–µ—Ä–µ–∑ LLM —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º —Ç–µ–∫—É—â–µ–≥–æ —Ç–µ—Å—Ç–∞
    gif_msg = None
    loading_msg = None
    animation_task = None

    try:
        # –ü–æ–∫–∞–∑ –∑–∞–≥—Ä—É–∑–∫–∏ (–Ω–µ –ø–∞–¥–∞–µ–º, –µ—Å–ª–∏ GIF –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω)
        try:
            gif_msg = await message.answer_animation(LOADING_GIF_ID, caption="")
        except Exception:
            gif_msg = None
        loading_msg = await message.answer("–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –≤–∞—à –≤–æ–ø—Ä–æ—Å...")
        animation_task = asyncio.create_task(animate_loading(loading_msg))

        system_msg = SystemMessage(
            content=f"""
            –¢—ã - –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–∏–∏ VetUnion –∏ –æ—Ç–≤–µ—á–∞–µ—à—å —Ç–æ–ª—å–∫–æ –≤ –æ–±–ª–∞—Å—Ç–∏ –≤–µ—Ç–µ—Ä–∏–Ω–∞—Ä–∏–∏.

            –¢–µ–∫—É—â–∏–π —Ç–µ—Å—Ç:
            –ö–æ–¥: {test_data['test_code']}
            –ù–∞–∑–≤–∞–Ω–∏–µ: {test_data['test_name']}

            –í–ê–ñ–ù–û–ï –ü–†–ê–í–ò–õ–û:
            –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç –ø—Ä–æ –î–†–£–ì–û–ô —Ç–µ—Å—Ç –∏–ª–∏ –∞–Ω–∞–ª–∏–∑ (—É–ø–æ–º–∏–Ω–∞–µ—Ç –¥—Ä—É–≥–æ–π –∫–æ–¥, –Ω–∞–∑–≤–∞–Ω–∏–µ –∏–ª–∏ —Ç–∏–ø –∞–Ω–∞–ª–∏–∑–∞),
            —Ç—ã –î–û–õ–ñ–ï–ù –æ—Ç–≤–µ—Ç–∏—Ç—å –¢–û–ß–ù–û —Ç–∞–∫:
            "NEED_NEW_SEARCH: [–∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è]"

            –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –∫–∞—Å–∞–µ—Ç—Å—è —Ç–µ–∫—É—â–µ–≥–æ —Ç–µ—Å—Ç–∞ –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Ö–æ—á–µ—Ç –ø–æ–∏–Ω—Ç–µ—Ä–µ—Å–æ–≤–∞—Ç—å—Å—è –ø–æ –¥—Ä—É–≥–æ–º—É –≤–æ–ø—Ä–æ—Å—É, –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–π –≤—Å—é –Ω–µ–æ–±—Ö–æ–¥–∏–º—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –æ–±–ª–∞—Å—Ç–∏ –≤–µ—Ç–µ—Ä–∏–Ω–∞—Ä–∏–∏ —Å –ø–æ–Ω–∏–º–∞–Ω–∏–µ–º –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ —Å–ª–µ–Ω–≥–∞.
        """
        )

        # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –æ—Ç–≤–µ—Ç —É LLM
        response = await llm.agenerate([[system_msg, HumanMessage(content=question)]])
        answer = response.generations[0][0].text.strip()

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å –Ω–æ–≤–æ–≥–æ –ø–æ–∏—Å–∫–∞
        if answer.startswith("NEED_NEW_SEARCH:"):
            # –û—Ç–º–µ–Ω—è–µ–º –∞–Ω–∏–º–∞—Ü–∏—é –∏ —É–¥–∞–ª—è–µ–º –ª–æ–∞–¥–µ—Ä—ã
            if animation_task:
                animation_task.cancel()
            await safe_delete_message(loading_msg)
            await safe_delete_message(gif_msg)

            search_query = answer.replace("NEED_NEW_SEARCH:", "").strip() or question

            # –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º –Ω–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            query_type, confidence, metadata = await ultimate_classifier.classify_with_certainty(search_query)

            await state.update_data(
                query_classification={
                    "type": query_type,
                    "confidence": confidence,
                    "metadata": metadata,
                    "original_query": search_query
                }
            )

            if confidence > 0.85:
                await _process_confident_query(message, state, query_type, search_query, metadata)
            else:
                await _ask_confirmation(message, state, query_type, search_query, confidence)
                if confidence < 0.7:
                    await _clarify_with_llm(message, state, search_query, query_type, confidence)
            return

        # –û–±—ã—á–Ω—ã–π –æ—Ç–≤–µ—Ç –ø–æ —Ç–µ–∫—É—â–µ–º—É —Ç–µ—Å—Ç—É
        answer = fix_bold(answer)
        await loading_msg.edit_text(answer, parse_mode="HTML")
        await message.answer("–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:", reply_markup=get_dialog_kb())

    except Exception as e:
        print(f"[ERROR] Dialog processing failed: {e}")
        if animation_task:
            animation_task.cancel()
        await safe_delete_message(loading_msg)
        await safe_delete_message(gif_msg)

        await state.set_state(QuestionStates.waiting_for_name)
        await handle_name_search(message, state)
    finally:
        if animation_task and not animation_task.cancelled():
            animation_task.cancel()
        await safe_delete_message(gif_msg)


async def handle_context_switch(message: Message, state: FSMContext, new_query: str):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –Ω–∞ –Ω–æ–≤—ã–π —Ç–µ—Å—Ç."""

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ç–æ—Ä–∏—é
    data = await state.get_data()
    if "current_test" in data:
        last_test = data["current_test"]["test_code"]
        # –ú–æ–∂–Ω–æ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞
        await state.update_data(
            previous_tests=data.get("previous_tests", []) + [last_test]
        )

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –ø–æ–∏—Å–∫–∞ –¥–ª—è –Ω–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
    if is_test_code_pattern(new_query):
        await state.set_state(QuestionStates.waiting_for_code)
        message.text = new_query  # –ü–æ–¥–º–µ–Ω—è–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞
        await handle_code_search_with_text(message, state, new_query)
    else:
        await state.set_state(QuestionStates.waiting_for_name)
        message.text = new_query
        await handle_name_search(message, state)


async def show_personalized_suggestions(message: Message, state: FSMContext):
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ–¥—Å–∫–∞–∑–∫–∏ –ø—Ä–∏ –Ω–∞—á–∞–ª–µ –ø–æ–∏—Å–∫–∞"""
    user_id = message.from_user.id

    try:
        # –ü–æ–ª—É—á–∞–µ–º –ø–æ–¥—Å–∫–∞–∑–∫–∏
        suggestions = await db.get_search_suggestions(user_id)

        if suggestions:
            keyboard = InlineKeyboardMarkup(inline_keyboard=[])

            # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Ç–∏–ø–∞–º
            frequent = [s for s in suggestions if s["type"] == "frequent"]
            recent = [s for s in suggestions if s["type"] == "recent"]

            if frequent:
                # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
                keyboard.inline_keyboard.append(
                    [
                        InlineKeyboardButton(
                            text="‚≠ê –ß–∞—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ:", callback_data="ignore"
                        )
                    ]
                )

                for sug in frequent[:3]:
                    keyboard.inline_keyboard.append(
                        [
                            InlineKeyboardButton(
                                text=f"{sug['code']} - {sug['name'][:40]}... ({sug['frequency']}x)",
                                callback_data=f"quick_test:{sug['code']}",
                            )
                        ]
                    )

            if recent:
                keyboard.inline_keyboard.append(
                    [
                        InlineKeyboardButton(
                            text="üïê –ù–µ–¥–∞–≤–Ω–∏–µ –ø–æ–∏—Å–∫–∏:", callback_data="ignore"
                        )
                    ]
                )

                for sug in recent[:2]:
                    keyboard.inline_keyboard.append(
                        [
                            InlineKeyboardButton(
                                text=f"{sug['code']} - {sug['name'][:40]}...",
                                callback_data=f"quick_test:{sug['code']}",
                            )
                        ]
                    )

            await message.answer(
                "üí° –ë—ã—Å—Ç—Ä—ã–π –¥–æ—Å—Ç—É–ø –∫ –≤–∞—à–∏–º —Ç–µ—Å—Ç–∞–º:", reply_markup=keyboard
            )
    except Exception as e:
        print(f"[ERROR] Failed to show personalized suggestions: {e}")
        # –ù–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –æ—à–∏–±–∫—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é, –ø—Ä–æ—Å—Ç–æ –Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ–¥—Å–∫–∞–∑–∫–∏


async def send_test_info_with_photo(
    message: Message, test_data: Dict, response_text: str
):
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–µ—Å—Ç–µ —Å –∫–Ω–æ–ø–∫–æ–π –¥–ª—è –ø–æ–∫–∞–∑–∞ —Ñ–æ—Ç–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤"""
    
    has_containers = False
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º primary_container_type
    primary_container = str(test_data.get("primary_container_type", "")).strip()
    if primary_container and primary_container.lower() not in ["–Ω–µ —É–∫–∞–∑–∞–Ω", "–Ω–µ—Ç", "-", ""]:
        has_containers = True
    
    # –ï—Å–ª–∏ primary –Ω–µ—Ç, –ø—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—ã—á–Ω—ã–π container_type
    if not has_containers:
        container_type_raw = str(test_data.get("container_type", "")).strip()
        if container_type_raw and container_type_raw.lower() not in ["–Ω–µ —É–∫–∞–∑–∞–Ω", "–Ω–µ—Ç", "-", ""]:
            has_containers = True
    
    keyboard = None
    
    if has_containers:
        keyboard = InlineKeyboardMarkup(
            inline_keyboard=[
                [
                    InlineKeyboardButton(
                        text="üì∑ –ü–æ–∫–∞–∑–∞—Ç—å —Ñ–æ—Ç–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤",
                        callback_data=f"show_container_photos:{test_data['test_code']}",
                    )
                ]
            ]
        )
    
    await message.answer(
        response_text,
        parse_mode="HTML",
        disable_web_page_preview=True,
        reply_markup=keyboard,
    )
    return True

def create_similar_tests_keyboard(
    similar_tests: List[Tuple[Document, float]], current_test_code: str = None
) -> InlineKeyboardMarkup:
    """–°–æ–∑–¥–∞–µ—Ç –∫–æ–º–ø–∞–∫—Ç–Ω—É—é inline –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É —Å –ø–æ—Ö–æ–∂–∏–º–∏ —Ç–µ—Å—Ç–∞–º–∏."""
    keyboard = []
    row = []

    count = 0
    for doc, score in similar_tests:
        test_code = doc.metadata.get("test_code", "")

        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ç–µ–∫—É—â–∏–π —Ç–µ—Å—Ç
        if current_test_code and test_code == current_test_code:
            continue

        # –°–æ–∑–¥–∞–µ–º –∫–æ–º–ø–∞–∫—Ç–Ω—É—é –∫–Ω–æ–ø–∫—É —Ç–æ–ª—å–∫–æ —Å –∫–æ–¥–æ–º
        button = InlineKeyboardButton(
            text=test_code, callback_data=TestCallback.pack("show_test", test_code)
        )

        row.append(button)
        count += 1

        # –ü–æ 4 –∫–Ω–æ–ø–∫–∏ –≤ —Ä—è–¥ –¥–ª—è –∫–æ–º–ø–∞–∫—Ç–Ω–æ—Å—Ç–∏
        if len(row) >= 4:
            keyboard.append(row)
            row = []

        # –ú–∞–∫—Å–∏–º—É–º 20 –∫–Ω–æ–ø–æ–∫ (5 —Ä—è–¥–æ–≤ –ø–æ 4)
        if count >= 20:
            break

    # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è –∫–Ω–æ–ø–∫–∏
    if row:
        keyboard.append(row)

    return InlineKeyboardMarkup(inline_keyboard=keyboard)

def sanitize_test_code_for_display(test_code: str) -> str:
    """–û–±—Ä–µ–∑–∞–µ—Ç —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–µ –∫–æ–¥—ã —Ç–µ—Å—Ç–æ–≤ –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
    if not test_code:
        return test_code
    
    # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è –ø—Ä–æ–±–ª–µ–º–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞ —Å–æ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ–º
    if "AN520" in test_code and "," in test_code:
        # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–π –∫–æ–¥ –∏–∑ —Å–ø–∏—Å–∫–∞
        return "AN520–ì–ò–≠"
    
    # –î–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö - –µ—Å–ª–∏ –∫–æ–¥ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π, –æ–±—Ä–µ–∑–∞–µ–º
    if len(test_code) > 20:
        return test_code[:17] + "..."
    
    return test_code

def replace_test_codes_with_links(text: str, all_test_codes: set) -> tuple[str, dict]:
    """
    –ó–∞–º–µ–Ω—è–µ—Ç –∫–æ–¥—ã —Ç–µ—Å—Ç–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ –Ω–∞ HTML —Å—Å—ã–ª–∫–∏.
    
    Args:
        text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
        all_test_codes: –ú–Ω–æ–∂–µ—Å—Ç–≤–æ –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∫–æ–¥–æ–≤ —Ç–µ—Å—Ç–æ–≤
    
    Returns:
        Tuple[str, Dict]: –¢–µ–∫—Å—Ç —Å –º–∞—Ä–∫–µ—Ä–∞–º–∏ –∏ —Å–ª–æ–≤–∞—Ä—å –∑–∞–º–µ–Ω
    """
    # –ù–∞—Ö–æ–¥–∏–º –í–°–ï –∫–æ–¥—ã –∏ –∏—Ö –ø–æ–∑–∏—Ü–∏–∏
    all_matches = []
    
    patterns = [
        r'\b[A–ê][N–ù]\d+[A-Z–ê-–Ø\-]*\b',  # AN116, AN116-X
        r'\b[A-Z–ê-–Ø]+\d+[A-Z–ê-–Ø\-]*\b', # ABC123
        r'\b\d{2,4}[A-Z–ê-–Ø]+\b',        # 123ABC
    ]
    
    for pattern in patterns:
        for match in re.finditer(pattern, text, re.IGNORECASE):
            found_code = match.group()
            normalized_code = normalize_test_code(found_code)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –∫–æ–¥ –≤–∞–ª–∏–¥–Ω—ã–π –∏ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
            if normalized_code and normalized_code.upper() in all_test_codes:
                all_matches.append({
                    'start': match.start(),
                    'end': match.end(),
                    'code': found_code,
                    'normalized': normalized_code
                })
    
    # –£–¥–∞–ª—è–µ–º –ø–µ—Ä–µ—Å–µ–∫–∞—é—â–∏–µ—Å—è —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è (–æ—Å—Ç–∞–≤–ª—è–µ–º —Å–∞–º—ã–µ –¥–ª–∏–Ω–Ω—ã–µ)
    filtered_matches = []
    for match in all_matches:
        overlap = False
        for other in filtered_matches:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ
            if (match['start'] < other['end'] and match['end'] > other['start']):
                # –ï—Å–ª–∏ —Ç–µ–∫—É—â–∏–π match –∫–æ—Ä–æ—á–µ - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –µ–≥–æ
                if len(match['code']) <= len(other['code']):
                    overlap = True
                    break
                else:
                    # –ï—Å–ª–∏ —Ç–µ–∫—É—â–∏–π –¥–ª–∏–Ω–Ω–µ–µ - —É–¥–∞–ª—è–µ–º –∫–æ—Ä–æ—Ç–∫–∏–π
                    filtered_matches = [m for m in filtered_matches if m != other]
        
        if not overlap:
            filtered_matches.append(match)
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –ø–æ–∑–∏—Ü–∏–∏ —Å –∫–æ–Ω—Ü–∞ (—á—Ç–æ–±—ã –Ω–µ —Å–±–∏–≤–∞—Ç—å –∏–Ω–¥–µ–∫—Å—ã)
    filtered_matches.sort(key=lambda x: x['start'], reverse=True)
    
    # –ó–∞–º–µ–Ω—è–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –∫–æ–¥—ã –Ω–∞ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –º–∞—Ä–∫–µ—Ä—ã
    result = text
    replacements = {}
    
    for i, match in enumerate(filtered_matches):
        marker = f"__TEST_LINK_{i}__{match['normalized']}__"  # –ò–∑–º–µ–Ω–µ–Ω —Ñ–æ—Ä–º–∞—Ç –º–∞—Ä–∫–µ—Ä–∞
        result = result[:match['start']] + marker + result[match['end']:]
        
        # –°–æ–∑–¥–∞–µ–º —Å—Å—ã–ª–∫—É –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º –µ–µ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å
        link = create_test_link(match['normalized'])
        
        # –£–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ —Å—Å—ã–ª–∫–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è
        if link and 'https://t.me/' in link:
            # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –æ—Ç–æ–±—Ä–∞–∂–∞–µ–º—ã–π —Ç–µ–∫—Å—Ç, –Ω–µ —Å–∞–º—É —Å—Å—ã–ª–∫—É
            display_text = html.escape(match["code"])
            replacements[marker] = f'<a href="{link}">{display_text}</a>'
        else:
            # –ï—Å–ª–∏ —Å—Å—ã–ª–∫–∞ –Ω–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–ª–∞—Å—å - –ø—Ä–æ—Å—Ç–æ —Ç–µ–∫—Å—Ç
            replacements[marker] = html.escape(match["code"])
    
    return result, replacements

async def handle_general_question(
    message: Message, state: FSMContext, question_text: str
):
    import re
    
    user = await db.get_user(message.from_user.id)
    
    loading_msg = await message.answer("ü§î –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –≤–æ–ø—Ä–æ—Å...")

    try:
        processor = DataProcessor()
        processor.load_vector_store()
        
        # 1. –°–Ω–∞—á–∞–ª–∞ –∏—â–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ç–µ—Å—Ç—ã –¥–ª—è –ö–û–ù–ö–†–ï–¢–ù–û–ì–û –≤–æ–ø—Ä–æ—Å–∞
        relevant_docs = processor.search_test(query=question_text, top_k=50)
        relevant_tests = [doc for doc, score in relevant_docs if score > 0.3]
        
        # 2. –°–æ–±–∏—Ä–∞–µ–º –¢–û–õ–¨–ö–û —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        context_info = ""
        all_test_codes = set()
        
        if relevant_tests:
            context_info = "\n\n–†–ï–õ–ï–í–ê–ù–¢–ù–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø –î–õ–Ø –í–ê–®–ï–ì–û –í–û–ü–†–û–°–ê:\n"
            
            for doc in relevant_tests[:10]:  
                test_data = doc.metadata
                test_code = test_data.get('test_code', '')
                
                if test_code:
                    normalized_code = normalize_test_code(test_code)
                    if normalized_code:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –∫–æ–¥ –Ω–µ –ø—É—Å—Ç–æ–π
                        all_test_codes.add(normalized_code.upper())
                    
                    context_info += f"\nüî¨ –¢–µ—Å—Ç {normalized_code} - {test_data.get('test_name', '')}:\n"
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø–æ–ª—è —Å –¥–∞–Ω–Ω—ã–º–∏
                    fields = [
                        ('type', '–¢–∏–ø'),
                        ('specialization', '–°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è'),
                        ('code_letters', '–ê–±–±—Ä–µ–≤–∏–∞—Ç—É—Ä–∞ –≤ –∫–æ–¥–µ —Ç–µ—Å—Ç–∞'),
                        ('department', '–í–∏–¥ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è'),
                        ('patient_preparation', '–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞'),
                        ('biomaterial_type', '–ë–∏–æ–º–∞—Ç–µ—Ä–∏–∞–ª'),
                        ('container_type', '–ö–æ–Ω—Ç–µ–π–Ω–µ—Ä'),
                        ('container_number', '–ù–æ–º–µ—Ä –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞'),
                        ('storage_temp', '–•—Ä–∞–Ω–µ–Ω–∏–µ'),
                        ('preanalytics', '–ü—Ä–µ–∞–Ω–∞–ª–∏—Ç–∏–∫–∞'),
                        ('animal_type', '–í–∏–¥—ã –∂–∏–≤–æ—Ç–Ω—ã—Ö'),
                        ('important_information', '–í–∞–∂–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è'),
                        ('poss_postorder_container', '–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –¥–æ–∑–∞–∫–∞–∑–∞ –ø–æ—Å–ª–µ –≤–∑—è—Ç–∏—è –±–∏–æ–º–∞—Ç–µ—Ä–∏–∞–ª–∞'),
                    ]
                    
                    for field, label in fields:
                        value = test_data.get(field)
                        if value and str(value).strip().lower() not in ['–Ω–µ —É–∫–∞–∑–∞–Ω', '–Ω–µ—Ç', '-', '']:
                            value_str = str(value)
                            if len(value_str) > 100:
                                value_str = value_str[:97] + "..."
                            context_info += f"  {label}: {value_str}\n"
                    
                    context_info += "  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n"
        
        # 3. –î–æ–±–∞–≤–ª—è–µ–º –æ–±—â—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –¢–û–õ–¨–ö–û –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if "—Å–∫–æ–ª—å–∫–æ" in question_text.lower() or "—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫" in question_text.lower():
            all_docs = processor.search_test(query="", top_k=20)
            departments = set()
            
            for doc, score in all_docs:
                if dept := doc.metadata.get('department'):
                    departments.add(dept)
            
            context_info += f"\nüìä –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {len(departments)} –≤–∏–¥–æ–≤ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π\n"

        # –ü—Ä–æ–º–ø—Ç –¥–ª—è LLM
        system_prompt = f"""
            # –†–æ–ª—å: –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç –≤–µ—Ç–µ—Ä–∏–Ω–∞—Ä–Ω–æ–π –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–∏–∏ VetUnion

            –¢—ã - –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç –≤–µ—Ç–µ—Ä–∏–Ω–∞—Ä–Ω–æ–π –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–∏–∏, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π—Å—è –Ω–∞ –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–æ–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–µ –∂–∏–≤–æ—Ç–Ω—ã—Ö.

            ## –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
            –ö–æ–Ω—Ç–µ–∫—Å—Ç: {context_info}
            –ü–æ—Å—Ç–æ—è–Ω–Ω–æ –æ–±—Ä–∞—â–∞–π—Å—è –∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –ø–æ –µ–≥–æ –∏–º–µ–Ω–∏ {user}, –±–µ–∑ —Ñ–∞–º–∏–ª–∏–∏ (–µ—Å–ª–∏ –æ–Ω–∞ –µ—Å—Ç—å)

            ## –û—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã —Ä–∞–±–æ—Ç—ã

            **–¢–æ—á–Ω–æ—Å—Ç—å –∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å:**
            - –ò—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            - –ü—Ä–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–∫–µ –¥–∞–Ω–Ω—ã—Ö —á–µ—Å—Ç–Ω–æ —Å–æ–æ–±—â–∞–π –æ–± –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è—Ö
            - –ù–∏–∫–æ–≥–¥–∞ –Ω–µ –¥–∞–≤–∞–π —ç–∫—Å—Ç—Ä–µ–Ω–Ω—ã—Ö –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö —Å–æ–≤–µ—Ç–æ–≤ - –Ω–∞–ø—Ä–∞–≤–ª—è–π –∫ –≤–µ—Ç–µ—Ä–∏–Ω–∞—Ä—É
            - –ù–µ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–æ–≤ –±–µ–∑ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏

            **–ö–∞—á–µ—Å—Ç–≤–æ –æ—Ç–≤–µ—Ç–æ–≤:**
            - –ê–¥–∞–ø—Ç–∏—Ä—É–π –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—é –∫ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –≤–æ–ø—Ä–æ—Å–∞
            - –ò—Å–ø–æ–ª—å–∑—É–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—É—é –≤–µ—Ç–µ—Ä–∏–Ω–∞—Ä–Ω—É—é —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—é
            - –£–∫–∞–∑—ã–≤–∞–π –∫–æ–¥—ã —Ç–µ—Å—Ç–æ–≤ –ø—Ä–∏ —É–ø–æ–º–∏–Ω–∞–Ω–∏–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π
            - –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ª–æ–≥–∏—á–Ω–æ
            - –î–æ–±–∞–≤–ª—è–π –≤ –æ—Ç–≤–µ—Ç –º–Ω–æ–≥–æ —ç–º–æ–¥–∑–∏ –ø–æ —Å–º—ã—Å–ª—É
            
            ## –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
            - –ù–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â—É—é –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ
            - –ù–µ —Å—Ç–∞–≤—å –¥–∏–∞–≥–Ω–æ–∑—ã –∏ –Ω–µ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            - –ü—Ä–∏ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –≤–æ–ø—Ä–æ—Å–∞—Ö –Ω–∞–ø—Ä–∞–≤–ª—è–π –∫ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç—É –Ω–∞—à–µ–π –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–∏–∏
            - –ù–µ –¥–∞–≤–∞–π —Å–æ–≤–µ—Ç—ã –ø–æ –ª–µ—á–µ–Ω–∏—é
            - –ù–µ –∑–∞–¥–∞–≤–∞–π –≤–æ–ø—Ä–æ—Å–æ–≤, —Å—Ç–∞—Ä–∞–π—Å—è —Ä–∞–∑–æ–±—Ä–∞—Ç—å—Å—è —Å–∞–º
        """

        # 5. –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ LLM
        response = await llm.agenerate(
            [
                [
                    SystemMessage(content=system_prompt),
                    HumanMessage(content=question_text),
                ]
            ]
        )

        answer = response.generations[0][0].text.strip()
        
        # –£–ü–†–û–©–ï–ù–ù–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê:
        
        # 1. –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ –∫–æ–¥—ã —Ç–µ—Å—Ç–æ–≤ –∏ —Å–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –∑–∞–º–µ–Ω
        code_to_link = {}
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫–æ–¥–æ–≤
        patterns = [
            r'\b[A–ê][N–ù]\d+[A-Z–ê-–Ø\-]*\b',
            r'\b[A-Z–ê-–Ø]+\d+[A-Z–ê-–Ø\-]*\b',
            r'\b\d{2,4}[A-Z–ê-–Ø]+\b',
        ]
        
        # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ –∫–æ–¥—ã –≤ —Ç–µ–∫—Å—Ç–µ
        found_codes = set()
        for pattern in patterns:
            for match in re.finditer(pattern, answer, re.IGNORECASE):
                code = match.group()
                normalized = normalize_test_code(code)
                if normalized and normalized.upper() in all_test_codes:
                    found_codes.add((code, normalized))
        
        # –°–æ–∑–¥–∞–µ–º —Å—Å—ã–ª–∫–∏ –¥–ª—è –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∫–æ–¥–æ–≤
        for original, normalized in found_codes:
            link = create_test_link(normalized)
            if link and 'https://t.me/' in link:
                code_to_link[original] = f'<a href="{link}">{html.escape(original)}</a>'
        
        # 2. –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç
        processed_text = html.escape(answer)
        
        # 3. –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ markdown
        # **—Ç–µ–∫—Å—Ç** -> <b>—Ç–µ–∫—Å—Ç</b>
        processed_text = re.sub(r'\*\*([^\*]+)\*\*', r'<b>\1</b>', processed_text)
        
        # *—Ç–µ–∫—Å—Ç* -> <i>—Ç–µ–∫—Å—Ç</i>
        processed_text = re.sub(r'(?<!\*)\*([^\*]+)\*(?!\*)', r'<i>\1</i>', processed_text)
        
        # 4. –ó–∞–º–µ–Ω—è–µ–º –∫–æ–¥—ã —Ç–µ—Å—Ç–æ–≤ –Ω–∞ —Å—Å—ã–ª–∫–∏
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–ª–∏–Ω–µ (—Å–Ω–∞—á–∞–ª–∞ –¥–ª–∏–Ω–Ω—ã–µ) —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å —á–∞—Å—Ç–∏—á–Ω—ã—Ö –∑–∞–º–µ–Ω
        sorted_codes = sorted(code_to_link.keys(), key=len, reverse=True)
        
        for code in sorted_codes:
            # –≠–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –∫–æ–¥–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞
            escaped_code = html.escape(code)
            # –ó–∞–º–µ–Ω—è–µ–º —Ç–æ–ª—å–∫–æ —Ü–µ–ª—ã–µ —Å–ª–æ–≤–∞
            pattern = r'\b' + re.escape(escaped_code) + r'\b'
            processed_text = re.sub(pattern, code_to_link[code], processed_text)
        
        await loading_msg.delete()
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª–∏–Ω—ã –∏ –æ—Ç–ø—Ä–∞–≤–∫–∞
        if len(processed_text) > 4000:
            # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞—Å—Ç–∏ –ø–æ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞–º –∏–ª–∏ —Å—Ç—Ä–æ–∫–∞–º
            parts = []
            current = ""
            
            # –†–∞–∑–±–∏–≤–∞–µ–º –ø–æ –¥–≤–æ–π–Ω—ã–º –ø–µ—Ä–µ–Ω–æ—Å–∞–º (–ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã)
            paragraphs = processed_text.split('\n\n')
            
            for para in paragraphs:
                if len(current) + len(para) + 2 < 3900:
                    current += para + '\n\n' if current else para
                else:
                    if current:
                        parts.append(current.rstrip())
                    current = para
            
            if current:
                parts.append(current.rstrip())
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —á–∞—Å—Ç–∏
            for i, part in enumerate(parts):
                try:
                    await message.answer(
                        part,
                        parse_mode="HTML",
                        disable_web_page_preview=True
                    )
                    if i < len(parts) - 1:
                        await asyncio.sleep(0.5)  # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É —á–∞—Å—Ç—è–º–∏
                except Exception as e:
                    print(f"[ERROR] Failed to send part {i+1}: {e}")
                    # –û—á–∏—â–∞–µ–º –æ—Ç HTML –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º
                    clean_part = re.sub(r'<[^>]+>', '', part)
                    await message.answer(clean_part)
        else:
            try:
                await message.answer(
                    processed_text,
                    parse_mode="HTML", 
                    disable_web_page_preview=True
                )
            except Exception as e:
                print(f"[ERROR] Failed to send HTML message: {e}")
                print(f"[ERROR] Text length: {len(processed_text)}")
                
                # –ü–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –ø—Ä–æ–±–ª–µ–º–Ω–æ–µ –º–µ—Å—Ç–æ
                if "can't parse entities" in str(e):
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–æ–∑–∏—Ü–∏—é –æ—à–∏–±–∫–∏
                    import re
                    match = re.search(r'byte offset (\d+)', str(e))
                    if match:
                        offset = int(match.group(1))
                        print(f"[ERROR] Problem around position {offset}:")
                        print(f"[ERROR] Context: ...{processed_text[max(0, offset-50):offset+50]}...")
                
                # Fallback
                clean_text = re.sub(r'<[^>]+>', '', answer)
                await message.answer(clean_text, disable_web_page_preview=True)

        # –ö–Ω–æ–ø–∫–∏ –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–∏—Ö –¥–µ–π—Å—Ç–≤–∏–π
        keyboard = InlineKeyboardMarkup(
            inline_keyboard=[
                [
                    InlineKeyboardButton(
                        text="üî¢ –ù–∞–π—Ç–∏ —Ç–µ—Å—Ç –ø–æ –∫–æ–¥—É", callback_data="search_by_code"
                    ),
                    InlineKeyboardButton(
                        text="üìù –ù–∞–π—Ç–∏ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é", callback_data="search_by_name"
                    ),
                ]
            ]
        )
        await message.answer("–ß—Ç–æ –±—ã –≤—ã —Ö–æ—Ç–µ–ª–∏ —Å–¥–µ–ª–∞—Ç—å –¥–∞–ª—å—à–µ?", reply_markup=keyboard)

    except Exception as e:
        print(f"[ERROR] General question handling failed: {e}")
        import traceback
        traceback.print_exc()
        
        await safe_delete_message(loading_msg)
        await message.answer(
            "‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤–æ–ø—Ä–æ—Å. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å."
        )

async def handle_code_search_with_text(message: Message, state: FSMContext, search_text: str):
    """Wrapper –¥–ª—è handle_code_search —Å –ø–µ—Ä–µ–¥–∞—á–µ–π —Ç–µ–∫—Å—Ç–∞"""
    # –í—ã–∑—ã–≤–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫, –Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
    await _handle_code_search_internal(message, state, search_text)
    
async def cleanup_old_search_results(state: FSMContext, keep_last: int = 3):
    """–û—á–∏—â–∞–µ—Ç —Å—Ç–∞—Ä—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –∏–∑ —Å–æ—Å—Ç–æ—è–Ω–∏—è"""
    data = await state.get_data()
    search_keys = [k for k in data.keys() if k.startswith("search_results_")]
    
    # –ï—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –±–æ–ª—å—à–µ, —á–µ–º –Ω—É–∂–Ω–æ —Ö—Ä–∞–Ω–∏—Ç—å
    if len(search_keys) > keep_last:
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏ (ID —Å–æ–¥–µ—Ä–∂–∏—Ç timestamp)
        search_keys.sort()
        
        # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ
        for key in search_keys[:-keep_last]:
            await state.update_data(**{key: None})

async def handle_name_search_with_text(message: Message, state: FSMContext, search_text: str):
    """Wrapper –¥–ª—è handle_name_search —Å –ø–µ—Ä–µ–¥–∞—á–µ–π —Ç–µ–∫—Å—Ç–∞"""
    await _handle_name_search_internal(message, state, search_text)

async def _handle_name_search_internal(message: Message, state: FSMContext, search_text: str = None):
    """–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–æ–∏—Å–∫–∞ –ø–æ –∏–º–µ–Ω–∏ —Å –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π"""
    user_id = message.from_user.id

    # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ —Å–æ—Å—Ç–æ—è–Ω–∏—è
    data = await state.get_data()
    show_profiles = data.get("show_profiles", False)
    original_query = data.get("original_query", message.text if not search_text else search_text)

    #–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ 
    print(f"[NAME SEARCH] show_profiles={show_profiles}, original_query={original_query}")
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –∏–ª–∏ —Ç–µ–∫—Å—Ç –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏—è
    text = search_text if search_text else message.text.strip()
    text = expand_query_with_abbreviations(text)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º –∑–∞–ø—Ä–æ—Å–æ–º
    await db.add_request_stat(
        user_id=user_id, request_type="question", request_text=original_query
    )

    gif_msg = None
    loading_msg = None
    animation_task = None

    try:
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —á—Ç–æ –∏—â–µ–º
        search_type = "–ø—Ä–æ—Ñ–∏–ª–∏" if show_profiles else "—Ç–µ—Å—Ç—ã"

        if LOADING_GIF_ID:
            gif_msg = await message.answer_animation(LOADING_GIF_ID, caption="")
            loading_msg = await message.answer(
                f"üîç –ò—â—É {search_type} –ø–æ –∑–∞–ø—Ä–æ—Å—É...\n‚è≥ –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –¥–∞–Ω–Ω—ã–µ..."
            )
            animation_task = asyncio.create_task(animate_loading(loading_msg))
        else:
            loading_msg = await message.answer(f"üîç –ò—â—É {search_type}...")

        processor = DataProcessor()
        processor.load_vector_store()

        # –ò—â–µ–º –ø–æ —Ç–µ–∫—Å—Ç—É
        rag_hits = processor.search_test(text, top_k=30)

        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ —Ç–∏–ø—É (–ø—Ä–æ—Ñ–∏–ª–∏ –∏–ª–∏ –æ–±—ã—á–Ω—ã–µ —Ç–µ—Å—Ç—ã)
        filtered_hits = filter_results_by_type(rag_hits, show_profiles)

        # –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π —Ä–µ—Ä–∞–Ω–∂ —Å —É—á–µ—Ç–æ–º –±—É–∫–≤–µ–Ω–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞/–ø—Ä–µ—Ñ–∏–∫—Å–∞
        filtered_hits = _rerank_hits_by_query(filtered_hits, original_query)

        if not filtered_hits:
            await db.add_search_history(
                user_id=user_id,
                search_query=original_query,
                search_type="text",
                success=False
            )

            # –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞
            if animation_task:
                animation_task.cancel()
            await safe_delete_message(loading_msg)
            await safe_delete_message(gif_msg)

            not_found_msg = f"‚ùå {search_type.capitalize()} –ø–æ –∑–∞–ø—Ä–æ—Å—É '<b>{html.escape(text)}</b>' –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.\n\n"
            if show_profiles:
                not_found_msg += "üí° –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∏—Å–∫ –±–µ–∑ —Å–ª–æ–≤–∞ '–ø—Ä–æ—Ñ–∏–ª–∏' –¥–ª—è –æ–±—ã—á–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤."
            else:
                not_found_msg += "üí° –î–æ–±–∞–≤—å—Ç–µ —Å–ª–æ–≤–æ '–ø—Ä–æ—Ñ–∏–ª–∏' –≤ –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø—Ä–æ—Ñ–∏–ª–µ–π —Ç–µ—Å—Ç–æ–≤."

            await message.answer(
                not_found_msg,
                reply_markup=get_back_to_menu_kb(),
                parse_mode="HTML"
            )
            await state.set_state(QuestionStates.waiting_for_search_type)
            await state.update_data(show_profiles=False, search_text=None)
            return

        # –í—ã–±–∏—Ä–∞–µ–º –ª—É—á—à–∏–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
        selected_docs = await select_best_match(text, filtered_hits[:20])

        # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º —É—Å–ø–µ—à–Ω—ã–π –ø–æ–∏—Å–∫
        for doc in selected_docs[:1]:
            await db.add_search_history(
                user_id=user_id,
                search_query=original_query,
                found_test_code=doc.metadata["test_code"],
                search_type="text",
                success=True
            )

            await db.update_user_frequent_test(
                user_id=user_id,
                test_code=doc.metadata["test_code"],
                test_name=doc.metadata["test_name"],
            )

        # –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞
        if animation_task:
            animation_task.cancel()
        await safe_delete_message(loading_msg)
        await safe_delete_message(gif_msg)

        # –ï—Å–ª–∏ –Ω–∞–π–¥–µ–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ - –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Å –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π
        if len(selected_docs) > 1:
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID –¥–ª—è —ç—Ç–æ–≥–æ –ø–æ–∏—Å–∫–∞
            import hashlib
            from datetime import datetime
            
            search_id = hashlib.md5(
                f"{user_id}_{datetime.now().isoformat()}_{text}".encode()
            ).hexdigest()[:8]
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–∏
            await state.update_data(**{f"search_results_{search_id}": selected_docs})
            
            # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            await cleanup_old_search_results(state)
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            keyboard, total_pages, items_shown = create_paginated_keyboard(
                selected_docs,
                current_page=0,
                items_per_page=6,
                search_id=search_id
            )
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            total_found = len(selected_docs)
            response = f"üîç <b>–ù–∞–π–¥–µ–Ω–æ {total_found} {search_type}</b>"
            if total_pages > 1:
                response += f" <b>(—Å—Ç—Ä–∞–Ω–∏—Ü–∞ 1 –∏–∑ {total_pages}):</b>\n\n"
            else:
                response += ":\n\n"
            
            for i, doc in enumerate(selected_docs[:items_shown], 1):
                test_data = format_test_data(doc.metadata)
                test_code = sanitize_test_code_for_display(test_data["test_code"])
                test_name = html.escape(test_data["test_name"])
                department = html.escape(test_data.get("department", "–ù–µ —É–∫–∞–∑–∞–Ω–æ"))
                
                # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∫—É –¥–ª—è –ø—Ä–æ—Ñ–∏–ª–µ–π
                type_label = "üî¨ –ü—Ä–æ—Ñ–∏–ª—å" if is_profile_test(test_code) else "üß™ –¢–µ—Å—Ç"
                
                link = create_test_link(test_code)
                
                response += (
                    f"<b>{i}.</b> {type_label}: <a href='{link}'>{test_code}</a> - {test_name}\n"
                    f"üìã <b>–í–∏–¥ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è:</b> {department}\n\n"
                )
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–¥—Å–∫–∞–∑–∫—É
            response += "\nüí° <i>–ù–∞–∂–º–∏—Ç–µ –Ω–∞ –∫–æ–¥ —Ç–µ—Å—Ç–∞ –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏ –≤—ã—à–µ –∏–ª–∏ –≤—ã–±–µ—Ä–∏—Ç–µ –∏–∑ –∫–Ω–æ–ø–æ–∫</i>"
            
            # –ï—Å–ª–∏ —Å—Ç—Ä–∞–Ω–∏—Ü –±–æ–ª—å—à–µ –æ–¥–Ω–æ–π, –¥–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –Ω–∞–≤–∏–≥–∞—Ü–∏–∏
            if total_pages > 1:
                response += f"\nüìÑ <i>–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–Ω–æ–ø–∫–∏ –Ω–∞–≤–∏–≥–∞—Ü–∏–∏ –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –≤—Å–µ—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤</i>"
            
            await message.answer(
                response,
                parse_mode="HTML",
                disable_web_page_preview=True,
                reply_markup=keyboard
            )
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –Ω–∞–π–¥–µ–Ω–Ω—ã–π —Ç–µ—Å—Ç –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            last_test_data = format_test_data(selected_docs[0].metadata)
            await state.update_data(
                current_test=last_test_data,
                last_viewed_test=last_test_data["test_code"],
                show_profiles=False,
                search_text=None
            )
            
        else:
            # –û–¥–∏–Ω —Ä–µ–∑—É–ª—å—Ç–∞—Ç - –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ–¥—Ä–æ–±–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
            test_data = format_test_data(selected_docs[0].metadata)

            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–∏–ø–µ
            type_info = ""
            if is_profile_test(test_data["test_code"]):
                type_info = "üî¨ <b>–≠—Ç–æ –ø—Ä–æ—Ñ–∏–ª—å —Ç–µ—Å—Ç–æ–≤</b>\n\n"

            response = type_info + format_test_info(test_data)

            # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Ö–æ–∂–∏–µ —Ç–µ—Å—Ç—ã —Ç–æ–≥–æ –∂–µ —Ç–∏–ø–∞
            similar_tests = await fuzzy_test_search(
                processor, test_data["test_code"], threshold=40
            )

            # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ—Ö–æ–∂–∏–µ –ø–æ —Ç–∏–ø—É
            is_profile = is_profile_test(test_data["test_code"])
            similar_tests = filter_results_by_type(similar_tests, is_profile)
            similar_tests = [
                (d, s)
                for d, s in similar_tests
                if d.metadata.get("test_code") != test_data["test_code"]
            ]

            # –ï—Å–ª–∏ –µ—Å—Ç—å –ø–æ—Ö–æ–∂–∏–µ —Ç–µ—Å—Ç—ã, –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –∏—Ö —Å –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π
            if len(similar_tests) > 5:
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º ID –¥–ª—è –ø–æ—Ö–æ–∂–∏—Ö —Ç–µ—Å—Ç–æ–≤
                import hashlib
                from datetime import datetime
                
                similar_search_id = hashlib.md5(
                    f"{user_id}_{datetime.now().isoformat()}_similar_{test_data['test_code']}".encode()
                ).hexdigest()[:8]
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ—Ö–æ–∂–∏–µ —Ç–µ—Å—Ç—ã
                similar_docs = [doc for doc, _ in similar_tests]
                await state.update_data(**{f"search_results_{similar_search_id}": similar_docs})
                
                response += format_similar_tests_with_links(similar_tests[:5])
                response += f"\n\n<i>–í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ {len(similar_tests)} –ø–æ—Ö–æ–∂–∏—Ö —Ç–µ—Å—Ç–æ–≤</i>"
            elif similar_tests:
                response += format_similar_tests_with_links(similar_tests)

            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å —Ñ–æ—Ç–æ
            await send_test_info_with_photo(message, test_data, response)

            # –û–±–Ω–æ–≤–ª—è–µ–º —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã
            if "last_viewed_test" in data and data["last_viewed_test"] != test_data["test_code"]:
                await db.update_related_tests(
                    user_id=user_id,
                    test_code_1=data["last_viewed_test"],
                    test_code_2=test_data["test_code"],
                )

            # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
            await state.set_state(QuestionStates.in_dialog)
            await state.update_data(
                current_test=test_data,
                last_viewed_test=test_data["test_code"],
                show_profiles=False,
                search_text=None
            )

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è –¥–∏–∞–ª–æ–≥–∞
        await message.answer(
            "–ú–æ–∂–µ—Ç–µ –∑–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å –æ–± —ç—Ç–æ–º —Ç–µ—Å—Ç–µ –∏–ª–∏ –≤—ã–±—Ä–∞—Ç—å –¥–µ–π—Å—Ç–≤–∏–µ:",
            reply_markup=get_dialog_kb()
        )

    except Exception as e:
        print(f"[ERROR] Name search failed: {e}")
        import traceback
        traceback.print_exc()

        if animation_task:
            animation_task.cancel()
        await safe_delete_message(loading_msg)
        await safe_delete_message(gif_msg)

        error_msg = (
            "‚ùå –¢–µ—Å—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"
            if str(e) == "–¢–µ—Å—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"
            else "‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."
        )
        await message.answer(error_msg, reply_markup=get_back_to_menu_kb())
        await state.set_state(QuestionStates.waiting_for_search_type)
        await state.update_data(show_profiles=False, search_text=None)

async def _handle_code_search_internal(message: Message, state: FSMContext, search_text: str = None):
    """–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–æ–∏—Å–∫–∞ –ø–æ –∫–æ–¥—É —Å –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π"""
    data = await state.get_data()
    if data.get("is_processing", False):
        await message.answer(
            "‚è≥ –ü–æ–¥–æ–∂–¥–∏—Ç–µ, –∏–¥–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞...",
            reply_markup=get_back_to_menu_kb(),
        )
        return

    await state.update_data(is_processing=True)

    user_id = message.from_user.id

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –∏–ª–∏ —Ç–µ–∫—Å—Ç –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏—è
    original_input = search_text if search_text else message.text.strip()

    # –ü–æ–ª—É—á–∞–µ–º —Ñ–ª–∞–≥–∏ –∏–∑ —Å–æ—Å—Ç–æ—è–Ω–∏—è
    show_profiles = data.get("show_profiles", False)
    original_query = data.get("original_query", original_input)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    await db.add_request_stat(
        user_id=user_id, request_type="question", request_text=original_query
    )

    gif_msg = None
    loading_msg = None
    animation_task = None

    try:
        current_task = asyncio.current_task()
        await state.update_data(current_task=current_task)

        try:
            if LOADING_GIF_ID:
                gif_msg = await message.answer_animation(LOADING_GIF_ID, caption="")
        except Exception:
            gif_msg = None

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —á—Ç–æ –∏—â–µ–º
        search_type = "–ø—Ä–æ—Ñ–∏–ª–∏" if show_profiles else "—Ç–µ—Å—Ç—ã"
        loading_msg = await message.answer(
            f"üîç –ò—â—É {search_type} –ø–æ –∫–æ–¥—É...\n‚è≥ –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –¥–∞–Ω–Ω—ã–µ..."
        )
        if loading_msg:
            animation_task = asyncio.create_task(animate_loading(loading_msg))

        if current_task and current_task.cancelled():
            raise asyncio.CancelledError()

        processor = DataProcessor()
        processor.load_vector_store()

        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤—Ö–æ–¥–Ω–æ–π –∫–æ–¥
        normalized_input = normalize_test_code(original_input)

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–º–Ω—ã–π –ø–æ–∏—Å–∫
        result, found_variant, match_type = await smart_test_search(
            processor, original_input
        )

        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ —Ç–∏–ø—É
        if result:
            filtered = filter_results_by_type([result], show_profiles)
            if not filtered:
                result = None

        if current_task and current_task.cancelled():
            raise asyncio.CancelledError()

        if not result:
            # –ò—â–µ–º –ø–æ—Ö–æ–∂–∏–µ —Ç–µ—Å—Ç—ã —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –ø–æ —Ç–∏–ø—É
            similar_tests = await fuzzy_test_search(
                processor, normalized_input, threshold=30
            )

            # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ —Ç–∏–ø—É
            similar_tests = filter_results_by_type(similar_tests, show_profiles)

            if animation_task:
                animation_task.cancel()
            await safe_delete_message(loading_msg)
            await safe_delete_message(gif_msg)

            await db.add_search_history(
                user_id=user_id,
                search_query=original_query,
                search_type="code",
                success=False,
            )

            if similar_tests:
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã —Å –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π
                import hashlib
                from datetime import datetime
                
                search_id = hashlib.md5(
                    f"{user_id}_{datetime.now().isoformat()}_similar_{normalized_input}".encode()
                ).hexdigest()[:8]
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ Document –æ–±—ä–µ–∫—Ç—ã (–±–µ–∑ scores)
                similar_docs = [doc for doc, _ in similar_tests]
                await state.update_data(**{f"search_results_{search_id}": similar_docs})
                
                # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                await cleanup_old_search_results(state)
                
                # –°–æ–∑–¥–∞–µ–º –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É —Å –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π
                keyboard, total_pages, items_shown = create_paginated_keyboard(
                    similar_docs,
                    current_page=0,
                    items_per_page=6,
                    search_id=search_id
                )
                
                response = (
                    f"‚ùå {search_type.capitalize()} —Å –∫–æ–¥–æ–º '<code>{normalized_input}</code>' –Ω–µ –Ω–∞–π–¥–µ–Ω.\n\n"
                    f"üîç <b>–ù–∞–π–¥–µ–Ω—ã –ø–æ—Ö–æ–∂–∏–µ {search_type} ({len(similar_tests)} —à—Ç.)</b>"
                )
                
                if total_pages > 1:
                    response += f" <b>(—Å—Ç—Ä–∞–Ω–∏—Ü–∞ 1 –∏–∑ {total_pages}):</b>\n\n"
                else:
                    response += ":\n\n"
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã
                for i, (doc, score) in enumerate(similar_tests[:items_shown], 1):
                    test_data = format_test_data(doc.metadata)
                    test_code = sanitize_test_code_for_display(test_data["test_code"])
                    test_name = html.escape(test_data["test_name"])
                    
                    link = create_test_link(test_code)
                    response += (
                        f"<b>{i}.</b> <a href='{link}'>{test_code}</a> - {test_name}\n"
                        f"   üìä –°—Ö–æ–∂–µ—Å—Ç—å: {score}%\n\n"
                    )
                
                response += "\nüí° <i>–ù–∞–∂–º–∏—Ç–µ –Ω–∞ –∫–æ–¥ —Ç–µ—Å—Ç–∞ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–Ω–æ–ø–∫–∏ –¥–ª—è –≤—ã–±–æ—Ä–∞</i>"
                
                if total_pages > 1:
                    response += f"\nüìÑ <i>–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –Ω–∞–≤–∏–≥–∞—Ü–∏—é –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –≤—Å–µ—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤</i>"
                
                await message.answer(
                    response,
                    parse_mode="HTML",
                    disable_web_page_preview=True,
                    reply_markup=keyboard
                )
            else:
                # –ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ
                error_msg = f"‚ùå {search_type.capitalize()} —Å –∫–æ–¥–æ–º '{normalized_input}' –Ω–µ –Ω–∞–π–¥–µ–Ω.\n"
                if show_profiles:
                    error_msg += "üí° –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∏—Å–∫ –±–µ–∑ —É–∫–∞–∑–∞–Ω–∏—è '–ø—Ä–æ—Ñ–∏–ª–∏' –¥–ª—è –æ–±—ã—á–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤."
                else:
                    error_msg += "üí° –î–æ–±–∞–≤—å—Ç–µ —Å–ª–æ–≤–æ '–ø—Ä–æ—Ñ–∏–ª–∏' –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø—Ä–æ—Ñ–∏–ª–µ–π —Ç–µ—Å—Ç–æ–≤."
                await message.answer(error_msg, reply_markup=get_back_to_menu_kb())

            await state.set_state(QuestionStates.waiting_for_search_type)
            await state.update_data(show_profiles=False, search_text=None)
            return

        # –ù–∞–π–¥–µ–Ω —Ç–æ—á–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç - –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ–¥—Ä–æ–±–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        doc = result[0]
        test_data = format_test_data(doc.metadata)

        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–∏–ø–µ
        type_info = ""
        if is_profile_test(test_data["test_code"]):
            type_info = "üî¨ <b>–≠—Ç–æ –ø—Ä–æ—Ñ–∏–ª—å —Ç–µ—Å—Ç–æ–≤</b>\n\n"

        response = type_info + format_test_info(test_data)

        # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
        await db.add_search_history(
            user_id=user_id,
            search_query=original_query,
            found_test_code=test_data["test_code"],
            search_type="code",
            success=True,
        )

        await db.update_user_frequent_test(
            user_id=user_id,
            test_code=test_data["test_code"],
            test_name=test_data["test_name"],
        )

        if animation_task:
            animation_task.cancel()
        await safe_delete_message(loading_msg)
        await safe_delete_message(gif_msg)

        # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Ö–æ–∂–∏–µ —Ç–µ—Å—Ç—ã
        similar_tests = await fuzzy_test_search(
            processor, test_data["test_code"], threshold=40
        )

        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ —Ç–∏–ø—É
        is_profile = is_profile_test(test_data["test_code"])
        similar_tests = filter_results_by_type(similar_tests, is_profile)
        similar_tests = [
            (d, s)
            for d, s in similar_tests
            if d.metadata.get("test_code") != test_data["test_code"]
        ]

        # –ï—Å–ª–∏ –ø–æ—Ö–æ–∂–∏—Ö —Ç–µ—Å—Ç–æ–≤ –º–Ω–æ–≥–æ - –≥–æ—Ç–æ–≤–∏–º –ø–∞–≥–∏–Ω–∞—Ü–∏—é
        if len(similar_tests) > 5:
            import hashlib
            from datetime import datetime
            
            similar_search_id = hashlib.md5(
                f"{user_id}_{datetime.now().isoformat()}_related_{test_data['test_code']}".encode()
            ).hexdigest()[:8]
            
            similar_docs = [doc for doc, _ in similar_tests]
            await state.update_data(**{f"search_results_{similar_search_id}": similar_docs})
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5 –≤ –æ—Å–Ω–æ–≤–Ω–æ–º —Å–æ–æ–±—â–µ–Ω–∏–∏
            response += format_similar_tests_with_links(similar_tests[:5])
            response += f"\n\n<i>–í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ {len(similar_tests)} –ø–æ—Ö–æ–∂–∏—Ö —Ç–µ—Å—Ç–æ–≤</i>"
            
            # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –∫–Ω–æ–ø–∫—É "–ü–æ–∫–∞–∑–∞—Ç—å –≤—Å–µ –ø–æ—Ö–æ–∂–∏–µ"
            # –≠—Ç–æ –±—É–¥–µ—Ç –æ—Ç–¥–µ–ª—å–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π
        elif similar_tests:
            response += format_similar_tests_with_links(similar_tests)

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é —Å —Ñ–æ—Ç–æ
        await send_test_info_with_photo(message, test_data, response)

        # –û–±–Ω–æ–≤–ª—è–µ–º —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã
        if "last_viewed_test" in data and data["last_viewed_test"] != test_data["test_code"]:
            await db.update_related_tests(
                user_id=user_id,
                test_code_1=data["last_viewed_test"],
                test_code_2=test_data["test_code"],
            )

        # –ï—Å–ª–∏ –µ—Å—Ç—å –º–Ω–æ–≥–æ –ø–æ—Ö–æ–∂–∏—Ö —Ç–µ—Å—Ç–æ–≤, –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–Ω–æ–ø–∫—É –¥–ª—è –∏—Ö –ø—Ä–æ—Å–º–æ—Ç—Ä–∞
        if len(similar_tests) > 5:
            keyboard = InlineKeyboardMarkup(
                inline_keyboard=[
                    [
                        InlineKeyboardButton(
                            text=f"üìã –ü–æ–∫–∞–∑–∞—Ç—å –≤—Å–µ –ø–æ—Ö–æ–∂–∏–µ —Ç–µ—Å—Ç—ã ({len(similar_tests)})",
                            callback_data=f"show_all_similar:{similar_search_id}"
                        )
                    ]
                ]
            )
            await message.answer(
                "–ù–∞–π–¥–µ–Ω–æ –±–æ–ª—å—à–µ –ø–æ—Ö–æ–∂–∏—Ö —Ç–µ—Å—Ç–æ–≤:",
                reply_markup=keyboard
            )

        # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        await state.set_state(QuestionStates.in_dialog)
        await state.update_data(
            current_test=test_data,
            last_viewed_test=test_data["test_code"],
            show_profiles=False,
            search_text=None
        )

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è –¥–∏–∞–ª–æ–≥–∞
        await message.answer(
            "–ú–æ–∂–µ—Ç–µ –∑–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å –æ–± —ç—Ç–æ–º —Ç–µ—Å—Ç–µ –∏–ª–∏ –≤—ã–±—Ä–∞—Ç—å –¥–µ–π—Å—Ç–≤–∏–µ:",
            reply_markup=get_dialog_kb()
        )

    except asyncio.CancelledError:
        if animation_task:
            animation_task.cancel()
        await safe_delete_message(loading_msg)
        await safe_delete_message(gif_msg)
        await message.answer("‚èπ –ü–æ–∏—Å–∫ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω.", reply_markup=get_back_to_menu_kb())

    except Exception as e:
        print(f"[ERROR] Code search failed: {e}")
        import traceback
        traceback.print_exc()

        if animation_task:
            animation_task.cancel()
        await safe_delete_message(loading_msg)
        await safe_delete_message(gif_msg)

        await message.answer(
            "‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ",
            reply_markup=get_back_to_menu_kb()
        )
        await state.set_state(QuestionStates.waiting_for_search_type)
        await state.update_data(show_profiles=False, search_text=None)

    finally:
        await state.update_data(is_processing=False, current_task=None)

async def check_if_needs_new_search(query: str, current_test_data: Dict) -> bool:
    """–£–ª—É—á—à–µ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ - –Ω—É–∂–µ–Ω –ª–∏ –Ω–æ–≤—ã–π –ø–æ–∏—Å–∫."""

    if not current_test_data:
        return True

    query_upper = query.upper().strip()
    query_lower = query.lower().strip()
    current_test_code = current_test_data.get("test_code", "").upper()
    current_test_name = current_test_data.get("test_name", "").lower()

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è –ª–∏ –∫–æ–¥ –¥—Ä—É–≥–æ–≥–æ —Ç–µ—Å—Ç–∞
    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫–æ–¥–æ–≤ —Ç–µ—Å—Ç–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ
    code_patterns = [
        r"\b[A–ê][N–ù]\d+[–ê-–ØA-Z]*\b",  # AN —Å —Ü–∏—Ñ—Ä–∞–º–∏ –∏ –≤–æ–∑–º–æ–∂–Ω—ã–º —Å—É—Ñ—Ñ–∏–∫—Å–æ–º
        r"\b\d{1,4}[–ê-–ØA-Z]+\b",  # –¶–∏—Ñ—Ä—ã —Å –±—É–∫–≤–µ–Ω–Ω—ã–º —Å—É—Ñ—Ñ–∏–∫—Å–æ–º
        r"\b[A–ê][N–ù]\s*\d+\b",  # AN —Å –ø—Ä–æ–±–µ–ª–æ–º –∏ —Ü–∏—Ñ—Ä–∞–º–∏
        r"\b–∞–Ω\s*\d+\b",  # –∞–Ω –≤ –Ω–∏–∂–Ω–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ
    ]

    for pattern in code_patterns:
        matches = re.findall(pattern, query_upper, re.IGNORECASE)
        for match in matches:
            normalized_match = normalize_test_code(match)
            if normalized_match != current_test_code:
                # –ù–∞–π–¥–µ–Ω –¥—Ä—É–≥–æ–π –∫–æ–¥ —Ç–µ—Å—Ç–∞
                return True

    # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ –¥—Ä—É–≥–æ–≥–æ —Ç–µ—Å—Ç–∞
    search_keywords = [
        "–ø–æ–∫–∞–∂–∏",
        "–Ω–∞–π–¥–∏",
        "–ø–æ–∏—Å–∫",
        "–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ",
        "—á—Ç–æ –∑–∞ —Ç–µ—Å—Ç",
        "—Ä–∞—Å—Å–∫–∞–∂–∏ –ø—Ä–æ",
        "–∞ —á—Ç–æ –Ω–∞—Å—á–µ—Ç",
        "–¥—Ä—É–≥–æ–π —Ç–µ—Å—Ç",
        "–µ—â–µ —Ç–µ—Å—Ç",
        "–∞–Ω–∞–ª–∏–∑ –Ω–∞",
        "—Ç–µ—Å—Ç –Ω–∞",
        "–Ω–∞–π—Ç–∏ —Ç–µ—Å—Ç",
        "–∫–æ–¥ —Ç–µ—Å—Ç–∞",
    ]

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –ø–æ–∏—Å–∫–∞
    for keyword in search_keywords:
        if keyword in query_lower:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –ø—Ä–æ —Ç–µ–∫—É—â–∏–π –ª–∏ —Ç–µ—Å—Ç —Å–ø—Ä–∞—à–∏–≤–∞—é—Ç
            if current_test_code.lower() not in query_lower and not any(
                word in current_test_name for word in query_lower.split()
            ):
                return True

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Ç–∏–ø–æ–≤ –∞–Ω–∞–ª–∏–∑–æ–≤
    test_categories = {
        "–±–∏–æ—Ö–∏–º–∏—è": ["–±–∏–æ—Ö–∏–º", "–∞–ª—Ç", "–∞—Å—Ç", "–∫—Ä–µ–∞—Ç–∏–Ω–∏–Ω", "–º–æ—á–µ–≤–∏–Ω–∞", "–≥–ª—é–∫–æ–∑–∞"],
        "–≥–µ–º–∞—Ç–æ–ª–æ–≥–∏—è": [
            "–æ–∞–∫",
            "–æ–±—â–∏–π –∞–Ω–∞–ª–∏–∑ –∫—Ä–æ–≤–∏",
            "–≥–µ–º–æ–≥–ª–æ–±–∏–Ω",
            "—ç—Ä–∏—Ç—Ä–æ—Ü–∏—Ç—ã",
            "–ª–µ–π–∫–æ—Ü–∏—Ç—ã",
        ],
        "–≥–æ—Ä–º–æ–Ω—ã": ["—Ç—Ç–≥", "—Ç3", "—Ç4", "–∫–æ—Ä—Ç–∏–∑–æ–ª", "—Ç–µ—Å—Ç–æ—Å—Ç–µ—Ä–æ–Ω"],
        "–∏–Ω—Ñ–µ–∫—Ü–∏–∏": ["–ø—Ü—Ä", "–∏—Ñ–∞", "–∞–Ω—Ç–∏—Ç–µ–ª–∞", "–≤–∏—Ä—É—Å", "–±–∞–∫—Ç–µ—Ä–∏–∏"],
        "–º–æ—á–∞": ["–º–æ—á–∞", "–æ–∞–º", "–æ–±—â–∏–π –∞–Ω–∞–ª–∏–∑ –º–æ—á–∏"],
    }

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é —Ç–µ–∫—É—â–µ–≥–æ —Ç–µ—Å—Ç–∞
    current_category = None
    for category, keywords in test_categories.items():
        for keyword in keywords:
            if keyword in current_test_name:
                current_category = category
                break

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —Å–ø—Ä–∞—à–∏–≤–∞—é—Ç –ª–∏ –ø—Ä–æ –¥—Ä—É–≥—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é
    for category, keywords in test_categories.items():
        if category != current_category:
            for keyword in keywords:
                if keyword in query_lower:
                    return True

    return False


__all__ = [
    "questions_router",
    "smart_test_search",
    "format_test_data",
    "format_test_info",
    "format_similar_tests_with_links",
    "QuestionStates",
    "get_dialog_kb",
    "create_test_link",
    "normalize_test_code",
]
