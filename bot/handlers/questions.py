from aiogram import Router, F
from aiogram.types import Message, BufferedInputFile
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import State, StatesGroup
from bot.keyboards import get_cancel_kb, get_menu_by_role, get_dialog_kb
from src.database.db_init import db
from src.data_vectorization import DataProcessor
from models.models_init import qwen3_32b_instruct_free as llm
from langchain.schema import SystemMessage, HumanMessage
import json
import re
import base64

questions_router = Router()

class QuestionStates(StatesGroup):
    waiting_for_question = State()
    in_dialog = State()

@questions_router.message(F.text.in_(["â“ Ð—Ð°Ð´Ð°Ñ‚ÑŒ Ð²Ð¾Ð¿Ñ€Ð¾Ñ", "ðŸ¤– Ð’Ð¾Ð¿Ñ€Ð¾Ñ Ð½ÐµÐ¹Ñ€Ð¾ÑÐµÑ‚Ð¸"]))
async def start_question(message: Message, state: FSMContext):
    """Begin question flow and reset ephemeral memory buffer."""
    user_id = message.from_user.id
    print(f"[INFO] User {user_id} initiated question flow")

    user = await db.get_user(user_id)
    if not user:
        print(f"[WARN] User {user_id} not registered")
        await message.answer(
            "Ð”Ð»Ñ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ñ ÑÑ‚Ð¾Ð¹ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¸ Ð½ÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð¼Ð¾ Ð¿Ñ€Ð¾Ð¹Ñ‚Ð¸ Ñ€ÐµÐ³Ð¸ÑÑ‚Ñ€Ð°Ñ†Ð¸ÑŽ.\n"
            "Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñƒ /start"
        )
        return

    role = user['role'] if 'role' in user else 'client'
    print(f"[INFO] Resolved role for user {user_id}: {role}")

    await db.clear_buffer(user_id)

    prompt = (
        "ðŸ¤– Ð—Ð°Ð´Ð°Ð¹Ñ‚Ðµ Ð²Ð°Ñˆ Ð¿Ñ€Ð¾Ñ„ÐµÑÑÐ¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð²Ð¾Ð¿Ñ€Ð¾Ñ Ð½ÐµÐ¹Ñ€Ð¾ÑÐµÑ‚Ð¸.\n\n"
        "Ð¯ Ð¼Ð¾Ð³Ñƒ Ð¿Ð¾Ð¼Ð¾Ñ‡ÑŒ Ñ:\n"
        "â€¢ Ð˜Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÐµÐ¹ Ð¾ Ð»ÐµÑ‡ÐµÐ½Ð¸Ð¸ Ð¶Ð¸Ð²Ð¾Ñ‚Ð½Ñ‹Ñ…\n"
        "â€¢ ÐšÐ¾Ð½ÑÑƒÐ»ÑŒÑ‚Ð°Ñ†Ð¸ÑÐ¼Ð¸ Ð¿Ð¾ ÑÐ¸Ð¼Ð¿Ñ‚Ð¾Ð¼Ð°Ð¼\n"
        "â€¢ Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸ÑÐ¼Ð¸ Ð¿Ð¾ ÑƒÑ…Ð¾Ð´Ñƒ\n"
        "â€¢ Ð’ÐµÑ‚ÐµÑ€Ð¸Ð½Ð°Ñ€Ð½Ñ‹Ð¼Ð¸ Ð¿Ñ€ÐµÐ¿Ð°Ñ€Ð°Ñ‚Ð°Ð¼Ð¸"
        if role == 'staff' else
        "ðŸ¤– Ð—Ð°Ð´Ð°Ð¹Ñ‚Ðµ Ð²Ð°Ñˆ Ð¿Ñ€Ð¾Ñ„ÐµÑÑÐ¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð²Ð¾Ð¿Ñ€Ð¾Ñ Ð½ÐµÐ¹Ñ€Ð¾ÑÐµÑ‚Ð¸.\n\n"
        "Ð¯ Ð¼Ð¾Ð³Ñƒ Ð¿Ð¾Ð¼Ð¾Ñ‡ÑŒ Ñ:\n"
        "â€¢ Ð˜Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÐµÐ¹ Ð¾ Ñ‚ÐµÑÑ‚Ð°Ñ… Ð¸ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ…\n"
        "â€¢ ÐŸÑ€ÐµÐ°Ð½Ð°Ð»Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¼Ð¸ Ñ‚Ñ€ÐµÐ±Ð¾Ð²Ð°Ð½Ð¸ÑÐ¼Ð¸\n"
        "â€¢ Ð˜Ð½Ñ‚ÐµÑ€Ð¿Ñ€ÐµÑ‚Ð°Ñ†Ð¸ÐµÐ¹ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²\n"
        "â€¢ ÐžÐ±Ñ‰Ð¸Ð¼Ð¸ Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ°Ð¼Ð¸ Ð¿Ð¾ Ð»Ð°Ð±Ð¾Ñ€Ð°Ñ‚Ð¾Ñ€Ð½Ð¾Ð¹ Ð´Ð¸Ð°Ð³Ð½Ð¾ÑÑ‚Ð¸ÐºÐµ"
    )

    await message.answer(prompt, reply_markup=get_cancel_kb())
    await state.set_state(QuestionStates.waiting_for_question)
    print(f"[INFO] State set to waiting_for_question for user {user_id}")

@questions_router.message(QuestionStates.waiting_for_question)
async def process_question(message: Message, state: FSMContext):
    """Handle user question: update memory, fetch RAG context, ask LLM, update memory."""
    user_id = message.from_user.id
    text = message.text.strip()

    if text == "âŒ ÐžÑ‚Ð¼ÐµÐ½Ð°":
        await state.clear()
        user = await db.get_user(user_id)
        role = user['role'] if 'role' in user else 'client'
        await message.answer("ÐžÐ¿ÐµÑ€Ð°Ñ†Ð¸Ñ Ð¾Ñ‚Ð¼ÐµÐ½ÐµÐ½Ð°.", reply_markup=get_menu_by_role(role))
        print(f"[INFO] User {user_id} cancelled question")
        return

    user = await db.get_user(user_id)
    role = user['role'] if 'role' in user else 'client'
    print(f"[INFO] User {user_id} submitted question: {text} (role={role})")

    # Store the original question in the state for follow-ups
    await state.update_data(original_question=text)

    # Process the question with RAG
    answer = await process_user_question(user_id, text, role, is_new_question=True)
    
    await message.answer(answer, reply_markup=get_dialog_kb())
    await state.set_state(QuestionStates.in_dialog)
    print(f"[INFO] State set to in_dialog for user {user_id}")

# @questions_router.message(
#     QuestionStates.in_dialog, 
#     F.text.regexp(r'(?i)(Ñ„Ð¾Ñ‚Ð¾|Ð¿Ð¾ÐºÐ°Ð¶Ð¸|Ð´Ð°Ð¹).*(ÐºÐ¾Ð½Ñ‚ÐµÐ¹Ð½ÐµÑ€|Ð¿Ñ€Ð¾Ð±Ð¸Ñ€Ðº|Ñ‚ÐµÑÑ‚|Ð°Ð½Ð°Ð»Ð¸Ð·)'),
#     flags={"priority": 10}
# )
# async def send_container_image(message: Message, state: FSMContext):
#     """Send container image when specifically requested."""
#     user_id = message.from_user.id
#     processor = DataProcessor()
#     processor.load_vector_store()
    
#     # Get last question from state
#     data = await state.get_data()
#     question = data.get('original_question', '')
    
#     # Search for relevant test
#     hits = processor.search_test(question, top_k=1)
#     if not hits:
#         await message.answer("ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð½Ð°Ð¹Ñ‚Ð¸ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¾ ÐºÐ¾Ð½Ñ‚ÐµÐ¹Ð½ÐµÑ€Ðµ.")
#         return
    
#     doc = hits[0][0]  # Get the document from search results
    
#     if 'container_image_base64' not in doc.metadata:
#         await message.answer("Ð˜Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ ÐºÐ¾Ð½Ñ‚ÐµÐ¹Ð½ÐµÑ€Ð° Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾ Ð´Ð»Ñ ÑÑ‚Ð¾Ð³Ð¾ Ñ‚ÐµÑÑ‚Ð°.")
#         return
    
#     try:
#         image_data = doc.metadata['container_image_base64']
#         if ';base64,' in image_data:
#             image_data = image_data.split(';base64,')[-1]
        
#         image_bytes = base64.b64decode(image_data)
#         await message.answer_photo(
#             BufferedInputFile(image_bytes, "container.jpg"),
#             caption=f"ÐšÐ¾Ð½Ñ‚ÐµÐ¹Ð½ÐµÑ€ Ð´Ð»Ñ Ñ‚ÐµÑÑ‚Ð°: {doc.page_content}"
#         )
#     except Exception as e:
#         await message.answer(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÐºÐµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ: {str(e)}")

@questions_router.message(QuestionStates.in_dialog)
async def handle_dialog(message: Message, state: FSMContext):
    """Handle follow-up questions in dialog mode."""
    user_id = message.from_user.id
    text = message.text.strip()

    if text == "âŒ Ð—Ð°Ð²ÐµÑ€ÑˆÐ¸Ñ‚ÑŒ Ð´Ð¸Ð°Ð»Ð¾Ð³":
        await state.clear()
        user = await db.get_user(user_id)
        role = user['role'] if 'role' in user else 'client'
        await message.answer("Ð”Ð¸Ð°Ð»Ð¾Ð³ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½.", reply_markup=get_menu_by_role(role))
        print(f"[INFO] User {user_id} ended dialog")
        return
    
    if text == "ðŸ”„ ÐÐ¾Ð²Ñ‹Ð¹ Ð²Ð¾Ð¿Ñ€Ð¾Ñ":
        await db.clear_buffer(user_id)
        await message.answer("Ð—Ð°Ð´Ð°Ð¹Ñ‚Ðµ Ð½Ð¾Ð²Ñ‹Ð¹ Ð²Ð¾Ð¿Ñ€Ð¾Ñ:", reply_markup=get_cancel_kb())
        await state.set_state(QuestionStates.waiting_for_question)
        print(f"[INFO] User {user_id} started new question")
        return

    # Get the original question from the state
    data = await state.get_data()
    original_question = data.get('original_question', '')

    user = await db.get_user(user_id)
    role = user['role'] if 'role' in user else 'client'
    print(f"[INFO] User {user_id} asked follow-up: {text} (role={role})")

    # Process follow-up without RAG (reuse original question context)
    answer = await process_user_question(user_id, text, role, is_new_question=False)
    
    await message.answer(answer, reply_markup=get_dialog_kb())
    print(f"[INFO] Follow-up answer sent to user {user_id}")

async def process_user_question(user_id: int, text: str, role: str, is_new_question: bool) -> str:
    """Process user question and return AI response."""
    await db.add_request_stat(user_id, "question", text[:200])
    await db.add_memory(user_id, 'buffer', f"User: {text}")

    summary = await db.get_latest_summary(user_id) or ""
    buffer = await db.get_buffer(user_id)

    rag_context = ""
    rag_hits = []  # Initialize empty list for follow-ups
    
    if is_new_question:
        processor = DataProcessor()
        processor.load_vector_store()
        rag_hits = processor.search_test(text, top_k=5)

        rag_blocks = []
        for doc, score in rag_hits:
            clean_meta = {k: v for k, v in doc.metadata.items() if k != 'container_image_base64'}
            meta_json = json.dumps(clean_meta, ensure_ascii=False, sort_keys=True)
            rag_blocks.append(f"Ð¢ÐµÑÑ‚: {doc.page_content}\nÐœÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ðµ: {meta_json}")
        rag_context = "\n\n---\n\n".join(rag_blocks)

    memory_section = ""
    if summary:
        memory_section += f"Ð¡Ð²Ð¾Ð´ÐºÐ° Ð¿Ñ€ÐµÐ´Ñ‹Ð´ÑƒÑ‰Ð¸Ñ… ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹: {summary}\n\n"
    if buffer:
        memory_section += "ÐŸÐ¾ÑÐ»ÐµÐ´Ð½Ð¸Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ:\n" + "\n".join(buffer) + "\n\n"

    system_msg = SystemMessage(
        content="Ð¢Ñ‹ â€” Ð²ÐµÑ‚ÐµÑ€Ð¸Ð½Ð°Ñ€Ð½Ñ‹Ð¹ Ð¿Ð¾Ð¼Ð¾Ñ‰Ð½Ð¸Ðº. Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ Ð¿Ð°Ð¼ÑÑ‚ÑŒ Ð¸ Ð¿Ñ€ÐµÐ°Ð½Ð°Ð»Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÑƒÑŽ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð´Ð»Ñ Ð¾Ñ‚Ð²ÐµÑ‚Ð°. Ð•ÑÐ»Ð¸ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸ Ð½ÐµÑ‚ - Ñ‡ÐµÑÑ‚Ð½Ð¾ ÑÐºÐ°Ð¶Ð¸ Ð¾Ð± ÑÑ‚Ð¾Ð¼. Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ: **Ð¶Ð¸Ñ€Ð½Ñ‹Ð¹** Ð´Ð»Ñ Ð²Ð°Ð¶Ð½Ð¾Ð³Ð¾, _ÐºÑƒÑ€ÑÐ¸Ð²_ Ð´Ð»Ñ Ñ‚ÐµÑ€Ð¼Ð¸Ð½Ð¾Ð². Ð‘ÑƒÐ´ÑŒ ÐºÑ€Ð°Ñ‚ÐºÐ¸Ð¼ Ð¸ Ð¿Ñ€Ð¾Ñ„ÐµÑÑÐ¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¼. Ð”ÐµÐ»Ð°Ð¹ Ð¿Ñ€Ð¸ÑÑ‚Ð½Ð¾Ðµ Ð¾Ñ„Ð¾Ñ€Ð¼Ð»ÐµÐ½Ð¸Ðµ Ð´Ð»Ñ Ñ‚ÐµÐ»ÐµÐ³Ñ€Ð°Ð¼Ð¼. Ð‘ÐµÐ· Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ñ Markdown"
    )
    user_msg = HumanMessage(
        content=(
            f"{memory_section}"
            f"ÐšÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ Ð¿Ñ€ÐµÐ°Ð½Ð°Ð»Ð¸Ñ‚Ð¸ÐºÐ¸:\n{rag_context}\n\n"
            f"Ð’Ð¾Ð¿Ñ€Ð¾Ñ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ: {text}\n\n"
            "ÐžÑ‚Ð²ÐµÑ‚ÑŒ Ð½Ð° Ñ€ÑƒÑÑÐºÐ¾Ð¼ ÑÐ·Ñ‹ÐºÐµ, ÐºÑ€Ð°Ñ‚ÐºÐ¾ Ð¸ Ð¿Ð¾ Ð´ÐµÐ»Ñƒ."
        )
    )

    print(f"[INFO] Sending prompt to LLM for user {user_id}")
    response = await llm.agenerate([[system_msg, user_msg]])

    def markdown_to_html(text: str) -> str:
        """Convert basic Markdown to Telegram-compatible HTML."""
        # Bold: **text** -> <b>text</b>
        text = re.sub(r'\*\*(.+?)\*\*', r'<b>\1</b>', text)
        # Italic: _text_ -> <i>text</i>
        text = re.sub(r'_(.+?)_', r'<i>\1</i>', text)
        # Code: `text` -> <code>text</code>
        text = re.sub(r'`(.+?)`', r'<code>\1</code>', text)
        return text

    answer = response.generations[0][0].text.strip()
    print(f"[INFO] Received LLM answer for user {user_id}")
    answer = markdown_to_html(answer)  # Convert Markdown to HTML
    print(f"[INFO] Converted Markdown to HTML for user {user_id}")
    await db.add_memory(user_id, 'buffer', f"Bot: {answer}")
    print(f"[INFO] Bot response buffered for user {user_id}")

    return answer

