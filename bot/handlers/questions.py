from aiogram import Router, F
from aiogram.types import Message, CallbackQuery, InlineKeyboardMarkup, InlineKeyboardButton, InputMediaPhoto
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import State, StatesGroup
from aiogram.filters import Command
from bot.keyboards import get_menu_by_role, get_dialog_kb, get_back_to_menu_kb, get_search_type_kb
from langchain.schema import SystemMessage, HumanMessage, Document
import pytz
import asyncio
import base64
import urllib.parse
import html
import re
from typing import Optional, Dict, List, Tuple
from fuzzywuzzy import fuzz, process
from datetime import datetime
from src.database.db_init import db
from src.data_vectorization import DataProcessor
from models.models_init import Google_Gemini_2_5_Flash_Lite as llm

BOT_USERNAME = "AI_VET_UNION_BOT"

LOADING_GIF_ID = "CgACAgIAAxkBAAMIaGr_qy1Wxaw2VrBrm3dwOAkYji4AAu54AAKmqHlJAtZWBziZvaA2BA"
# LOADING_GIF_ID = "CgACAgIAAxkBAAIBFGiBcXtGY7OZvr3-L1dZIBRNqSztAALueAACpqh5Scn4VmIRb4UjNgQ"
# LOADING_GIF_ID = "CgACAgIAAxkBAAMMaHSq3vqxq2RuMMj-DIMvldgDjfkAAu54AAKmqHlJCNcCjeoHRJI2BA"
questions_router = Router()

def fix_bold(text: str) -> str:
    """–ó–∞–º–µ–Ω—è–µ—Ç markdown –∂–∏—Ä–Ω—ã–π —Ç–µ–∫—Å—Ç –Ω–∞ HTML."""
    import re
    # –ó–∞–º–µ–Ω—è–µ–º **—Ç–µ–∫—Å—Ç** –Ω–∞ <b>—Ç–µ–∫—Å—Ç</b>
    text = re.sub(r'\*\*([^\*]+)\*\*', r'<b>\1</b>', text)
    return text

class TestCallback:
    @staticmethod
    def pack(action: str, test_code: str) -> str:
        return f"{action}:{test_code}"
    
    @staticmethod
    def unpack(callback_data: str) -> Tuple[str, str]:
        parts = callback_data.split(":", 1)
        return parts[0] if len(parts) > 0 else "", parts[1] if len(parts) > 1 else ""

class QuestionStates(StatesGroup):
    waiting_for_search_type = State()
    waiting_for_code = State()
    waiting_for_name = State()
    in_dialog = State()
    processing = State()
    clarifying_search = State()

# –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–æ–∏—Å–∫–∞
class SearchContext:
    def __init__(self):
        self.original_query = ""
        self.search_attempts = []
        self.candidate_tests = []
        self.clarification_step = 0
        self.filters = {}

# –°–ª–æ–≤–∞—Ä—å –∞–±–±—Ä–µ–≤–∏–∞—Ç—É—Ä –¥–ª—è —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤
TEST_ABBREVIATIONS = {
    "–û–ê–ö": "–æ–±—â–∏–π –∞–Ω–∞–ª–∏–∑ –∫—Ä–æ–≤–∏ –∫–ª–∏–Ω–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∫—Ä–æ–≤–∏ –≥–µ–º–∫–∞ –≥–µ–º–∞—Ç–æ–ª–æ–≥–∏—è",
    "–ë–•": "–±–∏–æ—Ö–∏–º–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –±–∏–æ—Ö–∏–º–∏—è –∫—Ä–æ–≤–∏",
    "–û–ê–ú": "–æ–±—â–∏–π –∞–Ω–∞–ª–∏–∑ –º–æ—á–∏",
    "–°–û–≠": "—Å–∫–æ—Ä–æ—Å—Ç—å –æ—Å–µ–¥–∞–Ω–∏—è —ç—Ä–∏—Ç—Ä–æ—Ü–∏—Ç–æ–≤",
    "–ê–õ–¢": "–∞–ª–∞–Ω–∏–Ω–∞–º–∏–Ω–æ—Ç—Ä–∞–Ω—Å—Ñ–µ—Ä–∞–∑–∞",
    "–ê–°–¢": "–∞—Å–ø–∞—Ä—Ç–∞—Ç–∞–º–∏–Ω–æ—Ç—Ä–∞–Ω—Å—Ñ–µ—Ä–∞–∑–∞",
    "–¢–¢–ì": "—Ç–∏—Ä–µ–æ—Ç—Ä–æ–ø–Ω—ã–π –≥–æ—Ä–º–æ–Ω",
    "–¢4": "—Ç–∏—Ä–æ–∫—Å–∏–Ω",
    "–ü–¶–†": "–ø–æ–ª–∏–º–µ—Ä–∞–∑–Ω–∞—è —Ü–µ–ø–Ω–∞—è —Ä–µ–∞–∫—Ü–∏—è",
    "–ò–§–ê": "–∏–º–º—É–Ω–æ—Ñ–µ—Ä–º–µ–Ω—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑",
    "–ì–ï–ú–ö–ê": "–æ–±—â–∏–π –∞–Ω–∞–ª–∏–∑ –∫—Ä–æ–≤–∏ –∫–ª–∏–Ω–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∫—Ä–æ–≤–∏ –æ–∞–∫ –≥–µ–º–∞—Ç–æ–ª–æ–≥–∏—è",
    "–ì–ï–ú–ê–¢–û–õ–û–ì–ò–Ø": "–æ–±—â–∏–π –∞–Ω–∞–ª–∏–∑ –∫—Ä–æ–≤–∏ –∫–ª–∏–Ω–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∫—Ä–æ–≤–∏ –æ–∞–∫ –≥–µ–º–∫–∞",
    "–ì–ï–ú–ê–¢–ö–ê": "–æ–±—â–∏–π –∞–Ω–∞–ª–∏–∑ –∫—Ä–æ–≤–∏ –∫–ª–∏–Ω–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∫—Ä–æ–≤–∏ –æ–∞–∫ –≥–µ–º–∫–∞ –≥–µ–º–∞—Ç–æ–ª–æ–≥–∏—è",
    "—Ü–∏—Ç–æ–ª–æ–≥–∏—è": "–¶–∏—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ",
}

def is_test_code_pattern(text: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –ª–∏ —Ç–µ–∫—Å—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—É –∫–æ–¥–∞ —Ç–µ—Å—Ç–∞."""
    text = text.strip().upper().replace(' ', '')
    
    patterns = [
        r'^[A–ê][N–ù]\d+',  # AN –∏–ª–∏ –ê–ù + —Ü–∏—Ñ—Ä—ã
        r'^[A–ê][N–ù]\d+[A-Z–ê-–Ø\-]+',  # AN + —Ü–∏—Ñ—Ä—ã + —Å—É—Ñ—Ñ–∏–∫—Å
        r'^\d{1,4}$',  # –¢–æ–ª—å–∫–æ —Ü–∏—Ñ—Ä—ã (–¥–æ 4 –∑–Ω–∞–∫–æ–≤)
        r'^\d+[A-Z–ê-–Ø\-]+$',  # –¶–∏—Ñ—Ä—ã + –±—É–∫–≤–µ–Ω–Ω—ã–π —Å—É—Ñ—Ñ–∏–∫—Å
    ]
    
    for pattern in patterns:
        if re.match(pattern, text):
            return True
            
    return False

def simple_translit(text: str) -> str:
    """–ü—Ä–æ—Å—Ç–∞—è —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏—è –¥–ª—è deep links."""
    translit_map = {
        '–ê': 'A', '–ë': 'B', '–í': 'V', '–ì': 'G', '–î': 'D', '–ï': 'E', '–Å': 'YO',
        '–ñ': 'ZH', '–ó': 'Z', '–ò': 'I', '–ô': 'Y', '–ö': 'K', '–õ': 'L', '–ú': 'M',
        '–ù': 'N', '–û': 'O', '–ü': 'P', '–†': 'R', '–°': 'S', '–¢': 'T', '–£': 'U',
        '–§': 'F', '–•': 'KH', '–¶': 'TS', '–ß': 'CH', '–®': 'SH', '–©': 'SCH',
        '–™': '', '–´': 'YI', '–¨': '', '–≠': 'EH', '–Æ': 'YU', '–Ø': 'YA'
    }
    
    result = ''
    for char in text.upper():
        if char in translit_map:
            result += translit_map[char]
        else:
            result += char
    return result

def reverse_translit(text: str) -> str:
    """–û–±—Ä–∞—Ç–Ω–∞—è —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏—è –¥–ª—è deep links."""
    # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É –Ω–∞ None –∏ –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É
    if not text:
        return ""
    
    text = text.upper()
    
    # –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–ª—É—á–∞–∏ –¥–ª—è –ø–æ–ª–Ω—ã—Ö –∫–æ–¥–æ–≤
    special_cases = {
        'ANDOKR': 'AN–î–û–ö–†',
        'AN515GIEH': 'AN515–ì–ò–≠',
        'AN506GIEH': 'AN506–ì–ò–≠',
        'AN513GIEH': 'AN513–ì–ò–≠',
        'AN515GIEH': 'AN515–ì–ò–≠',
        'AN712BTK': 'AN712–ë–¢–ö'
    }
    
    if text in special_cases:
        return special_cases[text]
    
    # –û–±—â–∞—è –æ–±—Ä–∞—Ç–Ω–∞—è —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏—è –¥–ª—è —Å—É—Ñ—Ñ–∏–∫—Å–æ–≤
    import re
    match = re.match(r'^(AN\d+)(.+)$', text)
    if match:
        prefix = match.group(1)
        suffix = match.group(2)
        
        # –°–ª–æ–≤–∞—Ä—å —Å—É—Ñ—Ñ–∏–∫—Å–æ–≤
        suffix_map = {
            'GIEH': '–ì–ò–≠',
            'GII': '–ì–ò–ò', 
            'BTK': '–ë–¢–ö',
            'BAL': '–ë–ê–õ',
            'KLSCH': '–ö–õ–©',
            'VPT': '–í–ü–¢',
            'GLZ': '–ì–õ–ó',
            'GSK': '–ì–°–ö',
            'KM': '–ö–ú',
            'KR': '–ö–†',
            'LIK': '–õ–ò–ö',
            'NOS': '–ù–û–°',
            'PRK': '–ü–†–ö',
            'ROT': '–†–û–¢',
            'SIN': '–°–ò–ù',
            'FK': '–§–ö',
            'ASP': '–ê–°–ü',
            'OBS': '–û–ë–°'
        }
        
        if suffix in suffix_map:
            return prefix + suffix_map[suffix]
    
    return text

def create_test_link(test_code: str) -> str:
    """–°–æ–∑–¥–∞–µ—Ç deep link –¥–ª—è —Ç–µ—Å—Ç–∞."""
    safe_code = simple_translit(test_code)
    return f"https://t.me/{BOT_USERNAME}?start=test_{safe_code}"

def normalize_test_code(text: str) -> str:
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –≤–≤–µ–¥–µ–Ω–Ω—ã–π –∫–æ–¥ —Ç–µ—Å—Ç–∞."""
    # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É –Ω–∞ None –∏ –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É
    if not text:
        return ""
    
    text = text.strip().upper().replace(' ', '')
    
    # –ó–∞–º–µ–Ω—è–µ–º –∫–∏—Ä–∏–ª–ª–∏—Ü—É –Ω–∞ –ª–∞—Ç–∏–Ω–∏—Ü—É –≤ –ø—Ä–µ—Ñ–∏–∫—Å–µ AN/–ê–ù
    text = text.replace('–ê–ù', 'AN').replace('–êN', 'AN').replace('A–ù', 'AN')
    
    # –ï—Å–ª–∏ —Ç–æ–ª—å–∫–æ —Ü–∏—Ñ—Ä—ã - –¥–æ–±–∞–≤–ª—è–µ–º AN
    if text.isdigit():
        text = f"AN{text}"
    # –ï—Å–ª–∏ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å —Ü–∏—Ñ—Ä - –¥–æ–±–∞–≤–ª—è–µ–º AN –≤ –Ω–∞—á–∞–ª–æ
    elif re.match(r'^\d', text):
        text = f"AN{text}"
    
    return text

async def get_test_container_photos(test_data: Dict) -> List[Dict]:
    """–ü–æ–ª—É—á–∞–µ—Ç –≤—Å–µ —Ñ–æ—Ç–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∞"""
    container_string = str(test_data.get('container_number', ''))
    
    # –ü–∞—Ä—Å–∏–º –Ω–æ–º–µ—Ä–∞ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤
    container_numbers = db.parse_container_numbers(container_string)
    
    photos = []
    for num in container_numbers:
        file_id = await db.get_container_photo(num)
        if file_id:
            photos.append({
                'number': num,
                'file_id': file_id
            })
    
    return photos

async def show_container_photos(message: Message, test_data: Dict):
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –≤—Å–µ —Ñ–æ—Ç–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∞"""
    photos = await get_test_container_photos(test_data)
    
    if photos:
        # –ï—Å–ª–∏ –æ–¥–Ω–æ —Ñ–æ—Ç–æ
        if len(photos) == 1:
            photo = photos[0]
            caption = (
                f"üß™ <b>–ö–æ–Ω—Ç–µ–π–Ω–µ—Ä ‚Ññ{photo['number']}</b>\n"
                f"‚ùÑÔ∏è –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ —Ö—Ä–∞–Ω–µ–Ω–∏—è: {test_data['storage_temp']}"
            )
            try:
                await message.answer_photo(
                    photo=photo['file_id'],
                    caption=caption,
                    parse_mode="HTML"
                )
            except Exception as e:
                print(f"[ERROR] Failed to send container photo: {e}")
        
        # –ï—Å–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ–æ—Ç–æ - –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –º–µ–¥–∏–∞ –≥—Ä—É–ø–ø—É
        elif len(photos) > 1:
            media_group = []
            for i, photo in enumerate(photos):
                caption = f"üß™ <b>–ö–æ–Ω—Ç–µ–π–Ω–µ—Ä ‚Ññ{photo['number']}</b>"
                if i == 0:  # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É —Ç–æ–ª—å–∫–æ –∫ –ø–µ—Ä–≤–æ–º—É —Ñ–æ—Ç–æ
                    caption += f"\n‚ùÑÔ∏è –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ —Ö—Ä–∞–Ω–µ–Ω–∏—è: {test_data['storage_temp']}"
                
                media_group.append(
                    InputMediaPhoto(
                        media=photo['file_id'],
                        caption=caption,
                        parse_mode="HTML"
                    )
                )
            
            try:
                await message.answer_media_group(media_group)
            except Exception as e:
                print(f"[ERROR] Failed to send container photos: {e}")

def calculate_fuzzy_score(query: str, test_code: str, test_name: str = "") -> float:
    """–£–ª—É—á—à–µ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –ø–æ –∫–æ–¥—É —Ç–µ—Å—Ç–∞."""
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –æ–±–∞ –∑–Ω–∞—á–µ–Ω–∏—è
    query = normalize_test_code(query)
    test_code = test_code.upper().strip()
    
    # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
    if query == test_code:
        return 100.0
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º —á–∏—Å–ª–∞ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞ –∏ –∫–æ–¥–∞
    query_digits = ''.join(c for c in query if c.isdigit())
    code_digits = ''.join(c for c in test_code if c.isdigit())
    
    # –ï—Å–ª–∏ –≤ –∑–∞–ø—Ä–æ—Å–µ –µ—Å—Ç—å —Ü–∏—Ñ—Ä—ã
    if query_digits:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Ü–∏—Ñ—Ä
        if code_digits == query_digits:
            return 90.0  # –í—ã—Å–æ–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è —Ü–∏—Ñ—Ä
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è –ª–∏ –∫–æ–¥ —Å —ç—Ç–∏—Ö —Ü–∏—Ñ—Ä
        elif code_digits.startswith(query_digits):
            # –ß–µ–º –±–ª–∏–∂–µ –¥–ª–∏–Ω–∞, —Ç–µ–º –≤—ã—à–µ score
            length_ratio = len(query_digits) / len(code_digits) if code_digits else 0
            return 70.0 + (length_ratio * 20)  # –û—Ç 70 –¥–æ 90
        # –ï—Å–ª–∏ —Ü–∏—Ñ—Ä—ã –Ω–µ —Å–æ–≤–ø–∞–¥–∞—é—Ç - –Ω–∏–∑–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
        else:
            return 0.0
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è –ª–∏ –∫–æ–¥ —Ç–µ—Å—Ç–∞ —Å –∑–∞–ø—Ä–æ—Å–∞ (–ø—Ä–µ—Ñ–∏–∫—Å)
    if test_code.startswith(query):
        return 85.0
    
    # –ë–∞–∑–æ–≤—ã–π fuzzy score —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ—Ç —Ü–∏—Ñ—Ä –≤ –∑–∞–ø—Ä–æ—Å–µ
    if not query_digits:
        code_score = fuzz.ratio(query, test_code)
        
        # –ë–æ–Ω—É—Å –∑–∞ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø—Ä–µ—Ñ–∏–∫—Å–∞ AN
        if query.startswith("AN") and test_code.startswith("AN"):
            code_score += 10
        
        return min(100, code_score)
    
    return 0.0 

async def fuzzy_test_search(processor: DataProcessor, query: str, threshold: float = 30) -> List[Tuple[Document, float]]:
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π fuzzy –ø–æ–∏—Å–∫ —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –ø–æ —Ü–∏—Ñ—Ä–∞–º."""
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∑–∞–ø—Ä–æ—Å
    query = normalize_test_code(query)
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ü–∏—Ñ—Ä—ã –∏–∑ –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
    query_digits = ''.join(c for c in query if c.isdigit())
    
    # –ü–æ–ª—É—á–∞–µ–º —Ç–µ—Å—Ç—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    all_tests = processor.search_test(query="", top_k=2000)
    
    fuzzy_results = []
    seen_codes = set()
    
    for doc, _ in all_tests:
        test_code = doc.metadata.get('test_code', '')
        test_name = doc.metadata.get('test_name', '')
        
        if test_code in seen_codes:
            continue
        
        # –í—ã—á–∏—Å–ª—è–µ–º score
        score = calculate_fuzzy_score(query, test_code, test_name)
        
        if score >= threshold:
            fuzzy_results.append((doc, score))
            seen_codes.add(test_code)
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–±—ã–≤–∞–Ω–∏—é score
    fuzzy_results.sort(key=lambda x: x[1], reverse=True)
    
    # –ï—Å–ª–∏ –µ—Å—Ç—å —Ü–∏—Ñ—Ä—ã –≤ –∑–∞–ø—Ä–æ—Å–µ, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ª—å–∫–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    if query_digits:
        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã - –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Å —Å–æ–≤–ø–∞–¥–∞—é—â–∏–º–∏ –∏–ª–∏ –Ω–∞—á–∏–Ω–∞—é—â–∏–º–∏—Å—è —Ü–∏—Ñ—Ä–∞–º–∏
        filtered_results = []
        for doc, score in fuzzy_results:
            code_digits = ''.join(c for c in doc.metadata.get('test_code', '') if c.isdigit())
            if code_digits.startswith(query_digits):
                filtered_results.append((doc, score))
        return filtered_results[:30]
    
    return fuzzy_results[:30]

async def check_if_needs_new_search(query: str, current_test_data: Dict) -> bool:
    """–£–ª—É—á—à–µ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ - –Ω—É–∂–µ–Ω –ª–∏ –Ω–æ–≤—ã–π –ø–æ–∏—Å–∫."""
    
    if not current_test_data:
        return True
    
    query_upper = query.upper().strip()
    query_lower = query.lower().strip()
    current_test_code = current_test_data.get('test_code', '').upper()
    current_test_name = current_test_data.get('test_name', '').lower()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è –ª–∏ –∫–æ–¥ –¥—Ä—É–≥–æ–≥–æ —Ç–µ—Å—Ç–∞
    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫–æ–¥–æ–≤ —Ç–µ—Å—Ç–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ
    code_patterns = [
        r'\b[A–ê][N–ù]\d+[–ê-–ØA-Z]*\b',  # AN —Å —Ü–∏—Ñ—Ä–∞–º–∏ –∏ –≤–æ–∑–º–æ–∂–Ω—ã–º —Å—É—Ñ—Ñ–∏–∫—Å–æ–º
        r'\b\d{1,4}[–ê-–ØA-Z]+\b',       # –¶–∏—Ñ—Ä—ã —Å –±—É–∫–≤–µ–Ω–Ω—ã–º —Å—É—Ñ—Ñ–∏–∫—Å–æ–º
        r'\b[A–ê][N–ù]\s*\d+\b',         # AN —Å –ø—Ä–æ–±–µ–ª–æ–º –∏ —Ü–∏—Ñ—Ä–∞–º–∏
        r'\b–∞–Ω\s*\d+\b',               # –∞–Ω –≤ –Ω–∏–∂–Ω–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ
    ]
    
    for pattern in code_patterns:
        matches = re.findall(pattern, query_upper, re.IGNORECASE)
        for match in matches:
            normalized_match = normalize_test_code(match)
            if normalized_match != current_test_code:
                # –ù–∞–π–¥–µ–Ω –¥—Ä—É–≥–æ–π –∫–æ–¥ —Ç–µ—Å—Ç–∞
                return True
    
    # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ –¥—Ä—É–≥–æ–≥–æ —Ç–µ—Å—Ç–∞
    search_keywords = [
        '–ø–æ–∫–∞–∂–∏', '–Ω–∞–π–¥–∏', '–ø–æ–∏—Å–∫', '–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ', '—á—Ç–æ –∑–∞ —Ç–µ—Å—Ç',
        '—Ä–∞—Å—Å–∫–∞–∂–∏ –ø—Ä–æ', '–∞ —á—Ç–æ –Ω–∞—Å—á–µ—Ç', '–¥—Ä—É–≥–æ–π —Ç–µ—Å—Ç', '–µ—â–µ —Ç–µ—Å—Ç',
        '–∞–Ω–∞–ª–∏–∑ –Ω–∞', '—Ç–µ—Å—Ç –Ω–∞', '–Ω–∞–π—Ç–∏ —Ç–µ—Å—Ç', '–∫–æ–¥ —Ç–µ—Å—Ç–∞'
    ]
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –ø–æ–∏—Å–∫–∞
    for keyword in search_keywords:
        if keyword in query_lower:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –ø—Ä–æ —Ç–µ–∫—É—â–∏–π –ª–∏ —Ç–µ—Å—Ç —Å–ø—Ä–∞—à–∏–≤–∞—é—Ç
            if current_test_code.lower() not in query_lower and \
               not any(word in current_test_name for word in query_lower.split()):
                return True
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Ç–∏–ø–æ–≤ –∞–Ω–∞–ª–∏–∑–æ–≤
    test_categories = {
        '–±–∏–æ—Ö–∏–º–∏—è': ['–±–∏–æ—Ö–∏–º', '–∞–ª—Ç', '–∞—Å—Ç', '–∫—Ä–µ–∞—Ç–∏–Ω–∏–Ω', '–º–æ—á–µ–≤–∏–Ω–∞', '–≥–ª—é–∫–æ–∑–∞'],
        '–≥–µ–º–∞—Ç–æ–ª–æ–≥–∏—è': ['–æ–∞–∫', '–æ–±—â–∏–π –∞–Ω–∞–ª–∏–∑ –∫—Ä–æ–≤–∏', '–≥–µ–º–æ–≥–ª–æ–±–∏–Ω', '—ç—Ä–∏—Ç—Ä–æ—Ü–∏—Ç—ã', '–ª–µ–π–∫–æ—Ü–∏—Ç—ã'],
        '–≥–æ—Ä–º–æ–Ω—ã': ['—Ç—Ç–≥', '—Ç3', '—Ç4', '–∫–æ—Ä—Ç–∏–∑–æ–ª', '—Ç–µ—Å—Ç–æ—Å—Ç–µ—Ä–æ–Ω'],
        '–∏–Ω—Ñ–µ–∫—Ü–∏–∏': ['–ø—Ü—Ä', '–∏—Ñ–∞', '–∞–Ω—Ç–∏—Ç–µ–ª–∞', '–≤–∏—Ä—É—Å', '–±–∞–∫—Ç–µ—Ä–∏–∏'],
        '–º–æ—á–∞': ['–º–æ—á–∞', '–æ–∞–º', '–æ–±—â–∏–π –∞–Ω–∞–ª–∏–∑ –º–æ—á–∏'],
    }
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é —Ç–µ–∫—É—â–µ–≥–æ —Ç–µ—Å—Ç–∞
    current_category = None
    for category, keywords in test_categories.items():
        for keyword in keywords:
            if keyword in current_test_name:
                current_category = category
                break
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —Å–ø—Ä–∞—à–∏–≤–∞—é—Ç –ª–∏ –ø—Ä–æ –¥—Ä—É–≥—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é
    for category, keywords in test_categories.items():
        if category != current_category:
            for keyword in keywords:
                if keyword in query_lower:
                    return True
    
    return False

def create_similar_tests_keyboard(similar_tests: List[Tuple[Document, float]], current_test_code: str = None) -> InlineKeyboardMarkup:
    """–°–æ–∑–¥–∞–µ—Ç –∫–æ–º–ø–∞–∫—Ç–Ω—É—é inline –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É —Å –ø–æ—Ö–æ–∂–∏–º–∏ —Ç–µ—Å—Ç–∞–º–∏."""
    keyboard = []
    row = []
    
    count = 0
    for doc, score in similar_tests:
        test_code = doc.metadata.get('test_code', '')
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ç–µ–∫—É—â–∏–π —Ç–µ—Å—Ç
        if current_test_code and test_code == current_test_code:
            continue
        
        # –°–æ–∑–¥–∞–µ–º –∫–æ–º–ø–∞–∫—Ç–Ω—É—é –∫–Ω–æ–ø–∫—É —Ç–æ–ª—å–∫–æ —Å –∫–æ–¥–æ–º
        button = InlineKeyboardButton(
            text=test_code,
            callback_data=TestCallback.pack("show_test", test_code)
        )
        
        row.append(button)
        count += 1
        
        # –ü–æ 4 –∫–Ω–æ–ø–∫–∏ –≤ —Ä—è–¥ –¥–ª—è –∫–æ–º–ø–∞–∫—Ç–Ω–æ—Å—Ç–∏
        if len(row) >= 4:
            keyboard.append(row)
            row = []
        
        # –ú–∞–∫—Å–∏–º—É–º 20 –∫–Ω–æ–ø–æ–∫ (5 —Ä—è–¥–æ–≤ –ø–æ 4)
        if count >= 20:
            break
    
    # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è –∫–Ω–æ–ø–∫–∏
    if row:
        keyboard.append(row)
    
    
    return InlineKeyboardMarkup(inline_keyboard=keyboard)

@questions_router.message(Command("test_link"))
async def test_link_generation(message: Message):
    """–¢–µ—Å—Ç–æ–≤–∞—è –∫–æ–º–∞–Ω–¥–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å—Å—ã–ª–æ–∫"""
    test_codes = ["AN506–ì–ò–≠", "AN511", "AN512-A", "AN712–ë–¢–ö"]
    
    response = "üîó –¢–µ—Å—Ç–æ–≤—ã–µ —Å—Å—ã–ª–∫–∏:\n\n"
    for code in test_codes:
        link = create_test_link(code)
        response += f"–ö–æ–¥: <code>{code}</code>\n–°—Å—ã–ª–∫–∞: <a href='{link}'>–ù–∞–∂–º–∏—Ç–µ –∑–¥–µ—Å—å</a>\n\n"
    
    await message.answer(response, parse_mode="HTML", disable_web_page_preview=True)

@questions_router.callback_query(F.data == "close_keyboard")
async def handle_close_keyboard(callback: CallbackQuery):
    await callback.answer()
    await callback.message.edit_reply_markup(reply_markup=None)

def format_similar_tests_text(similar_tests: List[Tuple[Document, float]], max_display: int = 5) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –ø–æ—Ö–æ–∂–∏—Ö —Ç–µ—Å—Ç–∞—Ö."""
    if not similar_tests:
        return ""
    
    text = "\n<b>üìã –ü–æ—Ö–æ–∂–∏–µ —Ç–µ—Å—Ç—ã:</b>\n"
    for doc, score in similar_tests[:max_display]:
        test_code = doc.metadata.get('test_code', '')
        test_name = doc.metadata.get('test_name', '')
        # –°–æ–∫—Ä–∞—â–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –µ—Å–ª–∏ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ
        if len(test_name) > 50:
            test_name = test_name[:47] + "..."
        text += f"‚Ä¢ <code>{test_code}</code> - {test_name}\n"
    
    if len(similar_tests) > max_display:
        text += f"\n<i>–ü–æ–∫–∞–∑–∞–Ω—ã {max_display} –∏–∑ {len(similar_tests)} –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö</i>"
    
    return text

def format_similar_tests_with_links(similar_tests: List[Tuple[Document, float]], max_display: int = 5) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç —Å –∫–ª–∏–∫–∞–±–µ–ª—å–Ω—ã–º–∏ —Å—Å—ã–ª–∫–∞–º–∏ –Ω–∞ –ø–æ—Ö–æ–∂–∏–µ —Ç–µ—Å—Ç—ã."""
    if not similar_tests:
        return ""
    
    text = "\n<b>üìã –ü–æ—Ö–æ–∂–∏–µ —Ç–µ—Å—Ç—ã (–Ω–∞–∂–º–∏—Ç–µ –Ω–∞ –∫–æ–¥):</b>\n"
    for doc, score in similar_tests[:max_display]:
        test_code = doc.metadata.get('test_code', '')
        test_name = doc.metadata.get('test_name', '')
        if len(test_name) > 40:
            test_name = test_name[:37] + "..."
        
        # –°–æ–∑–¥–∞–µ–º –∫–ª–∏–∫–∞–±–µ–ª—å–Ω—É—é —Å—Å—ã–ª–∫—É
        link = create_test_link(test_code)
        text += f"‚Ä¢ <a href='{link}'>{test_code}</a> - {test_name}\n"
    
    if len(similar_tests) > max_display:
        text += f"\n<i>–ü–æ–∫–∞–∑–∞–Ω—ã {max_display} –∏–∑ {len(similar_tests)} –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö</i>"
    
    return text

def generate_test_code_variants(text: str) -> list[str]:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –Ω–∞–ø–∏—Å–∞–Ω–∏—è –∫–æ–¥–∞ —Ç–µ—Å—Ç–∞."""
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤—Ö–æ–¥–Ω–æ–π —Ç–µ–∫—Å—Ç
    text = normalize_test_code(text)
    variants = [text]  # –û—Ä–∏–≥–∏–Ω–∞–ª

    cyrillic_to_latin = {
        '–ê': 'A', '–ë': 'B', '–í': ['V', 'W', 'B'], '–ì': 'G', '–î': 'D',
        '–ï': ['E', 'I'], '–Å': ['E', 'I'], '–ñ': ['J', 'ZH'], '–ó': ['Z', 'S', 'C'],  
        '–ò': ['I', 'E', 'Y'], '–ô': ['Y', 'I'], '–ö': ['K', 'C', 'Q'], '–õ': 'L',
        '–ú': 'M', '–ù': ['N', 'H'], '–û': 'O', '–ü': 'P', '–†': ['R', 'P'],
        '–°': ['S', 'C'], '–¢': 'T', '–£': ['U', 'Y', 'W'], '–§': 'F',
        '–•': ['H', 'X'], '–¶': ['C', 'TS'], '–ß': 'CH', '–®': 'SH', '–©': 'SCH',
        '–´': ['Y', 'I'], '–≠': ['E', 'A'], '–Æ': ['U', 'YU'], '–Ø': ['YA', 'A']
    }
    
    # –õ–∞—Ç–∏–Ω–∏—Ü–∞ -> –∫–∏—Ä–∏–ª–ª–∏—Ü–∞ (–¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–≥–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è)
    latin_to_cyrillic = {
        'A': ['–ê', '–Ø'], 'B': ['–ë', '–í'], 'C': ['–°', '–ö', '–¶'], 'D': '–î',
        'E': ['–ï', '–ò', '–≠'], 'F': '–§', 'G': '–ì', 'H': ['–•', '–ù'],
        'I': ['–ò', '–ô'], 'J': '–ñ', 'K': '–ö', 'L': '–õ', 'M': '–ú', 'N': '–ù',
        'O': '–û', 'P': ['–ü', '–†'], 'Q': '–ö', 'R': '–†', 'S': ['–°', '–ó'],
        'T': '–¢', 'U': ['–£', '–Æ'], 'V': '–í', 'W': ['–í', '–£'], 'X': '–•',
        'Y': ['–£', '–ô', '–´'], 'Z': '–ó'
    }
    
    def convert_string(s, mapping, max_variants=5):
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç —Å—Ç—Ä–æ–∫—É –∏—Å–ø–æ–ª—å–∑—É—è –º–∞–ø–ø–∏–Ω–≥, –≥–µ–Ω–µ—Ä–∏—Ä—É—è –≤–∞—Ä–∏–∞–Ω—Ç—ã"""
        if not s:
            return ['']
        
        result_variants = []
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–π —Å–∏–º–≤–æ–ª
        char = s[0]
        rest = s[1:]
        
        if char.isdigit() or char in ['-', '_']:
            # –¶–∏—Ñ—Ä—ã –∏ —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å
            rest_variants = convert_string(rest, mapping, max_variants)
            for rv in rest_variants:
                result_variants.append(char + rv)
        elif char in mapping:
            replacements = mapping[char]
            if not isinstance(replacements, list):
                replacements = [replacements]
            
            rest_variants = convert_string(rest, mapping, max_variants)
            for replacement in replacements:
                for rv in rest_variants[:max_variants]:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–º–±–∏–Ω–∞—Ç–æ—Ä–Ω—ã–π –≤–∑—Ä—ã–≤
                    variant = replacement + rv
                    if variant not in result_variants:
                        result_variants.append(variant)
                        if len(result_variants) >= max_variants:
                            return result_variants
        else:
            # –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Å–∏–º–≤–æ–ª - –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å
            rest_variants = convert_string(rest, mapping, max_variants)
            for rv in rest_variants:
                result_variants.append(char + rv)
        
        return result_variants[:max_variants]
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã
    # 1. –ü–æ–ª–Ω–∞—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ –ª–∞—Ç–∏–Ω–∏—Ü—É (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)
    if any(char in cyrillic_to_latin for char in text):
        latin_variants = convert_string(text, cyrillic_to_latin, max_variants=3)
        for lv in latin_variants:
            if lv not in variants:
                variants.append(lv)
    
    # 2. –î–ª—è —Å–º–µ—à–∞–Ω–Ω—ã—Ö –∫–æ–¥–æ–≤ - —á–∞—Å—Ç–∏—á–Ω–∞—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è
    match = re.match(r'^([A-Z–ê-–Ø]+)(\d+)([A-Z–ê-–Ø\-]+)?$', text)
    if match:
        prefix, numbers, suffix = match.groups()
        suffix = suffix or ''
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –ø—Ä–µ—Ñ–∏–∫—Å –≤ –ª–∞—Ç–∏–Ω–∏—Ü—É
        if any(char in cyrillic_to_latin for char in prefix):
            prefix_variants = convert_string(prefix, cyrillic_to_latin, max_variants=2)
        else:
            prefix_variants = [prefix]
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å—É—Ñ—Ñ–∏–∫—Å
        if suffix:
            # –î–ª—è —Å—É—Ñ—Ñ–∏–∫—Å–æ–≤ –ø—Ä–æ–±—É–µ–º –æ–±–∞ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏
            suffix_variants = []
            
            # –ï—Å–ª–∏ —Å—É—Ñ—Ñ–∏–∫—Å –∫–∏—Ä–∏–ª–ª–∏—á–µ—Å–∫–∏–π - –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ –ª–∞—Ç–∏–Ω–∏—Ü—É
            if any(char in cyrillic_to_latin for char in suffix):
                suffix_variants.extend(convert_string(suffix, cyrillic_to_latin, max_variants=3))
            
            # –ï—Å–ª–∏ —Å—É—Ñ—Ñ–∏–∫—Å –ª–∞—Ç–∏–Ω—Å–∫–∏–π - –ø—Ä–æ–±—É–µ–º –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –≤ –∫–∏—Ä–∏–ª–ª–∏—Ü—É
            if any(char in latin_to_cyrillic for char in suffix):
                suffix_variants.extend(convert_string(suffix, latin_to_cyrillic, max_variants=2))
            
            # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Å—É—Ñ—Ñ–∏–∫—Å
            if suffix not in suffix_variants:
                suffix_variants.append(suffix)
            
            # –ö–æ–º–±–∏–Ω–∏—Ä—É–µ–º –≤–∞—Ä–∏–∞–Ω—Ç—ã
            for pv in prefix_variants[:2]:
                for sv in suffix_variants[:3]:
                    variant = pv + numbers + sv
                    if variant not in variants and len(variants) < 20:
                        variants.append(variant)
        else:
            # –¢–æ–ª—å–∫–æ –ø—Ä–µ—Ñ–∏–∫—Å –∏ —á–∏—Å–ª–∞
            for pv in prefix_variants[:3]:
                variant = pv + numbers
                if variant not in variants:
                    variants.append(variant)
    
    # 3. –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
    special_suffixes = ['–û–ë–°', '–ì–ò–≠', '–ì–ò–ò', '–ë–¢–ö', '–ë–ê–õ', '–ö–õ–©', '–í–ü–¢', '–ì–õ–ó', '–ì–°–ö', '–ö–ú', '–ö–†', '–õ–ò–ö', '–ù–û–°', '–ü–†–ö', '–†–û–¢', '–°–ò–ù', '–§–ö', '–ê–°–ü']
    
    for suffix in special_suffixes:
        if text.endswith(suffix):
            # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ—Ñ–∏–∫—Å –±–µ–∑ —Å—É—Ñ—Ñ–∏–∫—Å–∞
            prefix_part = text[:-len(suffix)]
            if any(char in cyrillic_to_latin for char in prefix_part):
                prefix_converted = convert_string(prefix_part, cyrillic_to_latin, max_variants=1)[0]
                variant = prefix_converted + suffix
                if variant not in variants:
                    variants.append(variant)
    
    # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã, —Å–æ—Ö—Ä–∞–Ω—è—è –ø–æ—Ä—è–¥–æ–∫
    seen = set()
    unique_variants = []
    for v in variants:
        if v not in seen:
            seen.add(v)
            unique_variants.append(v)
    
    print(f"[DEBUG] Variants for '{text}': {unique_variants[:10]}")
    return unique_variants[:20]

def calculate_phonetic_score(query: str, test_code: str) -> float:
    """–í—ã—á–∏—Å–ª—è–µ—Ç —Ñ–æ–Ω–µ—Ç–∏—á–µ—Å–∫–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ –º–µ–∂–¥—É —Å—Ç—Ä–æ–∫–∞–º–∏."""
    
    # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Ü–∏—Ñ—Ä
    query_digits = ''.join(c for c in query if c.isdigit())
    code_digits = ''.join(c for c in test_code if c.isdigit())
    
    # –ï—Å–ª–∏ —Ü–∏—Ñ—Ä—ã –Ω–µ —Å–æ–≤–ø–∞–¥–∞—é—Ç, —Å–Ω–∏–∂–∞–µ–º –æ—Ü–µ–Ω–∫—É
    digit_penalty = 0
    if query_digits != code_digits:
        # –°—á–∏—Ç–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ—Å–æ–≤–ø–∞–¥–∞—é—â–∏—Ö —Ü–∏—Ñ—Ä
        diff_count = sum(1 for i in range(min(len(query_digits), len(code_digits))) 
                        if query_digits[i] != code_digits[i])
        diff_count += abs(len(query_digits) - len(code_digits))
        digit_penalty = diff_count * 20  # -20 –±–∞–ª–ª–æ–≤ –∑–∞ –∫–∞–∂–¥—É—é –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—É—é —Ü–∏—Ñ—Ä—É
    
    # –§–æ–Ω–µ—Ç–∏—á–µ—Å–∫–∏–π –º–∞–ø–ø–∏–Ω–≥
    phonetic_map = {
        # –õ–∞—Ç–∏–Ω–∏—Ü–∞
        'A': 'A', 'B': 'B', 'C': 'K', 'D': 'D', 'E': 'I', 'F': 'F',
        'G': 'G', 'H': 'H', 'I': 'I', 'J': 'J', 'K': 'K', 'L': 'L',
        'M': 'M', 'N': 'N', 'O': 'O', 'P': 'P', 'Q': 'K', 'R': 'R',
        'S': 'S', 'T': 'T', 'U': 'U', 'V': 'V', 'W': 'V', 'X': 'H',
        'Y': 'U', 'Z': 'Z',
        # –ö–∏—Ä–∏–ª–ª–∏—Ü–∞
        '–ê': 'A', '–ë': 'B', '–í': 'V', '–ì': 'G', '–î': 'D', '–ï': 'I',
        '–Å': 'I', '–ñ': 'J', '–ó': 'Z', '–ò': 'I', '–ô': 'I', '–ö': 'K',
        '–õ': 'L', '–ú': 'M', '–ù': 'N', '–û': 'O', '–ü': 'P', '–†': 'R',
        '–°': 'S', '–¢': 'T', '–£': 'U', '–§': 'F', '–•': 'H', '–¶': 'S',
        '–ß': 'CH', '–®': 'SH', '–©': 'SCH', '–´': 'I', '–≠': 'I', '–Æ': 'U',
        '–Ø': 'A'
    }
    
    def to_phonetic(s):
        result = ''
        s = s.upper()
        i = 0
        while i < len(s):
            if i < len(s) - 1:
                two_char = s[i:i+2]
                if two_char in ['PH', 'TH', 'CH', 'SH']:
                    if two_char == 'PH':
                        result += 'F'
                    elif two_char == 'TH':
                        result += 'T'
                    else:
                        result += two_char
                    i += 2
                    continue
            
            char = s[i]
            if char in phonetic_map:
                result += phonetic_map[char]
            elif char.isdigit():
                result += char
            i += 1
        
        return result
    
    query_phonetic = to_phonetic(query)
    code_phonetic = to_phonetic(test_code)
    
    # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
    if query_phonetic == code_phonetic:
        return max(0, 100.0 - digit_penalty)
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–µ—Ñ–∏–∫—Å–∞
    min_len = min(len(query_phonetic), len(code_phonetic))
    if min_len >= 4:
        if query_phonetic[:4] == code_phonetic[:4]:
            return max(0, 85.0 - digit_penalty)
    
    # –†–∞—Å—á–µ—Ç —Å—Ö–æ–∂–µ—Å—Ç–∏ –ø–æ —Å–∏–º–≤–æ–ª–∞–º
    matches = 0
    for i in range(min(len(query_phonetic), len(code_phonetic))):
        if query_phonetic[i] == code_phonetic[i]:
            matches += 1
    
    max_len = max(len(query_phonetic), len(code_phonetic))
    if max_len == 0:
        return 0.0
    
    base_score = (matches / max_len) * 100
    return max(0, base_score - digit_penalty)

async def smart_test_search(processor, original_query: str) -> Optional[tuple]:
    """–£–º–Ω—ã–π –ø–æ–∏—Å–∫ —Å —É—á–µ—Ç–æ–º —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –Ω–∞–ø–∏—Å–∞–Ω–∏—è."""
    
    # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É –Ω–∞ None –∏ –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É
    if not original_query:
        return None, None, None
    
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∑–∞–ø—Ä–æ—Å
    normalized_query = normalize_test_code(original_query)
    
    # –ï—Å–ª–∏ –ø–æ—Å–ª–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –ø–æ–ª—É—á–∏–ª–∏ –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É
    if not normalized_query:
        return None, None, None
    
    # 1. –¢–æ—á–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–º—É –∫–æ–¥—É
    results = processor.search_test(filter_dict={"test_code": normalized_query})
    if results:
        return results[0], normalized_query, "exact"
    
    # 2. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –≤–∞—Ä–∏–∞–Ω—Ç—ã –∏ –∏—â–µ–º
    variants = generate_test_code_variants(normalized_query)
    for variant in variants[:5]:
        results = processor.search_test(filter_dict={"test_code": variant})
        if results:
            return results[0], variant, "variant"
    
    # 3. –¢–µ–∫—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫
    text_results = processor.search_test(query=normalized_query, top_k=50)
    
    if text_results and text_results[0][1] > 0.8:
        return text_results[0], text_results[0][0].metadata.get('test_code'), "text"
    
    return None, None, None

async def safe_delete_message(message):
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è"""
    try:
        if message:
            await message.delete()
    except Exception:
        pass  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ —É–¥–∞–ª–µ–Ω–∏—è
    
def split_long_message(text: str, max_length: int = 4000) -> list[str]:
    """–†–∞–∑–±–∏–≤–∞–µ—Ç –¥–ª–∏–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –Ω–∞ —á–∞—Å—Ç–∏"""
    if len(text) <= max_length:
        return [text]
    
    parts = []
    current_part = ""
    
    # –†–∞–∑–±–∏–≤–∞–µ–º –ø–æ —Å—Ç—Ä–æ–∫–∞–º
    lines = text.split('\n')
    
    for line in lines:
        if len(current_part) + len(line) + 1 > max_length:
            if current_part:
                parts.append(current_part.strip())
                current_part = line
            else:
                # –ï—Å–ª–∏ –æ–¥–Ω–∞ —Å—Ç—Ä–æ–∫–∞ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–∞—è, —Ä–µ–∂–µ–º –µ—ë
                while len(line) > max_length:
                    parts.append(line[:max_length])
                    line = line[max_length:]
                current_part = line
        else:
            current_part += '\n' + line if current_part else line
    
    if current_part:
        parts.append(current_part.strip())
    
    return parts

def expand_query_with_abbreviations(query: str) -> str:
    """Expand query with known test abbreviations."""
    query_upper = query.upper()
    for abbr, expansion in TEST_ABBREVIATIONS.items():
        if abbr in query_upper:
            return f"{query} {expansion}"
    return query

def safe_html(text: str) -> str:
    """–≠–∫—Ä–∞–Ω–∏—Ä—É–µ—Ç HTML —Å–∏–º–≤–æ–ª—ã –≤ —Ç–µ–∫—Å—Ç–µ"""
    return html.escape(text)

def get_time_based_farewell(user_name: str = None):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –ø—Ä–æ—â–∞–Ω–∏–µ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –≤—Ä–µ–º–µ–Ω–∏ —Å—É—Ç–æ–∫"""
    tz = pytz.timezone('Europe/Minsk')
    current_hour = datetime.now(tz).hour
    
    name_part = f", {user_name}" if user_name and user_name != '–¥—Ä—É–≥' else ""
    
    if 4 <= current_hour < 12:
        return f"–†–∞–¥ –±—ã–ª –ø–æ–º–æ—á—å{name_part}! –•–æ—Ä–æ—à–µ–≥–æ —É—Ç—Ä–∞ ‚òÄÔ∏è"
    elif 12 <= current_hour < 17:
        return f"–†–∞–¥ –±—ã–ª –ø–æ–º–æ—á—å{name_part}! –•–æ—Ä–æ—à–µ–≥–æ –¥–Ω—è ü§ù"
    elif 17 <= current_hour < 22:
        return f"–†–∞–¥ –±—ã–ª –ø–æ–º–æ—á—å{name_part}! –•–æ—Ä–æ—à–µ–≥–æ –≤–µ—á–µ—Ä–∞ üåÜ"
    else:
        return f"–†–∞–¥ –±—ã–ª –ø–æ–º–æ—á—å{name_part}! –î–æ–±—Ä–æ–π –Ω–æ—á–∏ üåô"
    
def get_user_first_name(user):
    if not user:
        return '–¥—Ä—É–≥'
    # –°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å dict –∏ aiosqlite.Row
    name = user['name'] if 'name' in user.keys() else None
    if not name:
        return '–¥—Ä—É–≥'
    full_name = name.strip()
    name_parts = full_name.split()
    if len(name_parts) >= 2 and ('user_type' in user.keys() and user['user_type'] == 'employee'):
        return name_parts[1]  # –î–ª—è —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤: –§–∞–º–∏–ª–∏—è –ò–º—è
    return name_parts[0]  # –î–ª—è –∫–ª–∏–µ–Ω—Ç–æ–≤ –∏–ª–∏ –æ–¥–Ω–æ—Å–ª–æ–≤–Ω—ã—Ö –∏–º–µ–Ω

def format_test_data(metadata: Dict) -> Dict:
    """Extract and format test metadata into standardized dictionary."""
    return {
        'type': metadata['type'],
        'test_code': metadata['test_code'],
        'test_name': metadata['test_name'],
        'container_type': metadata['container_type'],
        'container_number': metadata['container_number'],
        'preanalytics': metadata['preanalytics'],
        'storage_temp': metadata['storage_temp'],
        'department': metadata['department']
    }

def format_test_info_brief(test_data: Dict) -> str:
    """Format brief test information for initial search results."""
    t_type = '–¢–µ—Å—Ç' if test_data['type'] == '–¢–µ—Å—Ç—ã' else '–ü—Ä–æ—Ñ–∏–ª—å'
    # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º HTML —Å–∏–º–≤–æ–ª—ã –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏ —Ç–µ—Å—Ç–∞
    test_name = html.escape(test_data['test_name'])
    department = html.escape(test_data['department'])
    
    return (
        f"<b>{t_type}: {test_data['test_code']} - {test_name}</b>\n"
        f"üß¨ <b>–í–∏–¥ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è:</b> {department}\n"
    )

def format_test_info(test_data: Dict) -> str:
    """Format full test information from metadata using HTML tags."""
    t_type = '–¢–µ—Å—Ç' if test_data['type'] == '–¢–µ—Å—Ç—ã' else '–ü—Ä–æ—Ñ–∏–ª—å'
    
    # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º HTML —Å–∏–º–≤–æ–ª—ã –≤–æ –≤—Å–µ—Ö –ø–æ–ª—è—Ö
    test_name = html.escape(test_data['test_name'])
    container_type = html.escape(test_data['container_type'])
    container_number = html.escape(str(test_data['container_number']))
    storage_temp = html.escape(test_data['storage_temp'])
    department = html.escape(test_data['department'])
    preanalytics = html.escape(test_data['preanalytics'])
    
    return (
        f"<b>{t_type}: {test_data['test_code']} - {test_name}</b>\n\n"
        f"üß™ <b>–¢–∏–ø –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞:</b> {container_type}\n"
        f"üî¢ <b>–ù–æ–º–µ—Ä –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞:</b> {container_number}\n"
        f"‚ùÑÔ∏è <b>–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞:</b> {storage_temp}\n"
        f"üß¨ <b>–í–∏–¥ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è:</b> {department}\n"
        f"üìã <b>–ü—Ä–µ–∞–Ω–∞–ª–∏—Ç–∏–∫–∞:</b> {preanalytics}\n\n"
    )
    
async def handle_general_question(message: Message, state: FSMContext, question_text: str):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–±—â–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ —á–µ—Ä–µ–∑ LLM."""
    user_id = message.from_user.id
    
    loading_msg = await message.answer("ü§î –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –≤–∞—à –≤–æ–ø—Ä–æ—Å...")
    
    try:
        system_prompt = """–¢—ã - –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –≤–µ—Ç–µ—Ä–∏–Ω–∞—Ä–Ω–æ–π –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–∏–∏ VetUnion. 
        –¢—ã –æ—Ç–≤–µ—á–∞–µ—à—å –Ω–∞ –≤—Å–µ –≤–æ–ø—Ä–æ—Å—ã –≤ –æ–±–ª–∞—Å—Ç–∏ –≤–µ—Ç–µ—Ä–∏–Ω–∞—Ä–∏–∏ –∏—Å—Ö–æ–¥—è –∏–∑ –≤–æ–ø—Ä–æ—Å–∞, –∫–æ—Ç–æ—Ä—ã–π —Ç–µ–±–µ –∑–∞–¥–∞–ª–∏ –∏ —Ç—ã –∑–Ω–∞–µ—à—å –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π —Å–ª–µ–Ω–≥. 
        –û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ —Å—É—â–µ—Å—Ç–≤—É –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ."""
        
        response = await llm.agenerate([[
            SystemMessage(content=system_prompt),
            HumanMessage(content=question_text)
        ]])
        
        answer = response.generations[0][0].text.strip()
        answer = fix_bold(answer)  # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—é markdown
        
        await loading_msg.delete()
        await message.answer(answer, parse_mode="HTML")
        
        # –ö–ª–∞–≤–∏–∞—Ç—É—Ä–∞ —Å –æ–ø—Ü–∏—è–º–∏
        keyboard = InlineKeyboardMarkup(inline_keyboard=[
            [
                InlineKeyboardButton(text="üî¢ –ù–∞–π—Ç–∏ —Ç–µ—Å—Ç –ø–æ –∫–æ–¥—É", callback_data="search_by_code"),
                InlineKeyboardButton(text="üìù –ù–∞–π—Ç–∏ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é", callback_data="search_by_name")
            ]
        ])
        
        await message.answer("–ß—Ç–æ –±—ã –≤—ã —Ö–æ—Ç–µ–ª–∏ —Å–¥–µ–ª–∞—Ç—å –¥–∞–ª—å—à–µ?", reply_markup=keyboard)
        
    except Exception as e:
        print(f"[ERROR] General question handling failed: {e}")
        await loading_msg.delete()
        await message.answer("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤–æ–ø—Ä–æ—Å. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å.")

# –¢–∞–∫–∂–µ –¥–æ–±–∞–≤–∏–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –¥–ª—è callback –∫–Ω–æ–ø–æ–∫, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –±—ã—Ç—å –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã:
@questions_router.callback_query(F.data == "search_by_code")
async def handle_search_by_code_callback(callback: CallbackQuery, state: FSMContext):
    await callback.answer()
    await callback.message.answer("–í–≤–µ–¥–∏—Ç–µ –∫–æ–¥ —Ç–µ—Å—Ç–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, AN5):", reply_markup=get_back_to_menu_kb())
    await state.set_state(QuestionStates.waiting_for_code)

@questions_router.callback_query(F.data == "search_by_name")
async def handle_search_by_name_callback(callback: CallbackQuery, state: FSMContext):
    await callback.answer()
    await callback.message.answer("–í–≤–µ–¥–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –∏–ª–∏ –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–µ—Å—Ç–∞:", reply_markup=get_back_to_menu_kb())
    await state.set_state(QuestionStates.waiting_for_name)

async def animate_loading(loading_msg: Message):
    """Animate loading message (edit text, not caption)."""
    animations = [
        "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –≤–∞—à –∑–∞–ø—Ä–æ—Å...\n‚è≥ –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –¥–∞–Ω–Ω—ã–µ...",
        "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –≤–∞—à –∑–∞–ø—Ä–æ—Å...\nüîç –ü–æ–∏—Å–∫ –≤ –±–∞–∑–µ VetUnion...",
        "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –≤–∞—à –∑–∞–ø—Ä–æ—Å...\nüß† –§–æ—Ä–º–∏—Ä—É—é –æ—Ç–≤–µ—Ç...",
    ]
    i = 0
    try:
        while True:
            await asyncio.sleep(2)
            i = (i + 1) % len(animations)
            await loading_msg.edit_text(animations[i])
    except (asyncio.CancelledError, Exception):
        pass

async def select_best_match(query: str, docs: list[tuple[Document, float]]) -> list[Document]:
    """Select best matching tests using LLM from multiple options."""
    if len(docs) == 1:
        return [docs[0][0]]
    
    options = "\n".join([
        f"{i}. {doc.metadata['test_name']} ({doc.metadata['test_code']}) - score: {score:.2f}"
        for i, (doc, score) in enumerate(docs, 1)
    ])
    
    prompt = f"""
    Select relevant tests for: "{query}"
    Return ONLY numbers of matching options (1-{len(docs)}) separated by commas.
    
    Options:
    {options}
    """
    
    try:
        response = await llm.agenerate([[SystemMessage(content=prompt)]])
        selected = response.generations[0][0].text.strip()
        
        if not selected:
            return [docs[0][0]]  # Fallback to top result
            
        selected_indices = []
        for num in selected.split(','):
            num = num.strip()
            if num.isdigit() and 1 <= int(num) <= len(docs):
                selected_indices.append(int(num) - 1)
                
        if not selected_indices:
            return [docs[0][0]]
            
        # –ü–æ–ª—É—á–∞–µ–º –≤—ã–±—Ä–∞–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ø–æ—Ä—è–¥–∫–∞ LLM
        selected_docs_with_order = [(docs[i][0], idx) for idx, i in enumerate(selected_indices)]
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º: —Å–Ω–∞—á–∞–ª–∞ "–¢–µ—Å—Ç—ã", –ø–æ—Ç–æ–º "–ü—Ä–æ—Ñ–∏–ª–∏", –≤–Ω—É—Ç—Ä–∏ –∫–∞–∂–¥–æ–π –≥—Ä—É–ø–ø—ã —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ—Ä—è–¥–æ–∫ LLM
        sorted_docs = sorted(selected_docs_with_order, key=lambda x: (
            0 if x[0].metadata.get('type') == '–¢–µ—Å—Ç—ã' else 1,  # –¢–µ—Å—Ç—ã –ø–µ—Ä–≤—ã–º–∏
            x[1]  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ—Ä—è–¥–æ–∫ LLM –≤–Ω—É—Ç—Ä–∏ –∫–∞–∂–¥–æ–π –≥—Ä—É–ø–ø—ã
        ))
        
        return [doc for doc, _ in sorted_docs]
        
    except Exception:
        return [docs[0][0]]  # Fallback on error

async def show_personalized_suggestions(message: Message, state: FSMContext):
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ–¥—Å–∫–∞–∑–∫–∏ –ø—Ä–∏ –Ω–∞—á–∞–ª–µ –ø–æ–∏—Å–∫–∞"""
    user_id = message.from_user.id
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º –ø–æ–¥—Å–∫–∞–∑–∫–∏
        suggestions = await db.get_search_suggestions(user_id)
        
        if suggestions:
            keyboard = InlineKeyboardMarkup(inline_keyboard=[])
            
            # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Ç–∏–ø–∞–º
            frequent = [s for s in suggestions if s['type'] == 'frequent']
            recent = [s for s in suggestions if s['type'] == 'recent']
            
            if frequent:
                # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
                keyboard.inline_keyboard.append([
                    InlineKeyboardButton(text="‚≠ê –ß–∞—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ:", callback_data="ignore")
                ])
                
                for sug in frequent[:3]:
                    keyboard.inline_keyboard.append([
                        InlineKeyboardButton(
                            text=f"{sug['code']} - {sug['name'][:40]}... ({sug['frequency']}x)",
                            callback_data=f"quick_test:{sug['code']}"
                        )
                    ])
            
            if recent:
                keyboard.inline_keyboard.append([
                    InlineKeyboardButton(text="üïê –ù–µ–¥–∞–≤–Ω–∏–µ –ø–æ–∏—Å–∫–∏:", callback_data="ignore")
                ])
                
                for sug in recent[:2]:
                    keyboard.inline_keyboard.append([
                        InlineKeyboardButton(
                            text=f"{sug['code']} - {sug['name'][:40]}...",
                            callback_data=f"quick_test:{sug['code']}"
                        )
                    ])
            
            await message.answer(
                "üí° –ë—ã—Å—Ç—Ä—ã–π –¥–æ—Å—Ç—É–ø –∫ –≤–∞—à–∏–º —Ç–µ—Å—Ç–∞–º:",
                reply_markup=keyboard
            )
    except Exception as e:
        print(f"[ERROR] Failed to show personalized suggestions: {e}")
        # –ù–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –æ—à–∏–±–∫—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é, –ø—Ä–æ—Å—Ç–æ –Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ–¥—Å–∫–∞–∑–∫–∏

# –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏
@questions_router.callback_query(F.data.startswith("show_test:"))
async def handle_show_test_callback(callback: CallbackQuery, state: FSMContext):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è –ø–æ–∫–∞–∑–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ç–µ—Å—Ç–µ –∏–∑ inline –∫–Ω–æ–ø–∫–∏."""
    action, test_code = TestCallback.unpack(callback.data)
    
    # –û—Ç–≤–µ—á–∞–µ–º –Ω–∞ callback —á—Ç–æ–±—ã —É–±—Ä–∞—Ç—å "—á–∞—Å–∏–∫–∏"
    await callback.answer()
    
    try:
        processor = DataProcessor()
        processor.load_vector_store()
        
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º —Ç–æ—á–Ω—ã–π –ø–æ–∏—Å–∫
        results = processor.search_test(filter_dict={"test_code": test_code})
        
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ - –ø—Ä–æ–±—É–µ–º —Å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π
        if not results:
            normalized_code = normalize_test_code(test_code)
            results = processor.search_test(filter_dict={"test_code": normalized_code})
        
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ - –∏—Å–ø–æ–ª—å–∑—É–µ–º fuzzy –ø–æ–∏—Å–∫ —Å –≤—ã—Å–æ–∫–∏–º –ø–æ—Ä–æ–≥–æ–º
        if not results:
            print(f"[DEBUG] Test {test_code} not found with exact search. Trying fuzzy...")
            fuzzy_results = await fuzzy_test_search(processor, test_code, threshold=85)
            
            if fuzzy_results:
                # –ò—â–µ–º —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å—Ä–µ–¥–∏ fuzzy —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                for doc, score in fuzzy_results:
                    if doc.metadata.get('test_code', '').upper() == test_code.upper():
                        results = [(doc, score)]
                        print(f"[DEBUG] Found exact match in fuzzy results: {doc.metadata.get('test_code')}")
                        break
                
                # –ï—Å–ª–∏ —Ç–æ—á–Ω–æ–≥–æ –Ω–µ –Ω–∞—à–ª–∏ - –±–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π —Å –≤—ã—Å–æ–∫–∏–º score
                if not results and fuzzy_results[0][1] >= 90:
                    results = [fuzzy_results[0]]
                    print(f"[DEBUG] Using best fuzzy match: {fuzzy_results[0][0].metadata.get('test_code')} (score: {fuzzy_results[0][1]})")
        
        # –ü–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞ - —Ç–µ–∫—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫
        if not results:
            print(f"[DEBUG] Trying text search for {test_code}")
            text_results = processor.search_test(query=test_code, top_k=50)
            
            # –ò—â–µ–º —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∫–æ–¥–∞
            for doc, score in text_results:
                doc_code = doc.metadata.get('test_code', '')
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å —É—á–µ—Ç–æ–º —Ä–µ–≥–∏—Å—Ç—Ä–∞ –∏ –ø—Ä–æ–±–µ–ª–æ–≤
                if doc_code.strip().upper() == test_code.strip().upper():
                    results = [(doc, score)]
                    print(f"[DEBUG] Found via text search: {doc_code}")
                    break
        
        # –ï—Å–ª–∏ –≤—Å–µ –µ—â–µ –Ω–µ –Ω–∞—à–ª–∏ - –∏—Å–ø–æ–ª—å–∑—É–µ–º smart_test_search
        if not results:
            result, found_variant, match_type = await smart_test_search(processor, test_code)
            if result:
                results = [result]
                print(f"[DEBUG] Found via smart search: {found_variant} (type: {match_type})")
        
        if not results:
            print(f"[ERROR] Test {test_code} not found after all attempts")
            await callback.message.answer(f"‚ùå –¢–µ—Å—Ç {test_code} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö")
            return
            
        doc = results[0][0] if isinstance(results[0], tuple) else results[0]
        test_data = format_test_data(doc.metadata)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç
        response = f"<b>–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≤—ã–±—Ä–∞–Ω–Ω–æ–º —Ç–µ—Å—Ç–µ:</b>\n\n"
        response += format_test_info(test_data)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        user_id = callback.from_user.id
        await db.add_search_history(
            user_id=user_id,
            search_query=f"–í—ã–±–æ—Ä –∏–∑ —Å–ø–∏—Å–∫–∞: {test_code}",
            found_test_code=test_data['test_code'],
            search_type='code',
            success=True
        )
        await db.update_user_frequent_test(
            user_id=user_id,
            test_code=test_data['test_code'],
            test_name=test_data['test_name']
        )
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã
        data = await state.get_data()
        if 'last_viewed_test' in data and data['last_viewed_test'] != test_data['test_code']:
            await db.update_related_tests(
                user_id=user_id,
                test_code_1=data['last_viewed_test'],
                test_code_2=test_data['test_code']
            )
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        related_tests = await db.get_user_related_tests(user_id, test_data['test_code'])
        
        # –ò—â–µ–º –ø–æ—Ö–æ–∂–∏–µ —Ç–µ—Å—Ç—ã –¥–ª—è —ç—Ç–æ–≥–æ —Ç–µ—Å—Ç–∞
        similar_tests = await fuzzy_test_search(processor, test_data['test_code'], threshold=40)
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º, —á—Ç–æ–±—ã –Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å —Å–∞–º —Ç–µ—Å—Ç
        similar_tests = [(d, s) for d, s in similar_tests if d.metadata.get('test_code') != test_data['test_code']]
        
        # –°–æ–∑–¥–∞–µ–º –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É –µ—Å–ª–∏ –µ—Å—Ç—å –ø–æ—Ö–æ–∂–∏–µ –∏–ª–∏ —Å–≤—è–∑–∞–Ω–Ω—ã–µ
        reply_markup = None
        if related_tests or similar_tests:
            keyboard = []
            row = []
            
            # –°–Ω–∞—á–∞–ª–∞ —Å–≤—è–∑–∞–Ω–Ω—ã–µ –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏ (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)
            for related in related_tests[:4]:
                row.append(InlineKeyboardButton(
                    text=f"‚≠ê {related['test_code']}",
                    callback_data=TestCallback.pack("show_test", related['test_code'])
                ))
                if len(row) >= 2:
                    keyboard.append(row)
                    row = []
            
            # –ó–∞—Ç–µ–º –ø–æ—Ö–æ–∂–∏–µ
            for doc, _ in similar_tests[:4]:
                if len(keyboard) * 2 + len(row) >= 8:  # –ú–∞–∫—Å–∏–º—É–º 8 –∫–Ω–æ–ø–æ–∫
                    break
                code = doc.metadata.get('test_code')
                if not any(r['test_code'] == code for r in related_tests):
                    row.append(InlineKeyboardButton(
                        text=code,
                        callback_data=TestCallback.pack("show_test", code)
                    ))
                    if len(row) >= 2:
                        keyboard.append(row)
                        row = []
            
            if row:
                keyboard.append(row)
            
            reply_markup = InlineKeyboardMarkup(inline_keyboard=keyboard)
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é —Å —Ñ–æ—Ç–æ –¢–û–õ–¨–ö–û –û–î–ò–ù –†–ê–ó
        await send_test_info_with_photo(callback.message, test_data, response)
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ - –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –∏—Ö –æ—Ç–¥–µ–ª—å–Ω—ã–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º
        if reply_markup:
            await callback.message.answer(
                "üéØ –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º —Ç–∞–∫–∂–µ:",
                reply_markup=reply_markup
            )
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å —Ç–µ–∫—É—â–∏–º —Ç–µ—Å—Ç–æ–º
        await state.set_state(QuestionStates.in_dialog)
        await state.update_data(current_test=test_data, last_viewed_test=test_data['test_code'])
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è –¥–∏–∞–ª–æ–≥–∞
        await callback.message.answer(
            "–ú–æ–∂–µ—Ç–µ –∑–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å –æ–± —ç—Ç–æ–º —Ç–µ—Å—Ç–µ –∏–ª–∏ –≤—ã–±—Ä–∞—Ç—å –¥–µ–π—Å—Ç–≤–∏–µ:",
            reply_markup=get_dialog_kb()
        )
        
    except Exception as e:
        print(f"[ERROR] Callback handling failed: {e}")
        import traceback
        traceback.print_exc()
        await callback.message.answer("‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ç–µ—Å—Ç–µ")

@questions_router.callback_query(F.data.startswith("quick_test:"))
async def handle_quick_test_selection(callback: CallbackQuery, state: FSMContext):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –±—ã—Å—Ç—Ä–æ–≥–æ –≤—ã–±–æ—Ä–∞ —Ç–µ—Å—Ç–∞ –∏–∑ –ø–æ–¥—Å–∫–∞–∑–æ–∫"""
    test_code = callback.data.split(':')[1]
    
    try:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º DataProcessor –Ω–∞–ø—Ä—è–º—É—é –¥–ª—è –ø–æ–∏—Å–∫–∞
        processor = DataProcessor()
        processor.load_vector_store()
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫–æ–¥ —Ç–µ—Å—Ç–∞
        normalized_code = normalize_test_code(test_code)
        
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º —Ç–æ—á–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–º—É –∫–æ–¥—É
        results = processor.search_test(filter_dict={"test_code": normalized_code})
        
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ - –ø—Ä–æ–±—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∫–æ–¥
        if not results:
            results = processor.search_test(filter_dict={"test_code": test_code})
        
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ - –ø—Ä–æ–±—É–µ–º fuzzy –ø–æ–∏—Å–∫
        if not results:
            print(f"[DEBUG] Test {test_code} not found with filter. Trying fuzzy search...")
            fuzzy_results = await fuzzy_test_search(processor, test_code, threshold=90)
            
            if fuzzy_results:
                # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å –≤—ã—Å–æ–∫–∏–º score
                results = [fuzzy_results[0]]
                print(f"[DEBUG] Found via fuzzy search: {results[0][0].metadata.get('test_code')}")
            else:
                # –ü—Ä–æ–±—É–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫
                print(f"[DEBUG] Trying text search for {test_code}")
                text_results = processor.search_test(query=test_code, top_k=10)
                
                # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ —Ç–æ—á–Ω–æ–º—É —Å–æ–≤–ø–∞–¥–µ–Ω–∏—é –∫–æ–¥–∞
                for doc, score in text_results:
                    doc_code = doc.metadata.get('test_code', '')
                    if doc_code.upper() == test_code.upper() or doc_code.upper() == normalized_code.upper():
                        results = [(doc, score)]
                        print(f"[DEBUG] Found via text search: {doc_code}")
                        break
        
        if not results:
            # –ü–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞ - –∏—Å–ø–æ–ª—å–∑—É–µ–º smart_test_search
            result, found_variant, match_type = await smart_test_search(processor, test_code)
            if result:
                results = [result]
                print(f"[DEBUG] Found via smart search: {found_variant} (type: {match_type})")
        
        if not results:
            print(f"[ERROR] Test {test_code} not found after all attempts")
            await callback.message.answer(f"‚ùå –¢–µ—Å—Ç {test_code} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö")
            await callback.answer()
            return
            
        doc = results[0][0] if isinstance(results[0], tuple) else results[0]
        test_data = format_test_data(doc.metadata)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        response = f"<b>–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≤—ã–±—Ä–∞–Ω–Ω–æ–º —Ç–µ—Å—Ç–µ:</b>\n\n"
        response += format_test_info(test_data)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        user_id = callback.from_user.id
        await db.add_search_history(
            user_id=user_id,
            search_query=f"–ë—ã—Å—Ç—Ä—ã–π –≤—ã–±–æ—Ä: {test_code}",
            found_test_code=test_data['test_code'],
            search_type='code',
            success=True
        )
        await db.update_user_frequent_test(
            user_id=user_id,
            test_code=test_data['test_code'],
            test_name=test_data['test_name']
        )
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã
        data = await state.get_data()
        if 'last_viewed_test' in data and data['last_viewed_test'] != test_data['test_code']:
            await db.update_related_tests(
                user_id=user_id,
                test_code_1=data['last_viewed_test'],
                test_code_2=test_data['test_code']
            )
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        related_tests = await db.get_user_related_tests(user_id, test_data['test_code'])
        
        # –ò—â–µ–º –ø–æ—Ö–æ–∂–∏–µ —Ç–µ—Å—Ç—ã –¥–ª—è —ç—Ç–æ–≥–æ —Ç–µ—Å—Ç–∞
        similar_tests = await fuzzy_test_search(processor, test_data['test_code'], threshold=40)
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º, —á—Ç–æ–±—ã –Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å —Å–∞–º —Ç–µ—Å—Ç
        similar_tests = [(d, s) for d, s in similar_tests if d.metadata.get('test_code') != test_data['test_code']]
        
        # –°–æ–∑–¥–∞–µ–º –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É –µ—Å–ª–∏ –µ—Å—Ç—å –ø–æ—Ö–æ–∂–∏–µ –∏–ª–∏ —Å–≤—è–∑–∞–Ω–Ω—ã–µ
        reply_markup = None
        if related_tests or similar_tests:
            keyboard = []
            row = []
            
            # –°–Ω–∞—á–∞–ª–∞ —Å–≤—è–∑–∞–Ω–Ω—ã–µ –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏ (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)
            for related in related_tests[:4]:
                row.append(InlineKeyboardButton(
                    text=f"‚≠ê {related['test_code']}",
                    callback_data=TestCallback.pack("show_test", related['test_code'])
                ))
                if len(row) >= 2:
                    keyboard.append(row)
                    row = []
            
            # –ó–∞—Ç–µ–º –ø–æ—Ö–æ–∂–∏–µ
            for doc, _ in similar_tests[:4]:
                if len(keyboard) * 2 + len(row) >= 8:  # –ú–∞–∫—Å–∏–º—É–º 8 –∫–Ω–æ–ø–æ–∫
                    break
                code = doc.metadata.get('test_code')
                if not any(r['test_code'] == code for r in related_tests):
                    row.append(InlineKeyboardButton(
                        text=code,
                        callback_data=TestCallback.pack("show_test", code)
                    ))
                    if len(row) >= 2:
                        keyboard.append(row)
                        row = []
            
            if row:
                keyboard.append(row)
            
            reply_markup = InlineKeyboardMarkup(inline_keyboard=keyboard)
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é —Å —Ñ–æ—Ç–æ –¢–û–õ–¨–ö–û –û–î–ò–ù –†–ê–ó
        await send_test_info_with_photo(callback.message, test_data, response)
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ - –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –∏—Ö –æ—Ç–¥–µ–ª—å–Ω—ã–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º
        if reply_markup:
            await callback.message.answer(
                "üéØ –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º —Ç–∞–∫–∂–µ:",
                reply_markup=reply_markup
            )
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å —Ç–µ–∫—É—â–∏–º —Ç–µ—Å—Ç–æ–º
        await state.set_state(QuestionStates.in_dialog)
        await state.update_data(current_test=test_data, last_viewed_test=test_data['test_code'])
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è –¥–∏–∞–ª–æ–≥–∞
        await callback.message.answer(
            "–ú–æ–∂–µ—Ç–µ –∑–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å –æ–± —ç—Ç–æ–º —Ç–µ—Å—Ç–µ –∏–ª–∏ –≤—ã–±—Ä–∞—Ç—å –¥–µ–π—Å—Ç–≤–∏–µ:",
            reply_markup=get_dialog_kb()
        )
        
    except Exception as e:
        print(f"[ERROR] Quick test selection failed: {e}")
        import traceback
        traceback.print_exc()
        await callback.message.answer("‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ç–µ—Å—Ç–µ")
    
    await callback.answer()  # –ó–∞–∫—Ä—ã–≤–∞–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –Ω–∞–∂–∞—Ç–∏–∏
    
@questions_router.callback_query(F.data == "ignore")
async def handle_ignore_callback(callback: CallbackQuery):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã—Ö –∫–Ω–æ–ø–æ–∫"""
    await callback.answer()

@questions_router.message(F.text == "üî¨ –ó–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç—É")
async def start_question(message: Message, state: FSMContext):
    """–ù–∞—á–∞–ª–æ –¥–∏–∞–ª–æ–≥–∞ —Å –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–º –±–µ–∑ –≤—ã–±–æ—Ä–∞ —Ç–∏–ø–∞ –ø–æ–∏—Å–∫–∞."""
    user_id = message.from_user.id
    user = await db.get_user(user_id)
    
    if not user:
        await message.answer("–î–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —ç—Ç–æ–π —Ñ—É–Ω–∫—Ü–∏–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –ø—Ä–æ–π—Ç–∏ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—é.\n–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–æ–º–∞–Ω–¥—É /start")
        return

    user_name = get_user_first_name(user)
    
    prompt = f"""–ü—Ä–∏–≤–µ—Ç, {user_name} üëã
    
üî¨ –Ø –º–æ–≥—É –ø–æ–º–æ—á—å —Å –ø–æ–∏—Å–∫–æ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ:
‚Ä¢ –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω—ã–º —Ç–µ—Å—Ç–∞–º (–≤–≤–µ–¥–∏—Ç–µ –∫–æ–¥, –Ω–∞–ø—Ä–∏–º–µ—Ä: AN5)
‚Ä¢ –ü—Ä–µ–∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–º —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º
‚Ä¢ –¢–∏–ø–∞–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤ –∏ —É—Å–ª–æ–≤–∏—è–º —Ö—Ä–∞–Ω–µ–Ω–∏—è
‚Ä¢ –ò–ª–∏ –∑–∞–¥–∞–π—Ç–µ –ª—é–±–æ–π –≤–æ–ø—Ä–æ—Å –æ –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–æ–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–µ

üí° –ü—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏—Ç–µ –≤–∞—à –≤–æ–ø—Ä–æ—Å –∏–ª–∏ –∫–æ–¥ —Ç–µ—Å—Ç–∞:"""

    await db.clear_buffer(user_id)
    await message.answer(prompt, reply_markup=get_back_to_menu_kb())
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ–¥—Å–∫–∞–∑–∫–∏
    await show_personalized_suggestions(message, state)
    
    await state.set_state(QuestionStates.waiting_for_search_type)

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —Ö–µ–Ω–¥–ª–µ—Ä –¥–ª—è –∫–Ω–æ–ø–∫–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –¥–∏–∞–ª–æ–≥–∞ (—Ä–∞–±–æ—Ç–∞–µ—Ç –≤ –ª—é–±–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏)
@questions_router.message(F.text == "‚ùå –ó–∞–≤–µ—Ä—à–∏—Ç—å –¥–∏–∞–ª–æ–≥")
async def handle_end_dialog(message: Message, state: FSMContext):
    current_state = await state.get_state()
    user = await db.get_user(message.from_user.id)
    role = user['role'] if 'role' in user.keys() else 'staff'
    user_name = get_user_first_name(user)
    
    # –ò—Å–∫–ª—é—á–µ–Ω–∏–µ: –µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–∞–∂–∞–ª "–∑–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç—É" –∏ –Ω–µ –≤–≤–µ–ª –≤–æ–ø—Ä–æ—Å
    if current_state == QuestionStates.waiting_for_search_type:
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –≤ –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é –±–µ–∑ –ø—Ä–æ—â–∞–Ω–∏—è
        await state.clear()
        farewell = get_time_based_farewell(user_name)
        await message.answer(farewell, reply_markup=get_menu_by_role(role))
        return
    
    # –í–æ –≤—Å–µ—Ö –æ—Å—Ç–∞–ª—å–Ω—ã—Ö —Å–ª—É—á–∞—è—Ö –∑–∞–≤–µ—Ä—à–∞–µ–º –¥–∏–∞–ª–æ–≥
    await state.clear()
    farewell = get_time_based_farewell(user_name)
    await message.answer(farewell, reply_markup=get_menu_by_role(role))
    return

# –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è —Å—Ç–∞—Ä–æ–π –∫–Ω–æ–ø–∫–∏ (–¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
@questions_router.message(F.text == "üîô –í–µ—Ä–Ω—É—Ç—å—Å—è –≤ –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é")
async def handle_back_to_menu_legacy(message: Message, state: FSMContext):
    await state.clear()
    user = await db.get_user(message.from_user.id)
    role = user['role'] if 'role' in user.keys() else 'staff'
    await message.answer("–û–ø–µ—Ä–∞—Ü–∏—è –æ—Ç–º–µ–Ω–µ–Ω–∞.", reply_markup=get_menu_by_role(role))
    return

@questions_router.message(QuestionStates.waiting_for_search_type)
async def handle_universal_search(message: Message, state: FSMContext):
    """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –∑–∞–ø—Ä–æ—Å–æ–≤ - –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø –ø–æ–∏—Å–∫–∞."""
    text = message.text.strip()
    user_id = message.from_user.id
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –∫–Ω–æ–ø–∫–∞ –ª–∏ —ç—Ç–æ –≤–æ–∑–≤—Ä–∞—Ç–∞ –∏–ª–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –¥–∏–∞–ª–æ–≥–∞
    if text == "üîô –í–µ—Ä–Ω—É—Ç—å—Å—è –≤ –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é" or text == "‚ùå –ó–∞–≤–µ—Ä—à–∏—Ç—å –¥–∏–∞–ª–æ–≥":
        return
    
    # –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ —Ç–æ–ª—å–∫–æ –∫–æ–¥—ã, –Ω–æ –∏ —è–≤–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã
    search_indicators = [
        '–ø–æ–∫–∞–∂–∏', '–Ω–∞–π–¥–∏', '–ø–æ–∏—Å–∫', '–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è',
        '—á—Ç–æ —Ç–∞–∫–æ–µ', '—Ä–∞—Å—Å–∫–∞–∂–∏ –ø—Ä–æ', '–∞–Ω–∞–ª–∏–∑ –Ω–∞'
    ]
    
    text_lower = text.lower()
    is_search_query = any(indicator in text_lower for indicator in search_indicators)
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∑–∞–ø—Ä–æ—Å–∞
    if is_test_code_pattern(text):
        # –≠—Ç–æ –ø–æ—Ö–æ–∂–µ –Ω–∞ –∫–æ–¥ —Ç–µ—Å—Ç–∞
        await state.set_state(QuestionStates.waiting_for_code)
        await handle_code_search(message, state)
    elif is_search_query or len(text.split()) <= 3:
        # –ö–æ—Ä–æ—Ç–∫–∏–π –∑–∞–ø—Ä–æ—Å –∏–ª–∏ —è–≤–Ω—ã–π –ø–æ–∏—Å–∫ - –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫
        await state.set_state(QuestionStates.waiting_for_name)
        await handle_name_search(message, state)
    else:
        # –î–ª–∏–Ω–Ω—ã–π –≤–æ–ø—Ä–æ—Å - –≤–æ–∑–º–æ–∂–Ω–æ, –æ–±—â–∏–π –≤–æ–ø—Ä–æ—Å
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ —Ç–µ—Å—Ç
        processor = DataProcessor()
        processor.load_vector_store()
        
        # –ë—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫
        results = processor.search_test(text, top_k=3)
        
        if results and results[0][1] > 0.7:  # –í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
            await state.set_state(QuestionStates.waiting_for_name)
            await handle_name_search(message, state)
        else:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –¥–ª—è –æ–±—â–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤
            await db.add_request_stat(
                user_id=user_id,
                request_type='question',
                request_text=text
            )
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∫ –æ–±—â–∏–π –≤–æ–ø—Ä–æ—Å
            await handle_general_question(message, state, text)

@questions_router.message(QuestionStates.waiting_for_code)
async def handle_code_search(message: Message, state: FSMContext):
    """Handle test code search with smart matching and fuzzy suggestions."""
    data = await state.get_data()
    if data.get('is_processing', False):
        await message.answer(
            "‚è≥ –ü–æ–¥–æ–∂–¥–∏—Ç–µ, –∏–¥–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞...",
            reply_markup=get_back_to_menu_kb()
        )
        return
    
    await state.update_data(is_processing=True)
    
    user_id = message.from_user.id
    original_input = message.text.strip()
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤–æ–ø—Ä–æ—Å–∞
    await db.add_request_stat(
        user_id=user_id,
        request_type='question',
        request_text=original_input
    )
    
    gif_msg = None
    loading_msg = None
    animation_task = None

    try:
        current_task = asyncio.current_task()
        await state.update_data(current_task=current_task)
        
        try:
            if LOADING_GIF_ID:
                gif_msg = await message.answer_animation(LOADING_GIF_ID, caption="")
        except Exception:
            gif_msg = None
        
        loading_msg = await message.answer("üîç –ò—â—É —Ç–µ—Å—Ç –ø–æ –∫–æ–¥—É...\n‚è≥ –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –¥–∞–Ω–Ω—ã–µ...")
        if loading_msg:
            animation_task = asyncio.create_task(animate_loading(loading_msg))
        
        if current_task and current_task.cancelled():
            raise asyncio.CancelledError()
        
        processor = DataProcessor()
        processor.load_vector_store()
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤—Ö–æ–¥–Ω–æ–π –∫–æ–¥ (—Å —É—á–µ—Ç–æ–º –∫–∏—Ä–∏–ª–ª–∏—Ü—ã)
        normalized_input = normalize_test_code(original_input)
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–º–Ω—ã–π –ø–æ–∏—Å–∫
        result, found_variant, match_type = await smart_test_search(processor, original_input)
        
        if current_task and current_task.cancelled():
            raise asyncio.CancelledError()
        
        if not result:
            # –ò—â–µ–º –ø–æ—Ö–æ–∂–∏–µ —Ç–µ—Å—Ç—ã —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π
            similar_tests = await fuzzy_test_search(processor, normalized_input, threshold=30)
            
            if animation_task:
                animation_task.cancel()
            await safe_delete_message(loading_msg)
            await safe_delete_message(gif_msg)
            
            await db.add_search_history(
                user_id=user_id,
                search_query=original_input,
                search_type='code',
                success=False
            )
            
            if similar_tests:
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã
                response = f"‚ùå –¢–µ—Å—Ç —Å –∫–æ–¥–æ–º '<code>{normalized_input}</code>' –Ω–µ –Ω–∞–π–¥–µ–Ω.\n"
                response += format_similar_tests_with_links(similar_tests, max_display=10)
                
                keyboard = create_similar_tests_keyboard(similar_tests[:20])
                
                await message.answer(
                    response + "\n<i>–ù–∞–∂–º–∏—Ç–µ –Ω–∞ –∫–æ–¥ —Ç–µ—Å—Ç–∞ –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏ –≤—ã—à–µ –∏–ª–∏ –≤—ã–±–µ—Ä–∏—Ç–µ –∏–∑ –∫–Ω–æ–ø–æ–∫ –Ω–∏–∂–µ:</i>", 
                    parse_mode="HTML", 
                    reply_markup=keyboard,
                    disable_web_page_preview=True
                )
            else:
                error_msg = f"‚ùå –¢–µ—Å—Ç —Å –∫–æ–¥–æ–º '{normalized_input}' –Ω–µ –Ω–∞–π–¥–µ–Ω.\n"
                error_msg += "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –≤–≤–µ—Å—Ç–∏ –¥—Ä—É–≥–æ–π –∫–æ–¥ –∏–ª–∏ –æ–ø–∏—à–∏—Ç–µ, —á—Ç–æ –≤—ã –∏—â–µ—Ç–µ."
                await message.answer(error_msg, reply_markup=get_back_to_menu_kb())
            
            await state.set_state(QuestionStates.waiting_for_search_type)
            return
            
        # –ù–∞–π–¥–µ–Ω —Ä–µ–∑—É–ª—å—Ç–∞—Ç - –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –∫–∞–∫ –æ–±—ã—á–Ω–æ
        doc = result[0]
        test_data = format_test_data(doc.metadata)
        
        response = format_test_info(test_data)
        
        await db.add_search_history(
            user_id=user_id,
            search_query=original_input,
            found_test_code=test_data['test_code'],
            search_type='code',
            success=True
        )
        
        await db.update_user_frequent_test(
            user_id=user_id,
            test_code=test_data['test_code'],
            test_name=test_data['test_name']
        )
        
        if animation_task:
            animation_task.cancel()
        await safe_delete_message(loading_msg)
        await safe_delete_message(gif_msg)
        
        # –ò–ó–ú–ï–ù–ï–ù–û: –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é —Å —Ñ–æ—Ç–æ
        await send_test_info_with_photo(message, test_data, response)
        
        await message.answer(
            "–ú–æ–∂–µ—Ç–µ –∑–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å –æ–± —ç—Ç–æ–º —Ç–µ—Å—Ç–µ –∏–ª–∏ –≤—ã–±—Ä–∞—Ç—å –¥–µ–π—Å—Ç–≤–∏–µ:", 
            reply_markup=get_dialog_kb()
        )
        
        await state.set_state(QuestionStates.in_dialog)
        await state.update_data(current_test=test_data, last_viewed_test=test_data['test_code'])
        
    except asyncio.CancelledError:
        if animation_task:
            animation_task.cancel()
        await safe_delete_message(loading_msg)
        await safe_delete_message(gif_msg)
        await message.answer("‚èπ –ü–æ–∏—Å–∫ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω.", reply_markup=get_back_to_menu_kb())
        
    except Exception as e:
        print(f"[ERROR] Code search failed: {e}")
        if animation_task:
            animation_task.cancel()
        await safe_delete_message(loading_msg)
        await safe_delete_message(gif_msg)
        
        await message.answer("‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ", reply_markup=get_back_to_menu_kb())
        await state.set_state(QuestionStates.waiting_for_search_type)
    
    finally:
        await state.update_data(is_processing=False, current_task=None)

@questions_router.message(QuestionStates.in_dialog, F.text == "üîÑ –ù–æ–≤—ã–π –≤–æ–ø—Ä–æ—Å")
async def handle_new_question_in_dialog(message: Message, state: FSMContext):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è –Ω–æ–≤—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ –≤ —Ä–µ–∂–∏–º–µ –¥–∏–∞–ª–æ–≥–∞."""
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Ç–µ—Å—Ç–æ–≤
    data = await state.get_data()
    last_viewed = data.get('last_viewed_test')
    
    await message.answer(
        "üí° –í–≤–µ–¥–∏—Ç–µ –∫–æ–¥ —Ç–µ—Å—Ç–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä: AN5) –∏–ª–∏ –æ–ø–∏—à–∏—Ç–µ, —á—Ç–æ –≤—ã –∏—â–µ—Ç–µ:",
        reply_markup=get_back_to_menu_kb()
    )
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ–¥—Å–∫–∞–∑–∫–∏
    await show_personalized_suggestions(message, state)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ç–æ—Ä–∏—é –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤ –ø—Ä–∏ –ø–µ—Ä–µ—Ö–æ–¥–µ –∫ –Ω–æ–≤–æ–º—É –ø–æ–∏—Å–∫—É
    await state.set_state(QuestionStates.waiting_for_search_type)
    if last_viewed:
        await state.update_data(last_viewed_test=last_viewed)

@questions_router.callback_query(F.data == "new_search")
async def handle_new_search(callback: CallbackQuery, state: FSMContext):
    await callback.answer()
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
    data = await state.get_data()
    last_viewed = data.get('last_viewed_test')
    
    await callback.message.answer(
        "üí° –í–≤–µ–¥–∏—Ç–µ –∫–æ–¥ —Ç–µ—Å—Ç–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä: AN5) –∏–ª–∏ –æ–ø–∏—à–∏—Ç–µ, —á—Ç–æ –≤—ã –∏—â–µ—Ç–µ:",
        reply_markup=get_back_to_menu_kb()
    )
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ–¥—Å–∫–∞–∑–∫–∏
    message = callback.message
    message.from_user = callback.from_user
    await show_personalized_suggestions(message, state)
    
    await state.set_state(QuestionStates.waiting_for_search_type)
    if last_viewed:
        await state.update_data(last_viewed_test=last_viewed)

@questions_router.message(QuestionStates.in_dialog, F.text == "üì∑ –ü–æ–∫–∞–∑–∞—Ç—å –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä")
async def handle_show_container_photo(message: Message, state: FSMContext):
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ñ–æ—Ç–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ —Ç–µ—Å—Ç–∞."""
    data = await state.get_data()
    test_data = data.get('current_test')
    
    if not test_data:
        await message.answer("‚ùå –°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ —Ç–µ—Å—Ç")
        return
    

@questions_router.message(QuestionStates.waiting_for_name)
async def handle_name_search(message: Message, state: FSMContext):
    """Handle test name search using RAG."""
    user_id = message.from_user.id
    text = message.text.strip()
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤–æ–ø—Ä–æ—Å–∞
    await db.add_request_stat(
        user_id=user_id,
        request_type='question',
        request_text=text
    )
    
    gif_msg = None
    loading_msg = None
    animation_task = None

    try:
        if LOADING_GIF_ID:
            gif_msg = await message.answer_animation(LOADING_GIF_ID, caption="")
            loading_msg = await message.answer("–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –≤–∞—à –∑–∞–ø—Ä–æ—Å...\n‚è≥ –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –¥–∞–Ω–Ω—ã–µ...")
            animation_task = asyncio.create_task(animate_loading(loading_msg))
        else:
            loading_msg = await message.answer("üîç –ò—â–µ–º —Ç–µ—Å—Ç...")
        
        expanded_query = expand_query_with_abbreviations(text)
        processor = DataProcessor()
        processor.load_vector_store()
        
        rag_hits = processor.search_test(expanded_query, top_k=20)
        
        if not rag_hits:
            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –Ω–µ—É–¥–∞—á–Ω—ã–π –ø–æ–∏—Å–∫
            await db.add_search_history(
                user_id=user_id,
                search_query=text,
                search_type='text',
                success=False
            )
            raise ValueError("–¢–µ—Å—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            
        selected_docs = await select_best_match(text, rag_hits)
        
        # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º —É—Å–ø–µ—à–Ω—ã–π –ø–æ–∏—Å–∫
        for doc in selected_docs[:1]:  # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–π –Ω–∞–π–¥–µ–Ω–Ω—ã–π
            await db.add_search_history(
                user_id=user_id,
                search_query=text,
                found_test_code=doc.metadata['test_code'],
                search_type='text',
                success=True
            )
            
            await db.update_user_frequent_test(
                user_id=user_id,
                test_code=doc.metadata['test_code'],
                test_name=doc.metadata['test_name']
            )
        
        # –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞
        if animation_task:
            animation_task.cancel()
        await safe_delete_message(loading_msg)
        await safe_delete_message(gif_msg)
        
        if len(selected_docs) > 1:
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å –ö–õ–ò–ö–ê–ë–ï–õ–¨–ù–´–ú–ò –°–°–´–õ–ö–ê–ú–ò
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –∫–ª–∏–∫–∞–±–µ–ª—å–Ω—ã–º–∏ –∫–æ–¥–∞–º–∏
            response = "–ù–∞–π–¥–µ–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö —Ç–µ—Å—Ç–æ–≤:\n\n"
            
            for i, doc in enumerate(selected_docs, 1):
                test_data = format_test_data(doc.metadata)
                test_code = test_data['test_code']
                test_name = html.escape(test_data['test_name'])
                department = html.escape(test_data['department'])
                
                # –°–æ–∑–¥–∞–µ–º –∫–ª–∏–∫–∞–±–µ–ª—å–Ω—É—é —Å—Å—ã–ª–∫—É –¥–ª—è –∫–æ–¥–∞
                link = create_test_link(test_code)
                
                response += (
                    f"<b>{i}.</b> –¢–µ—Å—Ç: <a href='{link}'>{test_code}</a> - {test_name}\n"
                    f"üß¨ <b>–í–∏–¥ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è:</b> {department}\n\n"
                )
                
                # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É —Å–æ–æ–±—â–µ–Ω–∏—è
                if len(response) > 3500:
                    response += "\n<i>... –∏ –¥—Ä—É–≥–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã</i>"
                    break
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –∫–ª–∏–∫–∞–±–µ–ª—å–Ω—ã–º–∏ —Å—Å—ã–ª–∫–∞–º–∏
            await message.answer(
                response, 
                parse_mode="HTML",
                disable_web_page_preview=True
            )
            
            # –°–æ–∑–¥–∞–µ–º –∫–æ–º–ø–∞–∫—Ç–Ω—É—é –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É —Å –∫–Ω–æ–ø–∫–∞–º–∏ (–∫–∞–∫ –¥–æ–ø–æ–ª–Ω–µ–Ω–∏–µ –∫ —Å—Å—ã–ª–∫–∞–º)
            keyboard = InlineKeyboardMarkup(inline_keyboard=[])
            row = []
            
            for i, doc in enumerate(selected_docs[:15]):  # –î–æ 15 –∫–Ω–æ–ø–æ–∫
                test_code = doc.metadata['test_code']
                row.append(InlineKeyboardButton(
                    text=test_code,
                    callback_data=TestCallback.pack("show_test", test_code)
                ))
                
                # –ü–æ 3 –∫–Ω–æ–ø–∫–∏ –≤ —Ä—è–¥
                if len(row) >= 3:
                    keyboard.inline_keyboard.append(row)
                    row = []
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ä—è–¥ –µ—Å–ª–∏ –µ—Å—Ç—å
            if row:
                keyboard.inline_keyboard.append(row)
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É —Å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–µ–π
            await message.answer(
                "üí° <b>–ù–∞–∂–º–∏—Ç–µ –Ω–∞ –∫–æ–¥ —Ç–µ—Å—Ç–∞ –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏ –≤—ã—à–µ –∏–ª–∏ –≤—ã–±–µ—Ä–∏—Ç–µ –∏–∑ –∫–Ω–æ–ø–æ–∫:</b>",
                reply_markup=keyboard,
                parse_mode="HTML"
            )

        else:
            # –û–¥–∏–Ω —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            test_data = format_test_data(selected_docs[0].metadata)
            response = format_test_info(test_data)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Ö–æ–∂–∏–µ —Ç–µ—Å—Ç—ã —Å –∫–ª–∏–∫–∞–±–µ–ª—å–Ω—ã–º–∏ —Å—Å—ã–ª–∫–∞–º–∏
            similar_tests = await fuzzy_test_search(processor, test_data['test_code'], threshold=40)
            similar_tests = [(d, s) for d, s in similar_tests if d.metadata.get('test_code') != test_data['test_code']]
            
            if similar_tests:
                response += format_similar_tests_with_links(similar_tests[:5])
            
            # –ò–ó–ú–ï–ù–ï–ù–û: –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å —Ñ–æ—Ç–æ
            await send_test_info_with_photo(message, test_data, response)
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É –¥–∏–∞–ª–æ–≥–∞
            await message.answer(
                "–ú–æ–∂–µ—Ç–µ –∑–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å –æ–± —ç—Ç–æ–º —Ç–µ—Å—Ç–µ –∏–ª–∏ –≤—ã–±—Ä–∞—Ç—å –¥–µ–π—Å—Ç–≤–∏–µ:",
                reply_markup=get_dialog_kb()
            )
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –Ω–∞–π–¥–µ–Ω–Ω—ã–π —Ç–µ—Å—Ç –¥–ª—è –¥–∏–∞–ª–æ–≥–∞
        await state.set_state(QuestionStates.in_dialog)
        if selected_docs:
            last_test_data = format_test_data(selected_docs[0].metadata)
            await state.update_data(current_test=last_test_data, last_viewed_test=last_test_data['test_code'])
            
    except Exception as e:
        print(f"[ERROR] Name search failed: {e}")
        import traceback
        traceback.print_exc()
        
        # –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –ø—Ä–∏ –æ—à–∏–±–∫–µ
        if animation_task:
            animation_task.cancel()
        await safe_delete_message(loading_msg)
        await safe_delete_message(gif_msg)
        
        error_msg = "‚ùå –¢–µ—Å—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã" if str(e) == "–¢–µ—Å—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã" else "‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."
        await message.answer(error_msg, reply_markup=get_back_to_menu_kb())
        await state.set_state(QuestionStates.waiting_for_search_type)

@questions_router.message(QuestionStates.in_dialog)
async def handle_dialog(message: Message, state: FSMContext):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–∏–∞–ª–æ–≥–∞ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ–º –Ω–∞ –Ω–æ–≤—ã–π –ø–æ–∏—Å–∫."""
    text = message.text.strip()
    user_id = message.from_user.id
    
        
    if text == "üîÑ –ù–æ–≤—ã–π –≤–æ–ø—Ä–æ—Å":
        await handle_new_question_in_dialog(message, state)
        return
    
    data = await state.get_data()
    test_data = data.get('current_test')
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –∫–æ–¥ –ª–∏ —Ç–µ—Å—Ç–∞ –≤–≤–µ–¥–µ–Ω
    if is_test_code_pattern(text):
        # –ï—Å–ª–∏ —ç—Ç–æ –∫–æ–¥ - —Å—Ä–∞–∑—É –∏—â–µ–º
        await state.set_state(QuestionStates.waiting_for_code)
        await handle_code_search(message, state)
        return
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–µ–Ω –ª–∏ –Ω–æ–≤—ã–π –ø–æ–∏—Å–∫
    needs_new_search = await check_if_needs_new_search(text, test_data)
    
    if needs_new_search:
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–ø—É—Å–∫–∞–µ–º –Ω–æ–≤—ã–π –ø–æ–∏—Å–∫
        await state.set_state(QuestionStates.waiting_for_name)
        await handle_name_search(message, state)
        return
    
    if not test_data:
        await message.answer("–ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ—Ç–µ—Ä—è–Ω. –ó–∞–¥–∞–π—Ç–µ –Ω–æ–≤—ã–π –≤–æ–ø—Ä–æ—Å.", reply_markup=get_back_to_menu_kb())
        await state.set_state(QuestionStates.waiting_for_search_type)
        return
    
    # –ï—Å–ª–∏ —ç—Ç–æ –≤–æ–ø—Ä–æ—Å –ø—Ä–æ —Ç–µ–∫—É—â–∏–π —Ç–µ—Å—Ç - —Å–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —á–µ—Ä–µ–∑ LLM
    gif_msg = None
    loading_msg = None
    animation_task = None
    
    try:
        gif_msg = await message.answer_animation(LOADING_GIF_ID, caption="")
        loading_msg = await message.answer("–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –≤–∞—à –∑–∞–ø—Ä–æ—Å...\n‚è≥ –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –¥–∞–Ω–Ω—ã–µ...")
        animation_task = asyncio.create_task(animate_loading(loading_msg))
        
        system_msg = SystemMessage(content=f"""
            –¢—ã - –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–∏–∏ VetUnion –∏ –æ—Ç–≤–µ—á–∞–µ—à—å —Ç–æ–ª—å–∫–æ –≤ –æ–±–ª–∞—Å—Ç–∏ –≤–µ—Ç–µ—Ä–∏–Ω–∞—Ä–∏–∏. 
            
            –¢–µ–∫—É—â–∏–π —Ç–µ—Å—Ç:
            –ö–æ–¥: {test_data['test_code']}
            –ù–∞–∑–≤–∞–Ω–∏–µ: {test_data['test_name']}
            
            –í–ê–ñ–ù–û–ï –ü–†–ê–í–ò–õ–û:
            –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç –ø—Ä–æ –î–†–£–ì–û–ô —Ç–µ—Å—Ç –∏–ª–∏ –∞–Ω–∞–ª–∏–∑ (—É–ø–æ–º–∏–Ω–∞–µ—Ç –¥—Ä—É–≥–æ–π –∫–æ–¥, –Ω–∞–∑–≤–∞–Ω–∏–µ –∏–ª–∏ —Ç–∏–ø –∞–Ω–∞–ª–∏–∑–∞),
            —Ç—ã –î–û–õ–ñ–ï–ù –æ—Ç–≤–µ—Ç–∏—Ç—å –¢–û–ß–ù–û —Ç–∞–∫:
            "NEED_NEW_SEARCH: [–∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è]"
            
            –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –∫–∞—Å–∞–µ—Ç—Å—è —Ç–µ–∫—É—â–µ–≥–æ —Ç–µ—Å—Ç–∞ –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Ö–æ—á–µ—Ç –ø–æ–∏–Ω—Ç–µ—Ä–µ—Å–æ–≤–∞—Ç—å—Å—è –ø–æ –¥—Ä—É–≥–æ–º—É –≤–æ–ø—Ä–æ—Å—É, –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–π –≤—Å—é –Ω–µ–æ–±—Ö–æ–¥–∏–º—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –æ–±–ª–∞—Å—Ç–∏ –≤–µ—Ç–µ—Ä–∏–Ω–∞—Ä–∏–∏ —Å –ø–æ–Ω–∏–º–∞–Ω–∏–µ–º –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ —Å–ª–µ–Ω–≥–∞.
        """)
        
        response = await llm.agenerate([[system_msg, HumanMessage(content=text)]])
        answer = response.generations[0][0].text.strip()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Ç–≤–µ—Ç LLM - –Ω—É–∂–µ–Ω –ª–∏ –Ω–æ–≤—ã–π –ø–æ–∏—Å–∫
        if answer.startswith("NEED_NEW_SEARCH:"):
            # LLM –æ–ø—Ä–µ–¥–µ–ª–∏–ª–∞ —á—Ç–æ –Ω—É–∂–µ–Ω –Ω–æ–≤—ã–π –ø–æ–∏—Å–∫
            search_query = answer.replace("NEED_NEW_SEARCH:", "").strip()
            
            # –£–¥–∞–ª—è–µ–º –∑–∞–≥—Ä—É–∑–æ—á–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
            if animation_task:
                animation_task.cancel()
            await safe_delete_message(loading_msg)
            await safe_delete_message(gif_msg)
            
            # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–ø—É—Å–∫–∞–µ–º –Ω–æ–≤—ã–π –ø–æ–∏—Å–∫ —Å –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–º –∑–∞–ø—Ä–æ—Å–æ–º
            if search_query:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å
                message.text = search_query
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –ø–æ–∏—Å–∫–∞ –∏ –∑–∞–ø—É—Å–∫–∞–µ–º
            if is_test_code_pattern(message.text):
                await state.set_state(QuestionStates.waiting_for_code)
                await handle_code_search(message, state)
            else:
                await state.set_state(QuestionStates.waiting_for_name)
                await handle_name_search(message, state)
            return
        
        # –û–±—ã—á–Ω—ã–π –æ—Ç–≤–µ—Ç –ø—Ä–æ —Ç–µ–∫—É—â–∏–π —Ç–µ—Å—Ç
        answer = fix_bold(answer)  # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—é markdown
        await loading_msg.edit_text(answer, parse_mode="HTML")  # –î–æ–±–∞–≤–ª—è–µ–º parse_mode
        await message.answer("–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:", reply_markup=get_dialog_kb())
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —É–∂–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ handle_universal_search –∏–ª–∏ –ø—Ä–∏ –ø–µ—Ä–≤–æ–Ω–∞—á–∞–ª—å–Ω–æ–º –≤—Ö–æ–¥–µ
        
    except Exception as e:
        print(f"[ERROR] Dialog processing failed: {e}")
        # –ü—Ä–∏ –æ—à–∏–±–∫–µ –ø—Ä–æ–±—É–µ–º –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
        if animation_task:
            animation_task.cancel()
        await safe_delete_message(loading_msg)
        await safe_delete_message(gif_msg)
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ–∏—Å–∫ –∫–∞–∫ fallback
        await state.set_state(QuestionStates.waiting_for_name)
        await handle_name_search(message, state)
    finally:
        if animation_task and not animation_task.cancelled():
            animation_task.cancel()
        await safe_delete_message(gif_msg)
        
async def send_test_info_with_photo(message: Message, test_data: Dict, response_text: str):
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–µ—Å—Ç–µ —Å —Ñ–æ—Ç–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ –µ—Å–ª–∏ –æ–Ω–æ –µ—Å—Ç—å"""
    # –ü–æ–ª—É—á–∞–µ–º –Ω–æ–º–µ—Ä–∞ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤
    container_numbers = db.parse_container_numbers(str(test_data.get('container_number', '')))
    
    if container_numbers:
        # –ü–æ–ª—É—á–∞–µ–º —Ñ–æ—Ç–æ –ø–µ—Ä–≤–æ–≥–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
        first_photo = await db.get_container_photo(container_numbers[0])
        
        if first_photo:
            try:
                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ñ–æ—Ç–æ —Å –ø–æ–ª–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –≤ –ø–æ–¥–ø–∏—Å–∏
                await message.answer_photo(
                    photo=first_photo,
                    caption=response_text,
                    parse_mode="HTML"
                )
                
                # –ï—Å–ª–∏ –µ—Å—Ç—å –µ—â–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã - –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –∏—Ö –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º–∏ —Ñ–æ—Ç–æ
                if len(container_numbers) > 1:
                    for num in container_numbers[1:]:
                        photo_id = await db.get_container_photo(num)
                        if photo_id:
                            try:
                                await message.answer_photo(
                                    photo=photo_id,
                                    caption=f"üß™ –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä ‚Ññ{num}",
                                    parse_mode="HTML"
                                )
                            except:
                                pass
                return True
            except Exception as e:
                print(f"[ERROR] Failed to send photo with caption: {e}")
    
    # –ï—Å–ª–∏ —Ñ–æ—Ç–æ –Ω–µ—Ç - –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ–±—ã—á–Ω–æ–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
    await message.answer(response_text, parse_mode="HTML")
    return False

async def handle_context_switch(message: Message, state: FSMContext, new_query: str):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –Ω–∞ –Ω–æ–≤—ã–π —Ç–µ—Å—Ç."""
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ç–æ—Ä–∏—é
    data = await state.get_data()
    if 'current_test' in data:
        last_test = data['current_test']['test_code']
        # –ú–æ–∂–Ω–æ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞
        await state.update_data(previous_tests=data.get('previous_tests', []) + [last_test])
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –ø–æ–∏—Å–∫–∞ –¥–ª—è –Ω–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
    if is_test_code_pattern(new_query):
        await state.set_state(QuestionStates.waiting_for_code)
        message.text = new_query  # –ü–æ–¥–º–µ–Ω—è–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞
        await handle_code_search(message, state)
    else:
        await state.set_state(QuestionStates.waiting_for_name)
        message.text = new_query
        await handle_name_search(message, state)

__all__ = [
    'questions_router',
    'smart_test_search',
    'format_test_data',
    'format_test_info',
    'fuzzy_test_search',
    'format_similar_tests_with_links',
    'QuestionStates',
    'get_dialog_kb',
    'create_test_link',
    'BOT_USERNAME',
    'normalize_test_code',
    'simple_translit',
    'reverse_translit'
]
